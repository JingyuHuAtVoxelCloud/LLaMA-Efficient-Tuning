nohup: ignoring input
[2023-08-16 15:48:28,625] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-16 15:48:32,145] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-16 15:48:32,152] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-16 15:48:32,175] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-16 15:48:32,304] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
08/16/2023 15:48:34 - WARNING - llmtuner.tuner.core.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Process rank: 2, device: cuda:2, n_gpu: 1
  distributed training: True, 16-bits training: True
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=10,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../outputs/Ihin/Ihin-sft-llama2/runs/Aug16_15-48-34_blade3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_torch,
optim_args=None,
output_dir=../outputs/Ihin/Ihin-sft-llama2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=../outputs/Ihin/Ihin-sft-llama2,
save_on_each_node=False,
save_safetensors=False,
save_steps=800,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
08/16/2023 15:48:34 - INFO - llmtuner.dsets.loader - Loading dataset self_cognition.json...
08/16/2023 15:48:34 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/load.py:2069: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
08/16/2023 15:48:34 - WARNING - llmtuner.tuner.core.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, 16-bits training: True
08/16/2023 15:48:34 - WARNING - llmtuner.tuner.core.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Process rank: 3, device: cuda:3, n_gpu: 1
  distributed training: True, 16-bits training: True
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=10,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../outputs/Ihin/Ihin-sft-llama2/runs/Aug16_15-48-34_blade3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_torch,
optim_args=None,
output_dir=../outputs/Ihin/Ihin-sft-llama2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=../outputs/Ihin/Ihin-sft-llama2,
save_on_each_node=False,
save_safetensors=False,
save_steps=800,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=10,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../outputs/Ihin/Ihin-sft-llama2/runs/Aug16_15-48-34_blade3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_torch,
optim_args=None,
output_dir=../outputs/Ihin/Ihin-sft-llama2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=../outputs/Ihin/Ihin-sft-llama2,
save_on_each_node=False,
save_safetensors=False,
save_steps=800,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
08/16/2023 15:48:34 - INFO - llmtuner.dsets.loader - Loading dataset self_cognition.json...
08/16/2023 15:48:34 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
08/16/2023 15:48:34 - WARNING - llmtuner.tuner.core.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
08/16/2023 15:48:34 - INFO - llmtuner.dsets.loader - Loading dataset self_cognition.json...
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, 16-bits training: True
08/16/2023 15:48:34 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/load.py:2069: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
08/16/2023 15:48:34 - INFO - llmtuner.tuner.core.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=10,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../outputs/Ihin/Ihin-sft-llama2/runs/Aug16_15-48-34_blade3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_torch,
optim_args=None,
output_dir=../outputs/Ihin/Ihin-sft-llama2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=../outputs/Ihin/Ihin-sft-llama2,
save_on_each_node=False,
save_safetensors=False,
save_steps=800,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/load.py:2069: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
08/16/2023 15:48:34 - INFO - llmtuner.dsets.loader - Loading dataset self_cognition.json...
08/16/2023 15:48:34 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/load.py:2069: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
08/16/2023 15:48:35 - INFO - llmtuner.dsets.loader - Loading dataset ihin_qa_adn.json...
08/16/2023 15:48:35 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
Using custom data configuration default-01cf452108899fd3
Loading Dataset Infos from /home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
08/16/2023 15:48:35 - INFO - llmtuner.dsets.loader - Loading dataset ihin_qa_adn.json...
08/16/2023 15:48:35 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
Found cached dataset json (/home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
08/16/2023 15:48:35 - INFO - llmtuner.dsets.loader - Loading dataset ihin_qa_adn.json...
08/16/2023 15:48:35 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
08/16/2023 15:48:35 - INFO - llmtuner.dsets.loader - Loading dataset ihin_qa_adn.json...
08/16/2023 15:48:35 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
08/16/2023 15:48:36 - INFO - llmtuner.dsets.loader - Loading dataset Ihin_sft.json...
08/16/2023 15:48:36 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
08/16/2023 15:48:36 - INFO - llmtuner.dsets.loader - Loading dataset Ihin_sft.json...
08/16/2023 15:48:36 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
08/16/2023 15:48:36 - INFO - llmtuner.dsets.loader - Loading dataset Ihin_sft.json...
08/16/2023 15:48:36 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
Using custom data configuration default-84d7b9963ed5511d
Loading Dataset Infos from /home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/jyhu/.cache/huggingface/datasets/json/default-84d7b9963ed5511d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Found cached dataset json (/home/jyhu/.cache/huggingface/datasets/json/default-84d7b9963ed5511d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/jyhu/.cache/huggingface/datasets/json/default-84d7b9963ed5511d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
08/16/2023 15:48:36 - INFO - llmtuner.dsets.loader - Loading dataset Ihin_sft.json...
08/16/2023 15:48:36 - WARNING - llmtuner.dsets.loader - Checksum failed: missing SHA-1 hash value in dataset_info.json.
Using custom data configuration default-b8e892af03bd9dfa
Loading Dataset Infos from /home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/jyhu/.cache/huggingface/datasets/json/default-b8e892af03bd9dfa/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Found cached dataset json (/home/jyhu/.cache/huggingface/datasets/json/default-b8e892af03bd9dfa/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/jyhu/.cache/huggingface/datasets/json/default-b8e892af03bd9dfa/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Some of the datasets have disparate format. Resetting the format of the concatenated dataset.
[INFO|tokenization_utils_base.py:1837] 2023-08-16 15:48:37,757 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:1837] 2023-08-16 15:48:37,757 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1837] 2023-08-16 15:48:37,758 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1837] 2023-08-16 15:48:37,758 >> loading file tokenizer_config.json
[INFO|configuration_utils.py:710] 2023-08-16 15:48:37,782 >> loading configuration file ../models/Llama-2-7b-chat-hf/config.json
[INFO|configuration_utils.py:768] 2023-08-16 15:48:37,783 >> Model config LlamaConfig {
  "_name_or_path": "../models/Llama-2-7b-chat-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.31.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|modeling_utils.py:2600] 2023-08-16 15:48:37,816 >> loading weights file ../models/Llama-2-7b-chat-hf/model.safetensors.index.json
[INFO|modeling_utils.py:1172] 2023-08-16 15:48:37,817 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:599] 2023-08-16 15:48:37,818 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0,
  "transformers_version": "4.31.0"
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.68it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.28it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.59it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.27it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.32it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.21it/s]
08/16/2023 15:48:38 - INFO - llmtuner.tuner.core.adapter - Fine-tuning method: LoRA
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.74it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.66it/s]
08/16/2023 15:48:38 - INFO - llmtuner.tuner.core.adapter - Fine-tuning method: LoRA
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.61it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.42it/s]
08/16/2023 15:48:38 - INFO - llmtuner.tuner.core.adapter - Fine-tuning method: LoRA
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.95it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.83it/s]
[INFO|modeling_utils.py:3329] 2023-08-16 15:48:38,531 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:3337] 2023-08-16 15:48:38,531 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at ../models/Llama-2-7b-chat-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:559] 2023-08-16 15:48:38,534 >> loading configuration file ../models/Llama-2-7b-chat-hf/generation_config.json
[INFO|configuration_utils.py:599] 2023-08-16 15:48:38,534 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.9,
  "top_p": 0.6,
  "transformers_version": "4.31.0"
}

08/16/2023 15:48:38 - INFO - llmtuner.tuner.core.adapter - Fine-tuning method: LoRA
08/16/2023 15:48:50 - INFO - llmtuner.tuner.core.loader - trainable params: 4194304 || all params: 6742609920 || trainable%: 0.0622
08/16/2023 15:48:50 - INFO - llmtuner.extras.template - Add pad token: <unk>
Filter:   0%|          | 0/6643 [00:00<?, ? examples/s]Filter: 100%|██████████| 6643/6643 [00:00<00:00, 176380.08 examples/s]
08/16/2023 15:48:50 - INFO - llmtuner.tuner.core.loader - trainable params: 4194304 || all params: 6742609920 || trainable%: 0.0622
08/16/2023 15:48:50 - INFO - llmtuner.extras.template - Add pad token: <unk>
08/16/2023 15:48:50 - INFO - llmtuner.tuner.core.loader - trainable params: 4194304 || all params: 6742609920 || trainable%: 0.0622
08/16/2023 15:48:50 - INFO - llmtuner.extras.template - Add pad token: <unk>
08/16/2023 15:48:50 - INFO - llmtuner.tuner.core.loader - trainable params: 4194304 || all params: 6742609920 || trainable%: 0.0622
08/16/2023 15:48:50 - INFO - llmtuner.extras.template - Add pad token: <unk>
[INFO|tokenization_utils_base.py:921] 2023-08-16 15:48:50,355 >> Assigning [] to the additional_special_tokens key of the tokenizer
Loading cached processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-809e8e56e4609142.arrow
Process #0 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00000_of_00032.arrow
Process #1 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00001_of_00032.arrow
Process #2 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00002_of_00032.arrow
Process #3 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00003_of_00032.arrow
Process #4 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00004_of_00032.arrow
Process #5 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00005_of_00032.arrow
Process #6 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00006_of_00032.arrow
Process #7 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00007_of_00032.arrow
Process #8 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00008_of_00032.arrow
Process #9 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00009_of_00032.arrow
Process #10 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00010_of_00032.arrow
Process #11 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00011_of_00032.arrow
Process #12 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00012_of_00032.arrow
Process #13 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00013_of_00032.arrow
Process #14 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00014_of_00032.arrow
Process #15 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00015_of_00032.arrow
Process #16 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00016_of_00032.arrow
Process #17 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00017_of_00032.arrow
Process #18 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00018_of_00032.arrow
Process #19 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00019_of_00032.arrow
Process #20 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00020_of_00032.arrow
Process #21 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00021_of_00032.arrow
Process #22 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00022_of_00032.arrow
Process #23 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00023_of_00032.arrow
Process #24 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00024_of_00032.arrow
Process #25 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00025_of_00032.arrow
Process #26 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00026_of_00032.arrow
Process #27 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00027_of_00032.arrow
Process #28 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00028_of_00032.arrow
Process #29 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00029_of_00032.arrow
Process #30 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00030_of_00032.arrow
Process #31 will write at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00031_of_00032.arrow
Spawning 32 processes
Running tokenizer on dataset (num_proc=32):   0%|          | 0/6643 [00:00<?, ? examples/s]Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00003_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00007_of_00032.arrow
Running tokenizer on dataset (num_proc=32):   3%|▎         | 208/6643 [00:00<00:15, 411.36 examples/s]Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00004_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00000_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00006_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00008_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00002_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00005_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00011_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00001_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00009_of_00032.arrow
Running tokenizer on dataset (num_proc=32):  25%|██▌       | 1664/6643 [00:00<00:01, 3397.96 examples/s]Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00010_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00012_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00016_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00013_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00014_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00018_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00019_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00017_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00020_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00021_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00026_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00025_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00023_of_00032.arrow
Running tokenizer on dataset (num_proc=32):  56%|█████▋    | 3743/6643 [00:00<00:00, 7369.18 examples/s]Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00015_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00024_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00029_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00028_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00027_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00030_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00031_of_00032.arrow
Caching processed dataset at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-fccbc7fb5b9c3479_00022_of_00032.arrow
Running tokenizer on dataset (num_proc=32): 100%|██████████| 6643/6643 [00:00<00:00, 7316.61 examples/s]
Concatenating 32 shards
input_ids:
[1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 8444, 29892, 3390, 1319, 322, 15993, 20255, 29889, 29849, 1234, 408, 1371, 3730, 408, 1950, 29892, 1550, 1641, 9109, 29889, 29871, 3575, 6089, 881, 451, 3160, 738, 10311, 1319, 29892, 443, 621, 936, 29892, 11021, 391, 29892, 7916, 391, 29892, 304, 27375, 29892, 18215, 29892, 470, 27302, 2793, 29889, 3529, 9801, 393, 596, 20890, 526, 5374, 635, 443, 5365, 1463, 322, 6374, 297, 5469, 29889, 13, 3644, 263, 1139, 947, 451, 1207, 738, 4060, 29892, 470, 338, 451, 2114, 1474, 16165, 261, 296, 29892, 5649, 2020, 2012, 310, 22862, 1554, 451, 1959, 29889, 960, 366, 1016, 29915, 29873, 1073, 278, 1234, 304, 263, 1139, 29892, 3113, 1016, 29915, 29873, 6232, 2089, 2472, 29889, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 30919, 31076, 518, 29914, 25580, 29962, 29871, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
inputs:
<s> [INST] <<SYS>>
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
<</SYS>>

你好 [/INST]  您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
labels:
<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> 您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
Caching indices mapping at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c7078bea43510d5b.arrow
Caching indices mapping at /home/jyhu/.cache/huggingface/datasets/json/default-01cf452108899fd3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-eebf3d35aab66279.arrow
Running tokenizer on dataset (num_proc=32):   0%|          | 0/6643 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/6643 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   0%|          | 0/6643 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=32):   3%|▎         | 208/6643 [00:00<00:17, 377.91 examples/s]Running tokenizer on dataset (num_proc=32):   3%|▎         | 208/6643 [00:00<00:21, 299.75 examples/s]Running tokenizer on dataset (num_proc=32):   6%|▋         | 416/6643 [00:00<00:09, 653.40 examples/s]Running tokenizer on dataset (num_proc=32):  16%|█▌        | 1040/6643 [00:00<00:03, 1632.93 examples/s]Running tokenizer on dataset (num_proc=32):   3%|▎         | 208/6643 [00:00<00:24, 258.69 examples/s]Running tokenizer on dataset (num_proc=32):  19%|█▉        | 1248/6643 [00:00<00:02, 2095.88 examples/s]Running tokenizer on dataset (num_proc=32):  41%|████      | 2704/6643 [00:00<00:00, 4361.67 examples/s]Running tokenizer on dataset (num_proc=32):  19%|█▉        | 1248/6643 [00:00<00:03, 1782.35 examples/s]Running tokenizer on dataset (num_proc=32):  50%|█████     | 3328/6643 [00:00<00:00, 6099.94 examples/s]Running tokenizer on dataset (num_proc=32):  72%|███████▏  | 4780/6643 [00:01<00:00, 7323.89 examples/s]Running tokenizer on dataset (num_proc=32):  59%|█████▉    | 3950/6643 [00:01<00:00, 6128.54 examples/s]Running tokenizer on dataset (num_proc=32):  81%|████████▏ | 5401/6643 [00:01<00:00, 8881.35 examples/s]Running tokenizer on dataset (num_proc=32): 100%|██████████| 6643/6643 [00:01<00:00, 9143.55 examples/s]Running tokenizer on dataset (num_proc=32):  81%|████████▏ | 5401/6643 [00:01<00:00, 7352.14 examples/s]Running tokenizer on dataset (num_proc=32): 100%|██████████| 6643/6643 [00:01<00:00, 9690.58 examples/s]Running tokenizer on dataset (num_proc=32): 100%|██████████| 6643/6643 [00:01<00:00, 5123.58 examples/s]
Running tokenizer on dataset (num_proc=32): 100%|██████████| 6643/6643 [00:01<00:00, 5113.68 examples/s]
input_ids:
[1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 8444, 29892, 3390, 1319, 322, 15993, 20255, 29889, 29849, 1234, 408, 1371, 3730, 408, 1950, 29892, 1550, 1641, 9109, 29889, 29871, 3575, 6089, 881, 451, 3160, 738, 10311, 1319, 29892, 443, 621, 936, 29892, 11021, 391, 29892, 7916, 391, 29892, 304, 27375, 29892, 18215, 29892, 470, 27302, 2793, 29889, 3529, 9801, 393, 596, 20890, 526, 5374, 635, 443, 5365, 1463, 322, 6374, 297, 5469, 29889, 13, 3644, 263, 1139, 947, 451, 1207, 738, 4060, 29892, 470, 338, 451, 2114, 1474, 16165, 261, 296, 29892, 5649, 2020, 2012, 310, 22862, 1554, 451, 1959, 29889, 960, 366, 1016, 29915, 29873, 1073, 278, 1234, 304, 263, 1139, 29892, 3113, 1016, 29915, 29873, 6232, 2089, 2472, 29889, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 30919, 31076, 518, 29914, 25580, 29962, 29871, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
inputs:
<s> [INST] <<SYS>>
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
<</SYS>>

你好 [/INST]  您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
labels:
<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> 您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
Running tokenizer on dataset (num_proc=32): 100%|██████████| 6643/6643 [00:01<00:00, 4971.08 examples/s]
input_ids:
[1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 8444, 29892, 3390, 1319, 322, 15993, 20255, 29889, 29849, 1234, 408, 1371, 3730, 408, 1950, 29892, 1550, 1641, 9109, 29889, 29871, 3575, 6089, 881, 451, 3160, 738, 10311, 1319, 29892, 443, 621, 936, 29892, 11021, 391, 29892, 7916, 391, 29892, 304, 27375, 29892, 18215, 29892, 470, 27302, 2793, 29889, 3529, 9801, 393, 596, 20890, 526, 5374, 635, 443, 5365, 1463, 322, 6374, 297, 5469, 29889, 13, 3644, 263, 1139, 947, 451, 1207, 738, 4060, 29892, 470, 338, 451, 2114, 1474, 16165, 261, 296, 29892, 5649, 2020, 2012, 310, 22862, 1554, 451, 1959, 29889, 960, 366, 1016, 29915, 29873, 1073, 278, 1234, 304, 263, 1139, 29892, 3113, 1016, 29915, 29873, 6232, 2089, 2472, 29889, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 30919, 31076, 518, 29914, 25580, 29962, 29871, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
inputs:
<s> [INST] <<SYS>>
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
<</SYS>>

你好 [/INST]  您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
labels:
<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> 您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
input_ids:
[1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 8444, 29892, 3390, 1319, 322, 15993, 20255, 29889, 29849, 1234, 408, 1371, 3730, 408, 1950, 29892, 1550, 1641, 9109, 29889, 29871, 3575, 6089, 881, 451, 3160, 738, 10311, 1319, 29892, 443, 621, 936, 29892, 11021, 391, 29892, 7916, 391, 29892, 304, 27375, 29892, 18215, 29892, 470, 27302, 2793, 29889, 3529, 9801, 393, 596, 20890, 526, 5374, 635, 443, 5365, 1463, 322, 6374, 297, 5469, 29889, 13, 3644, 263, 1139, 947, 451, 1207, 738, 4060, 29892, 470, 338, 451, 2114, 1474, 16165, 261, 296, 29892, 5649, 2020, 2012, 310, 22862, 1554, 451, 1959, 29889, 960, 366, 1016, 29915, 29873, 1073, 278, 1234, 304, 263, 1139, 29892, 3113, 1016, 29915, 29873, 6232, 2089, 2472, 29889, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 30919, 31076, 518, 29914, 25580, 29962, 29871, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
inputs:
<s> [INST] <<SYS>>
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.
If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
<</SYS>>

你好 [/INST]  您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 233, 133, 171, 31076, 30214, 30672, 30392, 29902, 11222, 29899, 29896, 29889, 29900, 30214, 30287, 30502, 31272, 30988, 31605, 31030, 31615, 31026, 30910, 30210, 319, 29902, 29871, 31863, 31577, 236, 164, 193, 31658, 30214, 232, 193, 139, 30528, 31914, 31439, 235, 178, 137, 233, 133, 171, 30267, 31088, 31658, 30672, 30815, 30573, 233, 133, 171, 232, 132, 157, 31959, 231, 190, 131, 31882, 30882, 2]
labels:
<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> 您好，我是Ihin-1.0，一个由体素科技开发的 AI 健康顾问，很高兴认识您。请问我能为您做些什么？</s>
[INFO|trainer.py:1686] 2023-08-16 15:49:02,247 >> ***** Running training *****
[INFO|trainer.py:1687] 2023-08-16 15:49:02,247 >>   Num examples = 6,636
[INFO|trainer.py:1688] 2023-08-16 15:49:02,247 >>   Num Epochs = 200
[INFO|trainer.py:1689] 2023-08-16 15:49:02,247 >>   Instantaneous batch size per device = 4
[INFO|trainer.py:1692] 2023-08-16 15:49:02,247 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1693] 2023-08-16 15:49:02,247 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:1694] 2023-08-16 15:49:02,247 >>   Total optimization steps = 20,600
[INFO|trainer.py:1695] 2023-08-16 15:49:02,250 >>   Number of trainable parameters = 4,194,304
08/16/2023 15:49:02 - WARNING - llmtuner.extras.callbacks - Previous log file in this folder will be deleted.
  0%|          | 0/20600 [00:00<?, ?it/s]  0%|          | 1/20600 [00:08<48:29:34,  8.47s/it]  0%|          | 2/20600 [00:17<49:55:05,  8.72s/it]  0%|          | 3/20600 [00:24<45:58:40,  8.04s/it]  0%|          | 4/20600 [00:32<45:35:03,  7.97s/it]  0%|          | 5/20600 [00:42<49:15:19,  8.61s/it]  0%|          | 6/20600 [00:52<51:34:22,  9.02s/it]  0%|          | 7/20600 [01:01<52:48:40,  9.23s/it]  0%|          | 8/20600 [01:13<58:04:26, 10.15s/it]  0%|          | 9/20600 [01:25<61:12:20, 10.70s/it]  0%|          | 10/20600 [01:40<69:16:18, 12.11s/it]                                                     {'loss': 2.3524, 'learning_rate': 4.9999999709279735e-05, 'epoch': 0.1}
  0%|          | 10/20600 [01:40<69:16:18, 12.11s/it][INFO|trainer.py:3081] 2023-08-16 15:50:43,461 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 15:50:43,462 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 15:50:43,462 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                     
                                     [A{'eval_loss': 1.7725926637649536, 'eval_runtime': 2.9196, 'eval_samples_per_second': 2.398, 'eval_steps_per_second': 0.343, 'epoch': 0.1}
  0%|          | 10/20600 [01:43<69:16:18, 12.11s/it]
100%|██████████| 1/1 [00:01<00:00,  1.95s/it][A
                                             [A  0%|          | 11/20600 [01:58<78:49:12, 13.78s/it]  0%|          | 12/20600 [02:19<90:40:05, 15.85s/it]  0%|          | 13/20600 [02:33<88:42:30, 15.51s/it]  0%|          | 14/20600 [02:52<93:45:40, 16.40s/it]  0%|          | 15/20600 [03:11<98:29:44, 17.23s/it]  0%|          | 16/20600 [03:35<110:03:41, 19.25s/it]  0%|          | 17/20600 [03:53<107:50:56, 18.86s/it]  0%|          | 18/20600 [04:09<103:45:47, 18.15s/it]  0%|          | 19/20600 [04:31<110:13:04, 19.28s/it]  0%|          | 20/20600 [04:57<121:05:34, 21.18s/it]                                                      {'loss': 2.2084, 'learning_rate': 4.999999738351759e-05, 'epoch': 0.19}
  0%|          | 20/20600 [04:57<121:05:34, 21.18s/it][INFO|trainer.py:3081] 2023-08-16 15:53:59,865 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 15:53:59,865 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 15:53:59,865 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.7264268398284912, 'eval_runtime': 6.5477, 'eval_samples_per_second': 1.069, 'eval_steps_per_second': 0.153, 'epoch': 0.19}
  0%|          | 20/20600 [05:03<121:05:34, 21.18s/it]
100%|██████████| 1/1 [00:05<00:00,  5.62s/it][A
                                             [A  0%|          | 21/20600 [05:22<128:24:18, 22.46s/it]  0%|          | 22/20600 [05:48<133:46:13, 23.40s/it]  0%|          | 23/20600 [06:18<144:31:56, 25.29s/it]  0%|          | 24/20600 [06:43<144:34:33, 25.30s/it]  0%|          | 25/20600 [06:58<127:39:35, 22.34s/it]  0%|          | 26/20600 [07:21<128:16:09, 22.44s/it]  0%|          | 27/20600 [07:38<118:18:57, 20.70s/it]  0%|          | 28/20600 [08:01<122:04:46, 21.36s/it]  0%|          | 29/20600 [08:20<119:06:56, 20.85s/it]  0%|          | 30/20600 [08:41<119:15:41, 20.87s/it]                                                      {'loss': 2.3225, 'learning_rate': 4.999999534847578e-05, 'epoch': 0.29}
  0%|          | 30/20600 [08:41<119:15:41, 20.87s/it][INFO|trainer.py:3081] 2023-08-16 15:57:44,149 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 15:57:44,149 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 15:57:44,149 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.706523060798645, 'eval_runtime': 8.2816, 'eval_samples_per_second': 0.845, 'eval_steps_per_second': 0.121, 'epoch': 0.29}
  0%|          | 30/20600 [08:49<119:15:41, 20.87s/it]
100%|██████████| 1/1 [00:07<00:00,  7.29s/it][A
                                             [A  0%|          | 31/20600 [09:09<130:57:36, 22.92s/it]  0%|          | 32/20600 [09:27<123:34:41, 21.63s/it]  0%|          | 33/20600 [09:53<129:56:03, 22.74s/it]  0%|          | 34/20600 [10:18<133:50:26, 23.43s/it]  0%|          | 35/20600 [10:36<125:02:32, 21.89s/it]  0%|          | 36/20600 [10:53<117:00:26, 20.48s/it]  0%|          | 37/20600 [11:21<128:40:17, 22.53s/it]  0%|          | 38/20600 [11:47<135:27:36, 23.72s/it]  0%|          | 39/20600 [12:10<133:44:37, 23.42s/it]  0%|          | 40/20600 [12:37<139:46:50, 24.48s/it]                                                      {'loss': 2.8129, 'learning_rate': 4.999999534847578e-05, 'epoch': 0.39}
  0%|          | 40/20600 [12:37<139:46:50, 24.48s/it][INFO|trainer.py:3081] 2023-08-16 16:01:39,808 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:01:39,808 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:01:39,808 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.706523060798645, 'eval_runtime': 4.6787, 'eval_samples_per_second': 1.496, 'eval_steps_per_second': 0.214, 'epoch': 0.39}
  0%|          | 40/20600 [12:42<139:46:50, 24.48s/it]
100%|██████████| 1/1 [00:03<00:00,  3.77s/it][A
                                             [A  0%|          | 41/20600 [13:06<147:24:13, 25.81s/it]  0%|          | 42/20600 [13:28<140:40:18, 24.63s/it]  0%|          | 43/20600 [13:53<141:28:41, 24.78s/it]  0%|          | 44/20600 [14:16<139:33:31, 24.44s/it]  0%|          | 45/20600 [14:42<140:48:35, 24.66s/it]  0%|          | 46/20600 [15:05<138:15:43, 24.22s/it]  0%|          | 47/20600 [15:26<132:25:47, 23.20s/it]  0%|          | 48/20600 [15:54<141:26:56, 24.78s/it]  0%|          | 49/20600 [16:21<145:43:40, 25.53s/it]  0%|          | 50/20600 [16:44<141:22:09, 24.77s/it]                                                      {'loss': 2.1814, 'learning_rate': 4.999999534847578e-05, 'epoch': 0.48}
  0%|          | 50/20600 [16:44<141:22:09, 24.77s/it][INFO|trainer.py:3081] 2023-08-16 16:05:47,269 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:05:47,269 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:05:47,269 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.706523060798645, 'eval_runtime': 9.126, 'eval_samples_per_second': 0.767, 'eval_steps_per_second': 0.11, 'epoch': 0.48}
  0%|          | 50/20600 [16:53<141:22:09, 24.77s/it]
100%|██████████| 1/1 [00:08<00:00,  8.15s/it][A
                                             [A  0%|          | 51/20600 [17:15<151:28:59, 26.54s/it]  0%|          | 52/20600 [17:39<148:00:55, 25.93s/it]  0%|          | 53/20600 [18:04<145:28:35, 25.49s/it]  0%|          | 54/20600 [18:27<141:44:45, 24.84s/it]  0%|          | 55/20600 [18:52<141:18:18, 24.76s/it]  0%|          | 56/20600 [19:15<139:13:22, 24.40s/it]  0%|          | 57/20600 [19:31<123:27:43, 21.64s/it]  0%|          | 58/20600 [19:58<132:36:06, 23.24s/it]  0%|          | 59/20600 [20:19<129:24:02, 22.68s/it]  0%|          | 60/20600 [20:45<134:25:27, 23.56s/it]                                                      {'loss': 2.6025, 'learning_rate': 4.999999273199353e-05, 'epoch': 0.58}
  0%|          | 60/20600 [20:45<134:25:27, 23.56s/it][INFO|trainer.py:3081] 2023-08-16 16:09:47,523 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:09:47,523 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:09:47,523 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.6901772022247314, 'eval_runtime': 8.0171, 'eval_samples_per_second': 0.873, 'eval_steps_per_second': 0.125, 'epoch': 0.58}
  0%|          | 60/20600 [20:53<134:25:27, 23.56s/it]
100%|██████████| 1/1 [00:07<00:00,  7.06s/it][A
                                             [A  0%|          | 61/20600 [21:10<138:27:29, 24.27s/it]  0%|          | 62/20600 [21:40<147:22:09, 25.83s/it]  0%|          | 63/20600 [22:05<146:50:55, 25.74s/it]  0%|          | 64/20600 [22:29<143:21:30, 25.13s/it]  0%|          | 65/20600 [22:52<139:23:14, 24.44s/it]  0%|          | 66/20600 [23:13<132:58:13, 23.31s/it]  0%|          | 67/20600 [23:34<130:09:55, 22.82s/it]  0%|          | 68/20600 [23:56<128:27:30, 22.52s/it]  0%|          | 69/20600 [24:21<131:33:52, 23.07s/it]  0%|          | 70/20600 [24:40<124:58:30, 21.91s/it]                                                      {'loss': 2.1431, 'learning_rate': 4.999998953407091e-05, 'epoch': 0.67}
  0%|          | 70/20600 [24:40<124:58:30, 21.91s/it][INFO|trainer.py:3081] 2023-08-16 16:13:42,733 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:13:42,733 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:13:42,733 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.6768971681594849, 'eval_runtime': 9.0566, 'eval_samples_per_second': 0.773, 'eval_steps_per_second': 0.11, 'epoch': 0.67}
  0%|          | 70/20600 [24:49<124:58:30, 21.91s/it]
100%|██████████| 1/1 [00:08<00:00,  8.08s/it][A
                                             [A  0%|          | 71/20600 [25:19<154:07:13, 27.03s/it]  0%|          | 72/20600 [25:39<141:56:43, 24.89s/it]  0%|          | 73/20600 [26:00<135:07:32, 23.70s/it]  0%|          | 74/20600 [26:24<136:52:30, 24.01s/it]  0%|          | 75/20600 [26:53<144:34:38, 25.36s/it]  0%|          | 76/20600 [27:15<139:36:50, 24.49s/it]  0%|          | 77/20600 [27:37<134:23:49, 23.57s/it]  0%|          | 78/20600 [27:57<129:09:36, 22.66s/it]  0%|          | 79/20600 [28:23<134:24:45, 23.58s/it]  0%|          | 80/20600 [28:45<131:15:26, 23.03s/it]                                                      {'loss': 2.7879, 'learning_rate': 4.999998953407091e-05, 'epoch': 0.77}
  0%|          | 80/20600 [28:45<131:15:26, 23.03s/it][INFO|trainer.py:3081] 2023-08-16 16:17:47,643 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:17:47,643 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:17:47,643 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.6768971681594849, 'eval_runtime': 9.0533, 'eval_samples_per_second': 0.773, 'eval_steps_per_second': 0.11, 'epoch': 0.77}
  0%|          | 80/20600 [28:54<131:15:26, 23.03s/it]
100%|██████████| 1/1 [00:08<00:00,  8.15s/it][A
                                             [A  0%|          | 81/20600 [29:14<141:13:48, 24.78s/it]  0%|          | 82/20600 [29:35<135:52:09, 23.84s/it]  0%|          | 83/20600 [29:58<134:00:19, 23.51s/it]  0%|          | 84/20600 [30:19<130:30:20, 22.90s/it]  0%|          | 85/20600 [30:42<130:00:33, 22.81s/it]  0%|          | 86/20600 [31:06<131:42:55, 23.11s/it]  0%|          | 87/20600 [31:25<125:11:00, 21.97s/it]  0%|          | 88/20600 [31:52<133:32:20, 23.44s/it]  0%|          | 89/20600 [32:12<128:17:59, 22.52s/it]  0%|          | 90/20600 [32:44<144:21:05, 25.34s/it]                                                      {'loss': 2.5053, 'learning_rate': 4.999998575470798e-05, 'epoch': 0.87}
  0%|          | 90/20600 [32:44<144:21:05, 25.34s/it][INFO|trainer.py:3081] 2023-08-16 16:21:47,253 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:21:47,253 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:21:47,253 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                      
                                     [A{'eval_loss': 1.6663649082183838, 'eval_runtime': 7.3403, 'eval_samples_per_second': 0.954, 'eval_steps_per_second': 0.136, 'epoch': 0.87}
  0%|          | 90/20600 [32:52<144:21:05, 25.34s/it]
100%|██████████| 1/1 [00:06<00:00,  6.41s/it][A
                                             [A  0%|          | 91/20600 [33:13<149:59:59, 26.33s/it]  0%|          | 92/20600 [33:34<141:30:58, 24.84s/it]  0%|          | 93/20600 [33:59<141:30:50, 24.84s/it]  0%|          | 94/20600 [34:27<147:03:18, 25.82s/it]  0%|          | 95/20600 [34:43<129:53:51, 22.81s/it]  0%|          | 96/20600 [35:09<135:25:19, 23.78s/it]  0%|          | 97/20600 [35:38<144:03:42, 25.29s/it]  0%|          | 98/20600 [35:57<133:55:13, 23.52s/it]  0%|          | 99/20600 [36:15<124:39:12, 21.89s/it]  0%|          | 100/20600 [36:37<124:33:19, 21.87s/it]                                                       {'loss': 2.409, 'learning_rate': 4.999998139390484e-05, 'epoch': 0.96}
  0%|          | 100/20600 [36:37<124:33:19, 21.87s/it][INFO|trainer.py:3081] 2023-08-16 16:25:40,157 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:25:40,157 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:25:40,157 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6572701930999756, 'eval_runtime': 9.0577, 'eval_samples_per_second': 0.773, 'eval_steps_per_second': 0.11, 'epoch': 0.96}
  0%|          | 100/20600 [36:46<124:33:19, 21.87s/it]
100%|██████████| 1/1 [00:08<00:00,  8.09s/it][A
                                             [A  0%|          | 101/20600 [37:04<133:21:04, 23.42s/it]  0%|          | 102/20600 [37:27<131:56:36, 23.17s/it]  0%|          | 103/20600 [37:52<135:32:14, 23.81s/it]  1%|          | 104/20600 [38:11<127:00:10, 22.31s/it]  1%|          | 105/20600 [38:36<131:11:38, 23.04s/it]  1%|          | 106/20600 [38:58<130:41:35, 22.96s/it]  1%|          | 107/20600 [39:19<126:02:35, 22.14s/it]  1%|          | 108/20600 [39:43<130:03:21, 22.85s/it]  1%|          | 109/20600 [40:04<126:58:25, 22.31s/it]  1%|          | 110/20600 [40:23<121:36:26, 21.37s/it]                                                       {'loss': 2.5438, 'learning_rate': 4.999997645166159e-05, 'epoch': 1.06}
  1%|          | 110/20600 [40:23<121:36:26, 21.37s/it][INFO|trainer.py:3081] 2023-08-16 16:29:26,348 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:29:26,348 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:29:26,348 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6496258974075317, 'eval_runtime': 9.1946, 'eval_samples_per_second': 0.761, 'eval_steps_per_second': 0.109, 'epoch': 1.06}
  1%|          | 110/20600 [40:33<121:36:26, 21.37s/it]
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A
                                             [A  1%|          | 111/20600 [40:48<127:05:30, 22.33s/it]  1%|          | 112/20600 [41:14<133:58:35, 23.54s/it]  1%|          | 113/20600 [41:31<122:59:26, 21.61s/it]  1%|          | 114/20600 [41:52<121:00:07, 21.26s/it]  1%|          | 115/20600 [42:16<125:06:53, 21.99s/it]  1%|          | 116/20600 [42:36<122:26:18, 21.52s/it]  1%|          | 117/20600 [42:57<122:24:47, 21.51s/it]  1%|          | 118/20600 [43:20<124:52:52, 21.95s/it]  1%|          | 119/20600 [43:46<130:45:42, 22.98s/it]  1%|          | 120/20600 [44:13<137:06:20, 24.10s/it]                                                       {'loss': 2.1792, 'learning_rate': 4.999997092797834e-05, 'epoch': 1.16}
  1%|          | 120/20600 [44:13<137:06:20, 24.10s/it][INFO|trainer.py:3081] 2023-08-16 16:33:15,532 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:33:15,532 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:33:15,532 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6428242921829224, 'eval_runtime': 5.2738, 'eval_samples_per_second': 1.327, 'eval_steps_per_second': 0.19, 'epoch': 1.16}
  1%|          | 120/20600 [44:18<137:06:20, 24.10s/it]
100%|██████████| 1/1 [00:04<00:00,  4.30s/it][A
                                             [A  1%|          | 121/20600 [44:38<139:07:38, 24.46s/it]  1%|          | 122/20600 [44:57<130:50:15, 23.00s/it]  1%|          | 123/20600 [45:25<137:49:04, 24.23s/it]  1%|          | 124/20600 [45:44<129:30:57, 22.77s/it]  1%|          | 125/20600 [46:10<135:14:42, 23.78s/it]  1%|          | 126/20600 [46:32<132:57:08, 23.38s/it]  1%|          | 127/20600 [46:59<138:48:21, 24.41s/it]  1%|          | 128/20600 [47:27<143:45:37, 25.28s/it]  1%|          | 129/20600 [47:51<142:33:55, 25.07s/it]  1%|          | 130/20600 [48:12<135:26:19, 23.82s/it]                                                       {'loss': 2.6389, 'learning_rate': 4.999997092797834e-05, 'epoch': 1.25}
  1%|          | 130/20600 [48:12<135:26:19, 23.82s/it][INFO|trainer.py:3081] 2023-08-16 16:37:15,067 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:37:15,067 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:37:15,067 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6428242921829224, 'eval_runtime': 4.3496, 'eval_samples_per_second': 1.609, 'eval_steps_per_second': 0.23, 'epoch': 1.25}
  1%|          | 130/20600 [48:16<135:26:19, 23.82s/it]
100%|██████████| 1/1 [00:03<00:00,  3.47s/it][A
                                             [A  1%|          | 131/20600 [48:36<136:09:14, 23.95s/it]  1%|          | 132/20600 [48:57<131:20:15, 23.10s/it]  1%|          | 133/20600 [49:19<128:45:01, 22.65s/it]  1%|          | 134/20600 [49:46<135:47:41, 23.89s/it]  1%|          | 135/20600 [50:05<127:15:30, 22.39s/it]  1%|          | 136/20600 [50:28<128:57:54, 22.69s/it]  1%|          | 137/20600 [50:50<127:36:45, 22.45s/it]  1%|          | 138/20600 [51:11<125:46:39, 22.13s/it]  1%|          | 139/20600 [51:32<123:38:10, 21.75s/it]  1%|          | 140/20600 [51:57<128:42:45, 22.65s/it]                                                       {'loss': 2.4249, 'learning_rate': 4.999997092797834e-05, 'epoch': 1.35}
  1%|          | 140/20600 [51:57<128:42:45, 22.65s/it][INFO|trainer.py:3081] 2023-08-16 16:40:59,963 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:40:59,963 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:40:59,963 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6428242921829224, 'eval_runtime': 8.5375, 'eval_samples_per_second': 0.82, 'eval_steps_per_second': 0.117, 'epoch': 1.35}
  1%|          | 140/20600 [52:06<128:42:45, 22.65s/it]
100%|██████████| 1/1 [00:07<00:00,  7.63s/it][A
                                             [A  1%|          | 141/20600 [52:31<148:28:22, 26.13s/it]  1%|          | 142/20600 [52:52<139:54:55, 24.62s/it]  1%|          | 143/20600 [53:12<132:07:49, 23.25s/it]  1%|          | 144/20600 [53:41<141:48:34, 24.96s/it]  1%|          | 145/20600 [54:02<134:15:11, 23.63s/it]  1%|          | 146/20600 [54:26<135:43:03, 23.89s/it]  1%|          | 147/20600 [54:47<130:10:17, 22.91s/it]  1%|          | 148/20600 [55:05<122:24:41, 21.55s/it]  1%|          | 149/20600 [55:28<124:46:45, 21.96s/it]  1%|          | 150/20600 [55:51<125:53:07, 22.16s/it]                                                       {'loss': 3.384, 'learning_rate': 4.999997092797834e-05, 'epoch': 1.45}
  1%|          | 150/20600 [55:51<125:53:07, 22.16s/it][INFO|trainer.py:3081] 2023-08-16 16:44:53,883 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:44:53,883 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:44:53,883 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6428242921829224, 'eval_runtime': 4.1352, 'eval_samples_per_second': 1.693, 'eval_steps_per_second': 0.242, 'epoch': 1.45}
  1%|          | 150/20600 [55:55<125:53:07, 22.16s/it]
100%|██████████| 1/1 [00:03<00:00,  3.23s/it][A
                                             [A  1%|          | 151/20600 [56:18<134:12:18, 23.63s/it]  1%|          | 152/20600 [56:38<128:21:14, 22.60s/it]  1%|          | 153/20600 [57:04<133:31:20, 23.51s/it]  1%|          | 154/20600 [57:22<123:41:03, 21.78s/it]  1%|          | 155/20600 [57:47<129:29:56, 22.80s/it]  1%|          | 156/20600 [58:12<132:52:39, 23.40s/it]  1%|          | 157/20600 [58:32<128:16:27, 22.59s/it]  1%|          | 158/20600 [58:54<126:45:56, 22.32s/it]  1%|          | 159/20600 [59:21<135:01:26, 23.78s/it]  1%|          | 160/20600 [59:44<133:37:59, 23.54s/it]                                                       {'loss': 2.7423, 'learning_rate': 4.999997092797834e-05, 'epoch': 1.54}
  1%|          | 160/20600 [59:44<133:37:59, 23.54s/it][INFO|trainer.py:3081] 2023-08-16 16:48:47,035 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:48:47,035 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:48:47,035 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                       
                                     [A{'eval_loss': 1.6428242921829224, 'eval_runtime': 8.7667, 'eval_samples_per_second': 0.798, 'eval_steps_per_second': 0.114, 'epoch': 1.54}
  1%|          | 160/20600 [59:53<133:37:59, 23.54s/it]
100%|██████████| 1/1 [00:07<00:00,  7.83s/it][A
                                             [A  1%|          | 161/20600 [1:00:12<141:47:45, 24.98s/it]  1%|          | 162/20600 [1:00:35<138:18:01, 24.36s/it]  1%|          | 163/20600 [1:00:57<134:01:40, 23.61s/it]  1%|          | 164/20600 [1:01:16<126:42:14, 22.32s/it]  1%|          | 165/20600 [1:01:39<126:20:57, 22.26s/it]  1%|          | 166/20600 [1:01:59<123:43:04, 21.80s/it]  1%|          | 167/20600 [1:02:24<127:55:59, 22.54s/it]  1%|          | 168/20600 [1:02:40<118:10:21, 20.82s/it]  1%|          | 169/20600 [1:03:06<125:28:38, 22.11s/it]  1%|          | 170/20600 [1:03:28<125:43:45, 22.15s/it]                                                         {'loss': 3.0958, 'learning_rate': 4.999997092797834e-05, 'epoch': 1.64}
  1%|          | 170/20600 [1:03:28<125:43:45, 22.15s/it][INFO|trainer.py:3081] 2023-08-16 16:52:30,760 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:52:30,760 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:52:30,760 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': 1.6428242921829224, 'eval_runtime': 8.7705, 'eval_samples_per_second': 0.798, 'eval_steps_per_second': 0.114, 'epoch': 1.64}
  1%|          | 170/20600 [1:03:37<125:43:45, 22.15s/it]
100%|██████████| 1/1 [00:07<00:00,  7.81s/it][A
                                             [A  1%|          | 171/20600 [1:03:57<137:45:36, 24.28s/it]  1%|          | 172/20600 [1:04:24<141:47:53, 24.99s/it]  1%|          | 173/20600 [1:04:49<141:34:57, 24.95s/it]  1%|          | 174/20600 [1:05:02<122:21:57, 21.57s/it]  1%|          | 175/20600 [1:05:25<124:20:18, 21.92s/it]  1%|          | 176/20600 [1:05:43<117:23:30, 20.69s/it]  1%|          | 177/20600 [1:06:00<112:20:04, 19.80s/it]  1%|          | 178/20600 [1:06:15<104:05:09, 18.35s/it]  1%|          | 179/20600 [1:06:42<117:48:38, 20.77s/it]  1%|          | 180/20600 [1:07:09<128:34:54, 22.67s/it]                                                         {'loss': 31.8356, 'learning_rate': 4.999993458796712e-05, 'epoch': 1.73}
  1%|          | 180/20600 [1:07:09<128:34:54, 22.67s/it][INFO|trainer.py:3081] 2023-08-16 16:56:11,945 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:56:11,946 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:56:11,946 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1352, 'eval_samples_per_second': 1.693, 'eval_steps_per_second': 0.242, 'epoch': 1.73}
  1%|          | 180/20600 [1:07:13<128:34:54, 22.67s/it]
100%|██████████| 1/1 [00:03<00:00,  3.28s/it][A
                                             [A  1%|          | 181/20600 [1:07:42<145:59:51, 25.74s/it]  1%|          | 182/20600 [1:08:03<137:18:56, 24.21s/it]  1%|          | 183/20600 [1:08:26<135:20:25, 23.86s/it]  1%|          | 184/20600 [1:08:49<135:00:05, 23.81s/it]  1%|          | 185/20600 [1:09:13<135:44:56, 23.94s/it]  1%|          | 186/20600 [1:09:33<128:15:57, 22.62s/it]  1%|          | 187/20600 [1:09:57<130:38:39, 23.04s/it]  1%|          | 188/20600 [1:10:14<120:25:45, 21.24s/it]  1%|          | 189/20600 [1:10:31<113:39:54, 20.05s/it]  1%|          | 190/20600 [1:10:53<116:25:24, 20.54s/it]                                                         {'loss': 0.0, 'learning_rate': 4.999981830004953e-05, 'epoch': 1.83}
  1%|          | 190/20600 [1:10:53<116:25:24, 20.54s/it][INFO|trainer.py:3081] 2023-08-16 16:59:55,996 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 16:59:55,997 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 16:59:55,997 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.4109, 'eval_samples_per_second': 0.832, 'eval_steps_per_second': 0.119, 'epoch': 1.83}
  1%|          | 190/20600 [1:11:01<116:25:24, 20.54s/it]
100%|██████████| 1/1 [00:07<00:00,  7.52s/it][A
                                             [A  1%|          | 191/20600 [1:11:25<136:02:07, 24.00s/it]  1%|          | 192/20600 [1:11:44<127:53:34, 22.56s/it]  1%|          | 193/20600 [1:12:03<122:01:15, 21.53s/it]  1%|          | 194/20600 [1:12:23<118:02:59, 20.83s/it]  1%|          | 195/20600 [1:12:46<122:20:51, 21.59s/it]  1%|          | 196/20600 [1:13:01<110:59:05, 19.58s/it]  1%|          | 197/20600 [1:13:16<104:13:56, 18.39s/it]  1%|          | 198/20600 [1:13:41<114:06:33, 20.13s/it]  1%|          | 199/20600 [1:14:01<115:12:17, 20.33s/it]  1%|          | 200/20600 [1:14:20<111:51:03, 19.74s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9999643868511215e-05, 'epoch': 1.93}
  1%|          | 200/20600 [1:14:20<111:51:03, 19.74s/it][INFO|trainer.py:3081] 2023-08-16 17:03:22,805 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:03:22,805 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:03:22,805 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.1526, 'eval_samples_per_second': 0.859, 'eval_steps_per_second': 0.123, 'epoch': 1.93}
  1%|          | 200/20600 [1:14:28<111:51:03, 19.74s/it]
100%|██████████| 1/1 [00:07<00:00,  7.26s/it][A
                                             [A  1%|          | 201/20600 [1:14:44<119:35:42, 21.11s/it]  1%|          | 202/20600 [1:15:03<115:12:42, 20.33s/it]  1%|          | 203/20600 [1:15:17<105:30:11, 18.62s/it]  1%|          | 204/20600 [1:15:43<117:39:57, 20.77s/it]  1%|          | 205/20600 [1:15:59<109:40:04, 19.36s/it]  1%|          | 206/20600 [1:16:16<105:38:36, 18.65s/it]  1%|          | 207/20600 [1:16:40<114:27:09, 20.20s/it]  1%|          | 208/20600 [1:16:58<110:37:21, 19.53s/it]  1%|          | 209/20600 [1:17:13<103:16:16, 18.23s/it]  1%|          | 210/20600 [1:17:33<106:48:42, 18.86s/it]                                                         {'loss': 0.0, 'learning_rate': 4.999941129375787e-05, 'epoch': 2.02}
  1%|          | 210/20600 [1:17:33<106:48:42, 18.86s/it][INFO|trainer.py:3081] 2023-08-16 17:06:36,412 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:06:36,412 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:06:36,412 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0579, 'eval_samples_per_second': 1.725, 'eval_steps_per_second': 0.246, 'epoch': 2.02}
  1%|          | 210/20600 [1:17:38<106:48:42, 18.86s/it]
100%|██████████| 1/1 [00:03<00:00,  3.17s/it][A
                                             [A  1%|          | 211/20600 [1:18:03<124:56:03, 22.06s/it]  1%|          | 212/20600 [1:18:22<119:32:28, 21.11s/it]  1%|          | 213/20600 [1:18:48<127:25:33, 22.50s/it]  1%|          | 214/20600 [1:19:10<127:45:32, 22.56s/it]  1%|          | 215/20600 [1:19:26<115:33:31, 20.41s/it]  1%|          | 216/20600 [1:19:45<113:53:18, 20.11s/it]  1%|          | 217/20600 [1:20:04<111:03:30, 19.61s/it]  1%|          | 218/20600 [1:20:20<106:11:03, 18.75s/it]  1%|          | 219/20600 [1:20:37<102:33:54, 18.12s/it]  1%|          | 220/20600 [1:21:02<114:14:12, 20.18s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9999120576330394e-05, 'epoch': 2.12}
  1%|          | 220/20600 [1:21:02<114:14:12, 20.18s/it][INFO|trainer.py:3081] 2023-08-16 17:10:04,910 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:10:04,910 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:10:04,910 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4626, 'eval_samples_per_second': 2.022, 'eval_steps_per_second': 0.289, 'epoch': 2.12}
  1%|          | 220/20600 [1:21:05<114:14:12, 20.18s/it]
100%|██████████| 1/1 [00:02<00:00,  2.57s/it][A
                                             [A  1%|          | 221/20600 [1:21:21<112:36:34, 19.89s/it]  1%|          | 222/20600 [1:21:45<119:01:45, 21.03s/it]  1%|          | 223/20600 [1:22:04<115:07:51, 20.34s/it]  1%|          | 224/20600 [1:22:27<119:34:53, 21.13s/it]  1%|          | 225/20600 [1:22:50<122:59:59, 21.73s/it]  1%|          | 226/20600 [1:23:11<121:45:10, 21.51s/it]  1%|          | 227/20600 [1:23:31<120:04:24, 21.22s/it]  1%|          | 228/20600 [1:23:48<113:10:12, 20.00s/it]  1%|          | 229/20600 [1:24:06<109:23:26, 19.33s/it]  1%|          | 230/20600 [1:24:31<118:13:56, 20.90s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9998771716904936e-05, 'epoch': 2.22}
  1%|          | 230/20600 [1:24:31<118:13:56, 20.90s/it][INFO|trainer.py:3081] 2023-08-16 17:13:33,657 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:13:33,657 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:13:33,657 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.49, 'eval_samples_per_second': 1.079, 'eval_steps_per_second': 0.154, 'epoch': 2.22}
  1%|          | 230/20600 [1:24:37<118:13:56, 20.90s/it]
100%|██████████| 1/1 [00:05<00:00,  5.59s/it][A
                                             [A  1%|          | 231/20600 [1:24:58<129:15:14, 22.84s/it]  1%|          | 232/20600 [1:25:15<118:33:39, 20.96s/it]  1%|          | 233/20600 [1:25:32<113:10:11, 20.00s/it]  1%|          | 234/20600 [1:25:49<107:56:47, 19.08s/it]  1%|          | 235/20600 [1:26:08<107:14:09, 18.96s/it]  1%|          | 236/20600 [1:26:25<104:09:52, 18.41s/it]  1%|          | 237/20600 [1:26:42<101:52:46, 18.01s/it]  1%|          | 238/20600 [1:27:02<104:51:36, 18.54s/it]  1%|          | 239/20600 [1:27:22<107:40:03, 19.04s/it]  1%|          | 240/20600 [1:27:42<109:33:09, 19.37s/it]                                                         {'loss': 0.0, 'learning_rate': 4.999836471629286e-05, 'epoch': 2.31}
  1%|          | 240/20600 [1:27:42<109:33:09, 19.37s/it][INFO|trainer.py:3081] 2023-08-16 17:16:45,314 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:16:45,314 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:16:45,314 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.5163, 'eval_samples_per_second': 1.074, 'eval_steps_per_second': 0.153, 'epoch': 2.31}
  1%|          | 240/20600 [1:27:49<109:33:09, 19.37s/it]
100%|██████████| 1/1 [00:05<00:00,  5.64s/it][A
                                             [A  1%|          | 241/20600 [1:28:06<116:05:57, 20.53s/it]  1%|          | 242/20600 [1:28:31<124:54:31, 22.09s/it]  1%|          | 243/20600 [1:28:47<114:54:10, 20.32s/it]  1%|          | 244/20600 [1:29:06<112:18:17, 19.86s/it]  1%|          | 245/20600 [1:29:24<107:52:11, 19.08s/it]  1%|          | 246/20600 [1:29:40<103:37:16, 18.33s/it]  1%|          | 247/20600 [1:29:57<100:37:11, 17.80s/it]  1%|          | 248/20600 [1:30:12<96:23:06, 17.05s/it]   1%|          | 249/20600 [1:30:37<109:51:08, 19.43s/it]  1%|          | 250/20600 [1:30:55<108:01:18, 19.11s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9997899575440745e-05, 'epoch': 2.41}
  1%|          | 250/20600 [1:30:55<108:01:18, 19.11s/it][INFO|trainer.py:3081] 2023-08-16 17:19:58,297 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:19:58,298 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:19:58,298 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3657, 'eval_samples_per_second': 2.08, 'eval_steps_per_second': 0.297, 'epoch': 2.41}
  1%|          | 250/20600 [1:30:59<108:01:18, 19.11s/it]
100%|██████████| 1/1 [00:02<00:00,  2.51s/it][A
                                             [A  1%|          | 251/20600 [1:31:23<122:22:42, 21.65s/it]  1%|          | 252/20600 [1:31:46<123:58:55, 21.94s/it]  1%|          | 253/20600 [1:32:16<138:58:58, 24.59s/it]  1%|          | 254/20600 [1:32:43<142:14:10, 25.17s/it]  1%|          | 255/20600 [1:33:01<130:50:39, 23.15s/it]  1%|          | 256/20600 [1:33:24<129:34:31, 22.93s/it]  1%|          | 257/20600 [1:33:42<121:35:40, 21.52s/it]  1%|▏         | 258/20600 [1:34:08<129:26:36, 22.91s/it]  1%|▏         | 259/20600 [1:34:24<117:02:16, 20.71s/it]  1%|▏         | 260/20600 [1:34:40<109:38:06, 19.40s/it]                                                         {'loss': 0.0, 'learning_rate': 4.999737629543041e-05, 'epoch': 2.51}
  1%|▏         | 260/20600 [1:34:40<109:38:06, 19.40s/it][INFO|trainer.py:3081] 2023-08-16 17:23:43,166 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:23:43,166 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:23:43,166 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0963, 'eval_samples_per_second': 0.77, 'eval_steps_per_second': 0.11, 'epoch': 2.51}
  1%|▏         | 260/20600 [1:34:49<109:38:06, 19.40s/it]
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A
                                             [A  1%|▏         | 261/20600 [1:35:11<129:13:56, 22.87s/it]  1%|▏         | 262/20600 [1:35:29<121:19:48, 21.48s/it]  1%|▏         | 263/20600 [1:35:52<123:45:24, 21.91s/it]  1%|▏         | 264/20600 [1:36:14<123:02:35, 21.78s/it]  1%|▏         | 265/20600 [1:36:31<115:14:40, 20.40s/it]  1%|▏         | 266/20600 [1:36:57<125:40:43, 22.25s/it]  1%|▏         | 267/20600 [1:37:14<116:24:39, 20.61s/it]  1%|▏         | 268/20600 [1:37:36<118:31:47, 20.99s/it]  1%|▏         | 269/20600 [1:37:55<114:51:09, 20.34s/it]  1%|▏         | 270/20600 [1:38:16<115:32:59, 20.46s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9996794877478875e-05, 'epoch': 2.6}
  1%|▏         | 270/20600 [1:38:16<115:32:59, 20.46s/it][INFO|trainer.py:3081] 2023-08-16 17:27:18,509 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:27:18,509 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:27:18,509 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.7521, 'eval_samples_per_second': 1.037, 'eval_steps_per_second': 0.148, 'epoch': 2.6}
  1%|▏         | 270/20600 [1:38:22<115:32:59, 20.46s/it]
100%|██████████| 1/1 [00:05<00:00,  5.86s/it][A
                                             [A  1%|▏         | 271/20600 [1:38:36<114:47:06, 20.33s/it]  1%|▏         | 272/20600 [1:38:58<118:46:57, 21.04s/it]  1%|▏         | 273/20600 [1:39:20<119:56:05, 21.24s/it]  1%|▏         | 274/20600 [1:39:37<113:31:44, 20.11s/it]  1%|▏         | 275/20600 [1:40:00<118:32:44, 21.00s/it]  1%|▏         | 276/20600 [1:40:19<114:21:03, 20.26s/it]  1%|▏         | 277/20600 [1:40:45<124:27:23, 22.05s/it]  1%|▏         | 278/20600 [1:41:00<112:54:17, 20.00s/it]  1%|▏         | 279/20600 [1:41:30<128:16:31, 22.72s/it]  1%|▏         | 280/20600 [1:41:49<123:22:44, 21.86s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9996155322938376e-05, 'epoch': 2.7}
  1%|▏         | 280/20600 [1:41:49<123:22:44, 21.86s/it][INFO|trainer.py:3081] 2023-08-16 17:30:52,362 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:30:52,362 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:30:52,362 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0749, 'eval_samples_per_second': 0.771, 'eval_steps_per_second': 0.11, 'epoch': 2.7}
  1%|▏         | 280/20600 [1:41:58<123:22:44, 21.86s/it]
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A
                                             [A  1%|▏         | 281/20600 [1:42:19<136:03:50, 24.11s/it]  1%|▏         | 282/20600 [1:42:41<132:55:45, 23.55s/it]  1%|▏         | 283/20600 [1:43:00<124:32:00, 22.07s/it]  1%|▏         | 284/20600 [1:43:24<128:54:46, 22.84s/it]  1%|▏         | 285/20600 [1:43:46<127:24:45, 22.58s/it]  1%|▏         | 286/20600 [1:44:07<124:37:51, 22.09s/it]  1%|▏         | 287/20600 [1:44:29<123:52:04, 21.95s/it]  1%|▏         | 288/20600 [1:44:48<119:55:53, 21.26s/it]  1%|▏         | 289/20600 [1:45:08<116:27:37, 20.64s/it]  1%|▏         | 290/20600 [1:45:25<111:42:42, 19.80s/it]                                                         {'loss': 0.0, 'learning_rate': 4.999545763329636e-05, 'epoch': 2.8}
  1%|▏         | 290/20600 [1:45:25<111:42:42, 19.80s/it][INFO|trainer.py:3081] 2023-08-16 17:34:28,450 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:34:28,450 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:34:28,450 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.9257, 'eval_samples_per_second': 1.011, 'eval_steps_per_second': 0.144, 'epoch': 2.8}
  1%|▏         | 290/20600 [1:45:32<111:42:42, 19.80s/it]
100%|██████████| 1/1 [00:06<00:00,  6.03s/it][A
                                             [A  1%|▏         | 291/20600 [1:45:51<121:19:31, 21.51s/it]  1%|▏         | 292/20600 [1:46:08<113:45:44, 20.17s/it]  1%|▏         | 293/20600 [1:46:29<115:03:20, 20.40s/it]  1%|▏         | 294/20600 [1:46:46<109:44:49, 19.46s/it]  1%|▏         | 295/20600 [1:47:05<108:06:14, 19.17s/it]  1%|▏         | 296/20600 [1:47:22<105:00:41, 18.62s/it]  1%|▏         | 297/20600 [1:47:42<106:41:25, 18.92s/it]  1%|▏         | 298/20600 [1:48:01<107:57:05, 19.14s/it]  1%|▏         | 299/20600 [1:48:22<110:26:44, 19.59s/it]  1%|▏         | 300/20600 [1:48:40<107:42:03, 19.10s/it]                                                         {'loss': 0.0, 'learning_rate': 4.99947018101755e-05, 'epoch': 2.89}
  1%|▏         | 300/20600 [1:48:40<107:42:03, 19.10s/it][INFO|trainer.py:3081] 2023-08-16 17:37:42,869 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:37:42,870 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:37:42,870 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.7971, 'eval_samples_per_second': 1.459, 'eval_steps_per_second': 0.208, 'epoch': 2.89}
  1%|▏         | 300/20600 [1:48:45<107:42:03, 19.10s/it]
100%|██████████| 1/1 [00:03<00:00,  3.86s/it][A
                                             [A  1%|▏         | 301/20600 [1:49:08<122:13:49, 21.68s/it]  1%|▏         | 302/20600 [1:49:29<122:12:28, 21.67s/it]  1%|▏         | 303/20600 [1:49:49<118:22:42, 21.00s/it]  1%|▏         | 304/20600 [1:50:08<114:51:16, 20.37s/it]  1%|▏         | 305/20600 [1:50:26<111:10:49, 19.72s/it]  1%|▏         | 306/20600 [1:50:51<121:18:20, 21.52s/it]  1%|▏         | 307/20600 [1:51:12<118:50:48, 21.08s/it]  1%|▏         | 308/20600 [1:51:32<117:06:24, 20.78s/it]  2%|▏         | 309/20600 [1:51:54<119:34:19, 21.21s/it]  2%|▏         | 310/20600 [1:52:13<115:59:58, 20.58s/it]                                                         {'loss': 0.0, 'learning_rate': 4.999388785533365e-05, 'epoch': 2.99}
  2%|▏         | 310/20600 [1:52:13<115:59:58, 20.58s/it][INFO|trainer.py:3081] 2023-08-16 17:41:15,948 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:41:15,948 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:41:15,948 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 5.6918, 'eval_samples_per_second': 1.23, 'eval_steps_per_second': 0.176, 'epoch': 2.99}
  2%|▏         | 310/20600 [1:52:19<115:59:58, 20.58s/it]
100%|██████████| 1/1 [00:04<00:00,  4.80s/it][A
                                             [A  2%|▏         | 311/20600 [1:52:39<124:57:39, 22.17s/it]  2%|▏         | 312/20600 [1:52:56<117:01:57, 20.77s/it]  2%|▏         | 313/20600 [1:53:16<114:41:42, 20.35s/it]  2%|▏         | 314/20600 [1:53:33<109:25:18, 19.42s/it]  2%|▏         | 315/20600 [1:53:49<103:05:23, 18.30s/it]  2%|▏         | 316/20600 [1:54:06<102:00:28, 18.10s/it]  2%|▏         | 317/20600 [1:54:23<99:39:58, 17.69s/it]   2%|▏         | 318/20600 [1:54:46<108:34:39, 19.27s/it]  2%|▏         | 319/20600 [1:55:05<107:53:54, 19.15s/it]  2%|▏         | 320/20600 [1:55:24<107:11:09, 19.03s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9993015770663876e-05, 'epoch': 3.08}
  2%|▏         | 320/20600 [1:55:24<107:11:09, 19.03s/it][INFO|trainer.py:3081] 2023-08-16 17:44:26,570 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:44:26,570 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:44:26,570 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.0232, 'eval_samples_per_second': 0.872, 'eval_steps_per_second': 0.125, 'epoch': 3.08}
  2%|▏         | 320/20600 [1:55:32<107:11:09, 19.03s/it]
100%|██████████| 1/1 [00:07<00:00,  7.08s/it][A
                                             [A  2%|▏         | 321/20600 [1:55:57<132:18:03, 23.49s/it]  2%|▏         | 322/20600 [1:56:17<125:37:49, 22.30s/it]  2%|▏         | 323/20600 [1:56:33<115:44:09, 20.55s/it]  2%|▏         | 324/20600 [1:56:49<106:51:28, 18.97s/it]  2%|▏         | 325/20600 [1:57:07<105:52:17, 18.80s/it]  2%|▏         | 326/20600 [1:57:32<116:25:27, 20.67s/it]  2%|▏         | 327/20600 [1:57:49<109:05:51, 19.37s/it]  2%|▏         | 328/20600 [1:58:04<102:15:05, 18.16s/it]  2%|▏         | 329/20600 [1:58:28<112:27:11, 19.97s/it]  2%|▏         | 330/20600 [1:58:48<112:14:28, 19.93s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9992085558194446e-05, 'epoch': 3.18}
  2%|▏         | 330/20600 [1:58:48<112:14:28, 19.93s/it][INFO|trainer.py:3081] 2023-08-16 17:47:50,905 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:47:50,905 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:47:50,905 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9468, 'eval_samples_per_second': 1.774, 'eval_steps_per_second': 0.253, 'epoch': 3.18}
  2%|▏         | 330/20600 [1:58:52<112:14:28, 19.93s/it]
100%|██████████| 1/1 [00:03<00:00,  3.05s/it][A
                                             [A  2%|▏         | 331/20600 [1:59:10<115:31:59, 20.52s/it]  2%|▏         | 332/20600 [1:59:26<107:49:04, 19.15s/it]  2%|▏         | 333/20600 [1:59:54<123:16:46, 21.90s/it]  2%|▏         | 334/20600 [2:00:10<112:44:12, 20.03s/it]  2%|▏         | 335/20600 [2:00:33<118:04:03, 20.97s/it]  2%|▏         | 336/20600 [2:00:51<112:22:28, 19.96s/it]  2%|▏         | 337/20600 [2:01:10<112:05:37, 19.92s/it]  2%|▏         | 338/20600 [2:01:37<123:39:57, 21.97s/it]  2%|▏         | 339/20600 [2:01:57<119:38:22, 21.26s/it]  2%|▏         | 340/20600 [2:02:14<112:51:04, 20.05s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9991097220088814e-05, 'epoch': 3.28}
  2%|▏         | 340/20600 [2:02:14<112:51:04, 20.05s/it][INFO|trainer.py:3081] 2023-08-16 17:51:16,912 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:51:16,913 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:51:16,913 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 5.2417, 'eval_samples_per_second': 1.335, 'eval_steps_per_second': 0.191, 'epoch': 3.28}
  2%|▏         | 340/20600 [2:02:19<112:51:04, 20.05s/it]
100%|██████████| 1/1 [00:04<00:00,  4.33s/it][A
                                             [A  2%|▏         | 341/20600 [2:02:34<112:41:49, 20.03s/it]  2%|▏         | 342/20600 [2:02:49<104:46:37, 18.62s/it]  2%|▏         | 343/20600 [2:03:07<104:08:16, 18.51s/it]  2%|▏         | 344/20600 [2:03:24<100:11:21, 17.81s/it]  2%|▏         | 345/20600 [2:03:42<101:53:48, 18.11s/it]  2%|▏         | 346/20600 [2:04:01<102:17:40, 18.18s/it]  2%|▏         | 347/20600 [2:04:28<117:26:07, 20.87s/it]  2%|▏         | 348/20600 [2:04:48<116:39:42, 20.74s/it]  2%|▏         | 349/20600 [2:05:13<123:04:40, 21.88s/it]  2%|▏         | 350/20600 [2:05:30<114:49:06, 20.41s/it]                                                         {'loss': 0.0, 'learning_rate': 4.99900507586456e-05, 'epoch': 3.37}
  2%|▏         | 350/20600 [2:05:30<114:49:06, 20.41s/it][INFO|trainer.py:3081] 2023-08-16 17:54:32,905 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:54:32,905 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:54:32,905 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9425, 'eval_samples_per_second': 1.776, 'eval_steps_per_second': 0.254, 'epoch': 3.37}
  2%|▏         | 350/20600 [2:05:34<114:49:06, 20.41s/it]
100%|██████████| 1/1 [00:03<00:00,  3.03s/it][A
                                             [A  2%|▏         | 351/20600 [2:05:50<113:24:05, 20.16s/it]  2%|▏         | 352/20600 [2:06:13<118:35:30, 21.09s/it]  2%|▏         | 353/20600 [2:06:37<124:22:58, 22.12s/it]  2%|▏         | 354/20600 [2:06:54<114:43:17, 20.40s/it]  2%|▏         | 355/20600 [2:07:12<111:45:50, 19.87s/it]  2%|▏         | 356/20600 [2:07:41<126:54:42, 22.57s/it]  2%|▏         | 357/20600 [2:07:59<118:08:26, 21.01s/it]  2%|▏         | 358/20600 [2:08:23<124:23:00, 22.12s/it]  2%|▏         | 359/20600 [2:08:47<126:41:46, 22.53s/it]  2%|▏         | 360/20600 [2:09:07<123:14:36, 21.92s/it]                                                         {'loss': 0.0, 'learning_rate': 4.998894617629864e-05, 'epoch': 3.47}
  2%|▏         | 360/20600 [2:09:07<123:14:36, 21.92s/it][INFO|trainer.py:3081] 2023-08-16 17:58:10,215 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 17:58:10,215 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 17:58:10,215 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4796, 'eval_samples_per_second': 2.012, 'eval_steps_per_second': 0.287, 'epoch': 3.47}
  2%|▏         | 360/20600 [2:09:11<123:14:36, 21.92s/it]
100%|██████████| 1/1 [00:02<00:00,  2.61s/it][A
                                             [A  2%|▏         | 361/20600 [2:09:40<141:34:53, 25.18s/it]  2%|▏         | 362/20600 [2:09:58<129:54:38, 23.11s/it]  2%|▏         | 363/20600 [2:10:22<130:41:25, 23.25s/it]  2%|▏         | 364/20600 [2:10:38<118:08:14, 21.02s/it]  2%|▏         | 365/20600 [2:10:58<117:46:58, 20.95s/it]  2%|▏         | 366/20600 [2:11:17<113:03:37, 20.12s/it]  2%|▏         | 367/20600 [2:11:36<111:25:15, 19.82s/it]  2%|▏         | 368/20600 [2:11:57<114:18:34, 20.34s/it]  2%|▏         | 369/20600 [2:12:14<108:24:28, 19.29s/it]  2%|▏         | 370/20600 [2:12:36<112:56:16, 20.10s/it]                                                         {'loss': 0.0, 'learning_rate': 4.998778347561693e-05, 'epoch': 3.57}
  2%|▏         | 370/20600 [2:12:36<112:56:16, 20.10s/it][INFO|trainer.py:3081] 2023-08-16 18:01:39,147 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:01:39,147 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:01:39,148 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.1286, 'eval_samples_per_second': 1.142, 'eval_steps_per_second': 0.163, 'epoch': 3.57}
  2%|▏         | 370/20600 [2:12:42<112:56:16, 20.10s/it]
100%|██████████| 1/1 [00:05<00:00,  5.21s/it][A
                                             [A  2%|▏         | 371/20600 [2:12:56<112:17:25, 19.98s/it]  2%|▏         | 372/20600 [2:13:21<120:15:33, 21.40s/it]  2%|▏         | 373/20600 [2:13:42<120:05:25, 21.37s/it]  2%|▏         | 374/20600 [2:13:59<112:47:14, 20.07s/it]  2%|▏         | 375/20600 [2:14:24<121:14:37, 21.58s/it]  2%|▏         | 376/20600 [2:14:42<115:28:38, 20.56s/it]  2%|▏         | 377/20600 [2:15:07<123:04:11, 21.91s/it]  2%|▏         | 378/20600 [2:15:28<121:09:33, 21.57s/it]  2%|▏         | 379/20600 [2:15:46<114:41:26, 20.42s/it]  2%|▏         | 380/20600 [2:16:10<121:42:16, 21.67s/it]                                                         {'loss': 0.0, 'learning_rate': 4.998656265930464e-05, 'epoch': 3.66}
  2%|▏         | 380/20600 [2:16:10<121:42:16, 21.67s/it][INFO|trainer.py:3081] 2023-08-16 18:05:13,347 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:05:13,347 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:05:13,347 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.8683, 'eval_samples_per_second': 0.89, 'eval_steps_per_second': 0.127, 'epoch': 3.66}
  2%|▏         | 380/20600 [2:16:18<121:42:16, 21.67s/it]
100%|██████████| 1/1 [00:07<00:00,  7.01s/it][A
                                             [A  2%|▏         | 381/20600 [2:16:37<130:20:04, 23.21s/it]  2%|▏         | 382/20600 [2:16:54<119:54:15, 21.35s/it]  2%|▏         | 383/20600 [2:17:14<116:40:26, 20.78s/it]  2%|▏         | 384/20600 [2:17:32<112:53:24, 20.10s/it]  2%|▏         | 385/20600 [2:17:55<117:27:56, 20.92s/it]  2%|▏         | 386/20600 [2:18:18<121:35:16, 21.65s/it]  2%|▏         | 387/20600 [2:18:39<120:15:21, 21.42s/it]  2%|▏         | 388/20600 [2:19:00<119:24:07, 21.27s/it]  2%|▏         | 389/20600 [2:19:21<119:18:54, 21.25s/it]  2%|▏         | 390/20600 [2:19:41<116:05:31, 20.68s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9985283730201074e-05, 'epoch': 3.76}
  2%|▏         | 390/20600 [2:19:41<116:05:31, 20.68s/it][INFO|trainer.py:3081] 2023-08-16 18:08:43,660 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:08:43,661 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:08:43,661 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.4133, 'eval_samples_per_second': 0.832, 'eval_steps_per_second': 0.119, 'epoch': 3.76}
  2%|▏         | 390/20600 [2:19:49<116:05:31, 20.68s/it]
100%|██████████| 1/1 [00:07<00:00,  7.57s/it][A
                                             [A  2%|▏         | 391/20600 [2:20:09<128:44:40, 22.93s/it]  2%|▏         | 392/20600 [2:20:25<117:07:30, 20.87s/it]  2%|▏         | 393/20600 [2:20:51<126:13:53, 22.49s/it]  2%|▏         | 394/20600 [2:21:13<125:01:26, 22.27s/it]  2%|▏         | 395/20600 [2:21:36<125:58:46, 22.45s/it]  2%|▏         | 396/20600 [2:21:52<115:51:00, 20.64s/it]  2%|▏         | 397/20600 [2:22:11<112:28:47, 20.04s/it]  2%|▏         | 398/20600 [2:22:30<110:58:35, 19.78s/it]  2%|▏         | 399/20600 [2:22:49<109:13:47, 19.47s/it]  2%|▏         | 400/20600 [2:23:11<113:32:08, 20.23s/it]                                                         {'loss': 0.0, 'learning_rate': 4.998394669128074e-05, 'epoch': 3.86}
  2%|▏         | 400/20600 [2:23:11<113:32:08, 20.23s/it][INFO|trainer.py:3081] 2023-08-16 18:12:13,794 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:12:13,794 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:12:13,794 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3662, 'eval_samples_per_second': 0.837, 'eval_steps_per_second': 0.12, 'epoch': 3.86}
  2%|▏         | 400/20600 [2:23:19<113:32:08, 20.23s/it]
100%|██████████| 1/1 [00:07<00:00,  7.48s/it][A
                                             [A  2%|▏         | 401/20600 [2:23:43<133:36:55, 23.81s/it]  2%|▏         | 402/20600 [2:24:03<127:24:16, 22.71s/it]  2%|▏         | 403/20600 [2:24:21<119:27:52, 21.29s/it]  2%|▏         | 404/20600 [2:24:40<115:38:41, 20.61s/it]  2%|▏         | 405/20600 [2:24:58<111:26:21, 19.87s/it]  2%|▏         | 406/20600 [2:25:17<110:09:15, 19.64s/it]  2%|▏         | 407/20600 [2:25:35<106:54:49, 19.06s/it]  2%|▏         | 408/20600 [2:25:52<104:02:31, 18.55s/it]  2%|▏         | 409/20600 [2:26:11<103:51:10, 18.52s/it]  2%|▏         | 410/20600 [2:26:39<119:39:43, 21.34s/it]                                                         {'loss': 0.0, 'learning_rate': 4.998255154565326e-05, 'epoch': 3.95}
  2%|▏         | 410/20600 [2:26:39<119:39:43, 21.34s/it][INFO|trainer.py:3081] 2023-08-16 18:15:41,767 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:15:41,767 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:15:41,767 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 5.8067, 'eval_samples_per_second': 1.205, 'eval_steps_per_second': 0.172, 'epoch': 3.95}
  2%|▏         | 410/20600 [2:26:45<119:39:43, 21.34s/it]
100%|██████████| 1/1 [00:04<00:00,  4.93s/it][A
                                             [A  2%|▏         | 411/20600 [2:27:04<125:47:13, 22.43s/it]  2%|▏         | 412/20600 [2:27:25<124:05:14, 22.13s/it]  2%|▏         | 413/20600 [2:27:41<112:49:29, 20.12s/it]  2%|▏         | 414/20600 [2:28:02<114:17:36, 20.38s/it]  2%|▏         | 415/20600 [2:28:20<111:26:58, 19.88s/it]  2%|▏         | 416/20600 [2:28:39<109:50:01, 19.59s/it]  2%|▏         | 417/20600 [2:29:14<135:06:09, 24.10s/it]  2%|▏         | 418/20600 [2:29:34<127:39:02, 22.77s/it]  2%|▏         | 419/20600 [2:29:55<125:56:07, 22.47s/it]  2%|▏         | 420/20600 [2:30:15<120:29:25, 21.49s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9981098296563415e-05, 'epoch': 4.05}
  2%|▏         | 420/20600 [2:30:15<120:29:25, 21.49s/it][INFO|trainer.py:3081] 2023-08-16 18:19:17,488 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:19:17,488 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:19:17,488 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0093, 'eval_samples_per_second': 1.746, 'eval_steps_per_second': 0.249, 'epoch': 4.05}
  2%|▏         | 420/20600 [2:30:19<120:29:25, 21.49s/it]
100%|██████████| 1/1 [00:03<00:00,  3.14s/it][A
                                             [A  2%|▏         | 421/20600 [2:30:38<124:32:59, 22.22s/it]  2%|▏         | 422/20600 [2:30:57<118:05:50, 21.07s/it]  2%|▏         | 423/20600 [2:31:18<118:40:59, 21.18s/it]  2%|▏         | 424/20600 [2:31:36<113:45:57, 20.30s/it]  2%|▏         | 425/20600 [2:31:53<108:08:51, 19.30s/it]  2%|▏         | 426/20600 [2:32:08<100:05:09, 17.86s/it]  2%|▏         | 427/20600 [2:32:32<110:37:59, 19.74s/it]  2%|▏         | 428/20600 [2:32:46<100:54:41, 18.01s/it]  2%|▏         | 429/20600 [2:33:03<98:51:19, 17.64s/it]   2%|▏         | 430/20600 [2:33:18<93:59:46, 16.78s/it]                                                        {'loss': 0.0, 'learning_rate': 4.997958694739112e-05, 'epoch': 4.14}
  2%|▏         | 430/20600 [2:33:18<93:59:46, 16.78s/it][INFO|trainer.py:3081] 2023-08-16 18:22:20,572 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:22:20,572 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:22:20,572 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                        
                                     [A{'eval_loss': nan, 'eval_runtime': 3.67, 'eval_samples_per_second': 1.907, 'eval_steps_per_second': 0.272, 'epoch': 4.14}
  2%|▏         | 430/20600 [2:33:21<93:59:46, 16.78s/it]
100%|██████████| 1/1 [00:02<00:00,  2.77s/it][A
                                             [A  2%|▏         | 431/20600 [2:33:47<114:47:31, 20.49s/it]  2%|▏         | 432/20600 [2:34:03<107:32:56, 19.20s/it]  2%|▏         | 433/20600 [2:34:19<102:43:09, 18.34s/it]  2%|▏         | 434/20600 [2:34:37<102:32:46, 18.31s/it]  2%|▏         | 435/20600 [2:34:58<106:34:02, 19.03s/it]  2%|▏         | 436/20600 [2:35:21<113:38:37, 20.29s/it]  2%|▏         | 437/20600 [2:35:36<104:41:10, 18.69s/it]  2%|▏         | 438/20600 [2:35:52<99:06:10, 17.70s/it]   2%|▏         | 439/20600 [2:36:12<103:36:10, 18.50s/it]  2%|▏         | 440/20600 [2:36:30<102:00:41, 18.22s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9978017501651395e-05, 'epoch': 4.24}
  2%|▏         | 440/20600 [2:36:30<102:00:41, 18.22s/it][INFO|trainer.py:3081] 2023-08-16 18:25:32,684 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:25:32,684 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:25:32,684 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 5.1986, 'eval_samples_per_second': 1.347, 'eval_steps_per_second': 0.192, 'epoch': 4.24}
  2%|▏         | 440/20600 [2:36:35<102:00:41, 18.22s/it]
100%|██████████| 1/1 [00:04<00:00,  4.28s/it][A
                                             [A  2%|▏         | 441/20600 [2:36:52<109:38:54, 19.58s/it]  2%|▏         | 442/20600 [2:37:15<113:49:23, 20.33s/it]  2%|▏         | 443/20600 [2:37:34<112:29:09, 20.09s/it]  2%|▏         | 444/20600 [2:37:55<113:28:20, 20.27s/it]  2%|▏         | 445/20600 [2:38:14<111:12:58, 19.86s/it]  2%|▏         | 446/20600 [2:38:32<107:53:20, 19.27s/it]  2%|▏         | 447/20600 [2:38:50<106:10:49, 18.97s/it]  2%|▏         | 448/20600 [2:39:19<123:08:15, 22.00s/it]  2%|▏         | 449/20600 [2:39:35<113:44:13, 20.32s/it]  2%|▏         | 450/20600 [2:40:03<125:59:49, 22.51s/it]                                                         {'loss': 0.0, 'learning_rate': 4.997638996299442e-05, 'epoch': 4.34}
  2%|▏         | 450/20600 [2:40:03<125:59:49, 22.51s/it][INFO|trainer.py:3081] 2023-08-16 18:29:05,896 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:29:05,896 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:29:05,896 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.5229, 'eval_samples_per_second': 1.548, 'eval_steps_per_second': 0.221, 'epoch': 4.34}
  2%|▏         | 450/20600 [2:40:07<125:59:49, 22.51s/it]
100%|██████████| 1/1 [00:03<00:00,  3.66s/it][A
                                             [A  2%|▏         | 451/20600 [2:40:23<121:12:59, 21.66s/it]  2%|▏         | 452/20600 [2:40:37<108:57:29, 19.47s/it]  2%|▏         | 453/20600 [2:40:57<110:36:41, 19.76s/it]  2%|▏         | 454/20600 [2:41:14<104:57:30, 18.76s/it]  2%|▏         | 455/20600 [2:41:31<102:57:39, 18.40s/it]  2%|▏         | 456/20600 [2:41:50<103:58:03, 18.58s/it]  2%|▏         | 457/20600 [2:42:13<111:05:12, 19.85s/it]  2%|▏         | 458/20600 [2:42:30<105:24:57, 18.84s/it]  2%|▏         | 459/20600 [2:42:52<111:06:54, 19.86s/it]  2%|▏         | 460/20600 [2:43:15<115:59:08, 20.73s/it]                                                         {'loss': 0.0, 'learning_rate': 4.997470433520546e-05, 'epoch': 4.43}
  2%|▏         | 460/20600 [2:43:15<115:59:08, 20.73s/it][INFO|trainer.py:3081] 2023-08-16 18:32:17,660 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:32:17,660 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:32:17,660 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4023, 'eval_samples_per_second': 2.057, 'eval_steps_per_second': 0.294, 'epoch': 4.43}
  2%|▏         | 460/20600 [2:43:18<115:59:08, 20.73s/it]
100%|██████████| 1/1 [00:02<00:00,  2.55s/it][A
                                             [A  2%|▏         | 461/20600 [2:43:44<130:09:40, 23.27s/it]  2%|▏         | 462/20600 [2:44:03<123:25:08, 22.06s/it]  2%|▏         | 463/20600 [2:44:22<118:36:10, 21.20s/it]  2%|▏         | 464/20600 [2:44:39<111:48:34, 19.99s/it]  2%|▏         | 465/20600 [2:45:09<127:40:03, 22.83s/it]  2%|▏         | 466/20600 [2:45:34<131:59:45, 23.60s/it]  2%|▏         | 467/20600 [2:45:52<121:37:43, 21.75s/it]  2%|▏         | 468/20600 [2:46:10<116:04:40, 20.76s/it]  2%|▏         | 469/20600 [2:46:39<128:52:54, 23.05s/it]  2%|▏         | 470/20600 [2:46:56<119:03:05, 21.29s/it]                                                         {'loss': 0.0, 'learning_rate': 4.997296062220486e-05, 'epoch': 4.53}
  2%|▏         | 470/20600 [2:46:56<119:03:05, 21.29s/it][INFO|trainer.py:3081] 2023-08-16 18:35:58,766 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:35:58,767 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:35:58,767 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.7857, 'eval_samples_per_second': 0.797, 'eval_steps_per_second': 0.114, 'epoch': 4.53}
  2%|▏         | 470/20600 [2:47:05<119:03:05, 21.29s/it]
100%|██████████| 1/1 [00:07<00:00,  7.89s/it][A
                                             [A  2%|▏         | 471/20600 [2:47:21<126:14:45, 22.58s/it]  2%|▏         | 472/20600 [2:47:38<116:29:14, 20.83s/it]  2%|▏         | 473/20600 [2:48:04<124:07:01, 22.20s/it]  2%|▏         | 474/20600 [2:48:22<117:38:34, 21.04s/it]  2%|▏         | 475/20600 [2:48:40<113:07:22, 20.24s/it]  2%|▏         | 476/20600 [2:49:01<113:16:28, 20.26s/it]  2%|▏         | 477/20600 [2:49:19<109:55:47, 19.67s/it]  2%|▏         | 478/20600 [2:49:40<112:32:50, 20.14s/it]  2%|▏         | 479/20600 [2:50:03<117:40:31, 21.05s/it]  2%|▏         | 480/20600 [2:50:19<109:26:01, 19.58s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9971158828048105e-05, 'epoch': 4.63}
  2%|▏         | 480/20600 [2:50:19<109:26:01, 19.58s/it][INFO|trainer.py:3081] 2023-08-16 18:39:22,364 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:39:22,364 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:39:22,364 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9211, 'eval_samples_per_second': 1.785, 'eval_steps_per_second': 0.255, 'epoch': 4.63}
  2%|▏         | 480/20600 [2:50:23<109:26:01, 19.58s/it]
100%|██████████| 1/1 [00:03<00:00,  3.03s/it][A
                                             [A  2%|▏         | 481/20600 [2:50:41<112:11:53, 20.08s/it]  2%|▏         | 482/20600 [2:51:00<111:23:14, 19.93s/it]  2%|▏         | 483/20600 [2:51:25<119:20:02, 21.36s/it]  2%|▏         | 484/20600 [2:51:47<120:28:55, 21.56s/it]  2%|▏         | 485/20600 [2:52:04<112:06:13, 20.06s/it]  2%|▏         | 486/20600 [2:52:29<121:08:48, 21.68s/it]  2%|▏         | 487/20600 [2:52:46<114:10:10, 20.44s/it]  2%|▏         | 488/20600 [2:53:08<115:09:34, 20.61s/it]  2%|▏         | 489/20600 [2:53:25<110:30:59, 19.78s/it]  2%|▏         | 490/20600 [2:53:45<110:12:15, 19.73s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9969298956925725e-05, 'epoch': 4.72}
  2%|▏         | 490/20600 [2:53:45<110:12:15, 19.73s/it][INFO|trainer.py:3081] 2023-08-16 18:42:47,936 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:42:47,936 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:42:47,936 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0125, 'eval_samples_per_second': 1.745, 'eval_steps_per_second': 0.249, 'epoch': 4.72}
  2%|▏         | 490/20600 [2:53:49<110:12:15, 19.73s/it]
100%|██████████| 1/1 [00:03<00:00,  3.09s/it][A
                                             [A  2%|▏         | 491/20600 [2:54:05<110:53:29, 19.85s/it]  2%|▏         | 492/20600 [2:54:23<107:58:34, 19.33s/it]  2%|▏         | 493/20600 [2:54:44<110:17:52, 19.75s/it]  2%|▏         | 494/20600 [2:55:11<121:43:56, 21.80s/it]  2%|▏         | 495/20600 [2:55:29<116:01:14, 20.77s/it]  2%|▏         | 496/20600 [2:55:59<131:29:57, 23.55s/it]  2%|▏         | 497/20600 [2:56:20<126:56:38, 22.73s/it]  2%|▏         | 498/20600 [2:56:37<117:25:05, 21.03s/it]  2%|▏         | 499/20600 [2:57:02<124:00:50, 22.21s/it]  2%|▏         | 500/20600 [2:57:20<117:50:44, 21.11s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9967381013163346e-05, 'epoch': 4.82}
  2%|▏         | 500/20600 [2:57:20<117:50:44, 21.11s/it][INFO|trainer.py:3081] 2023-08-16 18:46:23,284 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:46:23,284 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:46:23,285 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.157, 'eval_samples_per_second': 1.684, 'eval_steps_per_second': 0.241, 'epoch': 4.82}
  2%|▏         | 500/20600 [2:57:24<117:50:44, 21.11s/it]
100%|██████████| 1/1 [00:03<00:00,  3.25s/it][A
                                             [A  2%|▏         | 501/20600 [2:57:47<126:23:08, 22.64s/it]  2%|▏         | 502/20600 [2:58:10<127:25:40, 22.83s/it]  2%|▏         | 503/20600 [2:58:29<121:30:27, 21.77s/it]  2%|▏         | 504/20600 [2:58:55<128:21:25, 22.99s/it]  2%|▏         | 505/20600 [2:59:12<117:48:18, 21.10s/it]  2%|▏         | 506/20600 [2:59:28<110:08:51, 19.73s/it]  2%|▏         | 507/20600 [2:59:46<107:18:01, 19.22s/it]  2%|▏         | 508/20600 [3:00:03<103:27:45, 18.54s/it]  2%|▏         | 509/20600 [3:00:26<110:42:47, 19.84s/it]  2%|▏         | 510/20600 [3:00:46<111:12:29, 19.93s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9965405001221647e-05, 'epoch': 4.92}
  2%|▏         | 510/20600 [3:00:46<111:12:29, 19.93s/it][INFO|trainer.py:3081] 2023-08-16 18:49:49,122 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:49:49,122 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:49:49,122 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.3565, 'eval_samples_per_second': 1.607, 'eval_steps_per_second': 0.23, 'epoch': 4.92}
  2%|▏         | 510/20600 [3:00:51<111:12:29, 19.93s/it]
100%|██████████| 1/1 [00:03<00:00,  3.48s/it][A
                                             [A  2%|▏         | 511/20600 [3:01:08<113:36:40, 20.36s/it]  2%|▏         | 512/20600 [3:01:25<109:08:51, 19.56s/it]  2%|▏         | 513/20600 [3:01:44<107:16:24, 19.23s/it]  2%|▏         | 514/20600 [3:02:06<112:34:52, 20.18s/it]  2%|▎         | 515/20600 [3:02:23<107:46:37, 19.32s/it]  3%|▎         | 516/20600 [3:02:42<106:52:24, 19.16s/it]  3%|▎         | 517/20600 [3:03:05<113:52:29, 20.41s/it]  3%|▎         | 518/20600 [3:03:26<113:46:58, 20.40s/it]  3%|▎         | 519/20600 [3:03:50<120:37:50, 21.63s/it]  3%|▎         | 520/20600 [3:04:12<121:05:18, 21.71s/it]                                                         {'loss': 0.0, 'learning_rate': 4.996337092569635e-05, 'epoch': 5.01}
  3%|▎         | 520/20600 [3:04:12<121:05:18, 21.71s/it][INFO|trainer.py:3081] 2023-08-16 18:53:15,218 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:53:15,218 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:53:15,218 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 5.4578, 'eval_samples_per_second': 1.283, 'eval_steps_per_second': 0.183, 'epoch': 5.01}
  3%|▎         | 520/20600 [3:04:18<121:05:18, 21.71s/it]
100%|██████████| 1/1 [00:04<00:00,  4.58s/it][A
                                             [A  3%|▎         | 521/20600 [3:04:35<123:28:07, 22.14s/it]  3%|▎         | 522/20600 [3:04:58<124:31:18, 22.33s/it]  3%|▎         | 523/20600 [3:05:17<117:56:44, 21.15s/it]  3%|▎         | 524/20600 [3:05:35<113:25:38, 20.34s/it]  3%|▎         | 525/20600 [3:05:53<109:19:37, 19.61s/it]  3%|▎         | 526/20600 [3:06:10<105:38:53, 18.95s/it]  3%|▎         | 527/20600 [3:06:29<104:51:55, 18.81s/it]  3%|▎         | 528/20600 [3:06:50<109:03:26, 19.56s/it]  3%|▎         | 529/20600 [3:07:10<109:16:56, 19.60s/it]  3%|▎         | 530/20600 [3:07:29<108:06:08, 19.39s/it]                                                         {'loss': 0.0, 'learning_rate': 4.996127879131824e-05, 'epoch': 5.11}
  3%|▎         | 530/20600 [3:07:29<108:06:08, 19.39s/it][INFO|trainer.py:3081] 2023-08-16 18:56:31,671 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:56:31,671 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:56:31,671 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.142, 'eval_samples_per_second': 0.98, 'eval_steps_per_second': 0.14, 'epoch': 5.11}
  3%|▎         | 530/20600 [3:07:36<108:06:08, 19.39s/it]
100%|██████████| 1/1 [00:06<00:00,  6.27s/it][A
                                             [A  3%|▎         | 531/20600 [3:07:49<110:16:02, 19.78s/it]  3%|▎         | 532/20600 [3:08:08<108:15:34, 19.42s/it]  3%|▎         | 533/20600 [3:08:28<110:05:08, 19.75s/it]  3%|▎         | 534/20600 [3:08:45<105:17:11, 18.89s/it]  3%|▎         | 535/20600 [3:09:01<99:29:47, 17.85s/it]   3%|▎         | 536/20600 [3:09:27<114:08:01, 20.48s/it]  3%|▎         | 537/20600 [3:09:50<117:00:25, 21.00s/it]  3%|▎         | 538/20600 [3:10:10<115:26:51, 20.72s/it]  3%|▎         | 539/20600 [3:10:24<105:22:22, 18.91s/it]  3%|▎         | 540/20600 [3:10:41<101:10:09, 18.16s/it]                                                         {'loss': 0.0, 'learning_rate': 4.995912860295313e-05, 'epoch': 5.2}
  3%|▎         | 540/20600 [3:10:41<101:10:09, 18.16s/it][INFO|trainer.py:3081] 2023-08-16 18:59:43,736 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 18:59:43,736 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 18:59:43,736 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.184, 'eval_samples_per_second': 0.855, 'eval_steps_per_second': 0.122, 'epoch': 5.2}
  3%|▎         | 540/20600 [3:10:49<101:10:09, 18.16s/it]
100%|██████████| 1/1 [00:07<00:00,  7.29s/it][A
                                             [A  3%|▎         | 541/20600 [3:11:09<118:16:33, 21.23s/it]  3%|▎         | 542/20600 [3:11:31<118:32:04, 21.27s/it]  3%|▎         | 543/20600 [3:11:49<113:48:47, 20.43s/it]  3%|▎         | 544/20600 [3:12:10<114:39:40, 20.58s/it]  3%|▎         | 545/20600 [3:12:30<112:59:57, 20.28s/it]  3%|▎         | 546/20600 [3:12:52<116:15:26, 20.87s/it]  3%|▎         | 547/20600 [3:13:11<113:32:55, 20.38s/it]  3%|▎         | 548/20600 [3:13:30<111:38:04, 20.04s/it]  3%|▎         | 549/20600 [3:13:52<114:58:21, 20.64s/it]  3%|▎         | 550/20600 [3:14:10<109:28:49, 19.66s/it]                                                         {'loss': 0.0, 'learning_rate': 4.995692036560183e-05, 'epoch': 5.3}
  3%|▎         | 550/20600 [3:14:10<109:28:49, 19.66s/it][INFO|trainer.py:3081] 2023-08-16 19:03:12,635 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:03:12,635 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:03:12,635 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.1285, 'eval_samples_per_second': 1.142, 'eval_steps_per_second': 0.163, 'epoch': 5.3}
  3%|▎         | 550/20600 [3:14:16<109:28:49, 19.66s/it]
100%|██████████| 1/1 [00:05<00:00,  5.22s/it][A
                                             [A  3%|▎         | 551/20600 [3:14:29<109:16:41, 19.62s/it]  3%|▎         | 552/20600 [3:14:49<110:10:18, 19.78s/it]  3%|▎         | 553/20600 [3:15:06<104:55:01, 18.84s/it]  3%|▎         | 554/20600 [3:15:29<111:46:49, 20.07s/it]  3%|▎         | 555/20600 [3:15:51<115:46:14, 20.79s/it]  3%|▎         | 556/20600 [3:16:19<126:52:20, 22.79s/it]  3%|▎         | 557/20600 [3:16:38<121:30:24, 21.82s/it]  3%|▎         | 558/20600 [3:17:02<123:38:42, 22.21s/it]  3%|▎         | 559/20600 [3:17:21<118:29:36, 21.29s/it]  3%|▎         | 560/20600 [3:17:39<113:04:14, 20.31s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9954654084400184e-05, 'epoch': 5.4}
  3%|▎         | 560/20600 [3:17:39<113:04:14, 20.31s/it][INFO|trainer.py:3081] 2023-08-16 19:06:41,691 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:06:41,691 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:06:41,691 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.5107, 'eval_samples_per_second': 1.552, 'eval_steps_per_second': 0.222, 'epoch': 5.4}
  3%|▎         | 560/20600 [3:17:43<113:04:14, 20.31s/it]
100%|██████████| 1/1 [00:03<00:00,  3.63s/it][A
                                             [A  3%|▎         | 561/20600 [3:18:05<123:31:28, 22.19s/it]  3%|▎         | 562/20600 [3:18:25<119:28:45, 21.47s/it]  3%|▎         | 563/20600 [3:18:41<110:55:05, 19.93s/it]  3%|▎         | 564/20600 [3:18:58<105:55:09, 19.03s/it]  3%|▎         | 565/20600 [3:19:21<111:25:32, 20.02s/it]  3%|▎         | 566/20600 [3:19:47<121:23:27, 21.81s/it]  3%|▎         | 567/20600 [3:20:07<119:19:33, 21.44s/it]  3%|▎         | 568/20600 [3:20:35<129:53:54, 23.34s/it]  3%|▎         | 569/20600 [3:20:51<117:01:48, 21.03s/it]  3%|▎         | 570/20600 [3:21:10<113:59:49, 20.49s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9952329764619025e-05, 'epoch': 5.49}
  3%|▎         | 570/20600 [3:21:10<113:59:49, 20.49s/it][INFO|trainer.py:3081] 2023-08-16 19:10:12,863 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:10:12,863 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:10:12,863 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.9949, 'eval_samples_per_second': 0.876, 'eval_steps_per_second': 0.125, 'epoch': 5.49}
  3%|▎         | 570/20600 [3:21:18<113:59:49, 20.49s/it]
100%|██████████| 1/1 [00:07<00:00,  7.11s/it][A
                                             [A  3%|▎         | 571/20600 [3:21:36<122:32:47, 22.03s/it]  3%|▎         | 572/20600 [3:22:02<129:51:10, 23.34s/it]  3%|▎         | 573/20600 [3:22:21<123:00:41, 22.11s/it]  3%|▎         | 574/20600 [3:22:38<114:55:49, 20.66s/it]  3%|▎         | 575/20600 [3:23:02<119:12:43, 21.43s/it]  3%|▎         | 576/20600 [3:23:21<115:44:47, 20.81s/it]  3%|▎         | 577/20600 [3:23:38<109:55:05, 19.76s/it]  3%|▎         | 578/20600 [3:24:03<118:19:22, 21.27s/it]  3%|▎         | 579/20600 [3:24:26<120:10:36, 21.61s/it]  3%|▎         | 580/20600 [3:24:46<117:52:19, 21.20s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9949947411664155e-05, 'epoch': 5.59}
  3%|▎         | 580/20600 [3:24:46<117:52:19, 21.20s/it][INFO|trainer.py:3081] 2023-08-16 19:13:48,737 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:13:48,737 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:13:48,737 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.5567, 'eval_samples_per_second': 0.926, 'eval_steps_per_second': 0.132, 'epoch': 5.59}
  3%|▎         | 580/20600 [3:24:53<117:52:19, 21.20s/it]
100%|██████████| 1/1 [00:06<00:00,  6.67s/it][A
                                             [A  3%|▎         | 581/20600 [3:25:13<127:07:55, 22.86s/it]  3%|▎         | 582/20600 [3:25:35<126:53:59, 22.82s/it]  3%|▎         | 583/20600 [3:25:54<119:35:04, 21.51s/it]  3%|▎         | 584/20600 [3:26:24<134:37:04, 24.21s/it]  3%|▎         | 585/20600 [3:26:43<125:00:40, 22.49s/it]  3%|▎         | 586/20600 [3:27:03<121:20:34, 21.83s/it]  3%|▎         | 587/20600 [3:27:21<114:52:36, 20.66s/it]  3%|▎         | 588/20600 [3:27:38<109:01:33, 19.61s/it]  3%|▎         | 589/20600 [3:27:55<104:43:11, 18.84s/it]  3%|▎         | 590/20600 [3:28:12<101:26:33, 18.25s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9947507031076367e-05, 'epoch': 5.69}
  3%|▎         | 590/20600 [3:28:12<101:26:33, 18.25s/it][INFO|trainer.py:3081] 2023-08-16 19:17:14,947 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:17:14,947 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:17:14,947 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.5627, 'eval_samples_per_second': 0.926, 'eval_steps_per_second': 0.132, 'epoch': 5.69}
  3%|▎         | 590/20600 [3:28:20<101:26:33, 18.25s/it]
100%|██████████| 1/1 [00:06<00:00,  6.66s/it][A
                                             [A  3%|▎         | 591/20600 [3:28:36<111:02:16, 19.98s/it]  3%|▎         | 592/20600 [3:28:59<115:43:42, 20.82s/it]  3%|▎         | 593/20600 [3:29:16<110:14:51, 19.84s/it]  3%|▎         | 594/20600 [3:29:32<104:00:12, 18.72s/it]  3%|▎         | 595/20600 [3:29:53<106:19:30, 19.13s/it]  3%|▎         | 596/20600 [3:30:13<109:00:29, 19.62s/it]  3%|▎         | 597/20600 [3:30:33<108:29:51, 19.53s/it]  3%|▎         | 598/20600 [3:30:51<107:03:53, 19.27s/it]  3%|▎         | 599/20600 [3:31:10<106:58:49, 19.26s/it]  3%|▎         | 600/20600 [3:31:27<102:27:27, 18.44s/it]                                                         {'loss': 0.0, 'learning_rate': 4.994500862853141e-05, 'epoch': 5.78}
  3%|▎         | 600/20600 [3:31:27<102:27:27, 18.44s/it][INFO|trainer.py:3081] 2023-08-16 19:20:29,996 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:20:29,996 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:20:29,996 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0594, 'eval_samples_per_second': 1.724, 'eval_steps_per_second': 0.246, 'epoch': 5.78}
  3%|▎         | 600/20600 [3:31:31<102:27:27, 18.44s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A  3%|▎         | 601/20600 [3:32:04<132:45:04, 23.90s/it]  3%|▎         | 602/20600 [3:32:26<129:55:30, 23.39s/it]  3%|▎         | 603/20600 [3:32:41<116:45:45, 21.02s/it]  3%|▎         | 604/20600 [3:33:02<116:24:39, 20.96s/it]  3%|▎         | 605/20600 [3:33:21<112:09:10, 20.19s/it]  3%|▎         | 606/20600 [3:33:37<105:25:49, 18.98s/it]  3%|▎         | 607/20600 [3:33:57<108:10:43, 19.48s/it]  3%|▎         | 608/20600 [3:34:15<104:17:22, 18.78s/it]  3%|▎         | 609/20600 [3:34:35<106:24:39, 19.16s/it]  3%|▎         | 610/20600 [3:34:53<105:04:17, 18.92s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9942452209839965e-05, 'epoch': 5.88}
  3%|▎         | 610/20600 [3:34:53<105:04:17, 18.92s/it][INFO|trainer.py:3081] 2023-08-16 19:23:55,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:23:55,896 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:23:55,896 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8976, 'eval_samples_per_second': 1.015, 'eval_steps_per_second': 0.145, 'epoch': 5.88}
  3%|▎         | 610/20600 [3:35:00<105:04:17, 18.92s/it]
100%|██████████| 1/1 [00:06<00:00,  6.01s/it][A
                                             [A  3%|▎         | 611/20600 [3:35:20<118:09:33, 21.28s/it]  3%|▎         | 612/20600 [3:35:36<110:20:32, 19.87s/it]  3%|▎         | 613/20600 [3:35:54<106:09:05, 19.12s/it]  3%|▎         | 614/20600 [3:36:12<104:50:38, 18.89s/it]  3%|▎         | 615/20600 [3:36:37<115:10:06, 20.75s/it]  3%|▎         | 616/20600 [3:36:59<116:20:48, 20.96s/it]  3%|▎         | 617/20600 [3:37:19<115:35:56, 20.83s/it]  3%|▎         | 618/20600 [3:37:37<110:22:57, 19.89s/it]  3%|▎         | 619/20600 [3:37:57<110:46:44, 19.96s/it]  3%|▎         | 620/20600 [3:38:12<103:17:09, 18.61s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9939837780947654e-05, 'epoch': 5.98}
  3%|▎         | 620/20600 [3:38:12<103:17:09, 18.61s/it][INFO|trainer.py:3081] 2023-08-16 19:27:15,310 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:27:15,310 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:27:15,310 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7101, 'eval_samples_per_second': 1.887, 'eval_steps_per_second': 0.27, 'epoch': 5.98}
  3%|▎         | 620/20600 [3:38:16<103:17:09, 18.61s/it]
100%|██████████| 1/1 [00:02<00:00,  2.76s/it][A
                                             [A  3%|▎         | 621/20600 [3:38:46<128:42:13, 23.19s/it]  3%|▎         | 622/20600 [3:39:05<121:26:50, 21.88s/it]  3%|▎         | 623/20600 [3:39:20<110:04:17, 19.84s/it]  3%|▎         | 624/20600 [3:39:41<111:58:54, 20.18s/it]  3%|▎         | 625/20600 [3:40:01<112:06:00, 20.20s/it]  3%|▎         | 626/20600 [3:40:22<112:53:37, 20.35s/it]  3%|▎         | 627/20600 [3:40:42<112:07:40, 20.21s/it]  3%|▎         | 628/20600 [3:40:58<105:57:56, 19.10s/it]  3%|▎         | 629/20600 [3:41:19<108:20:32, 19.53s/it]  3%|▎         | 630/20600 [3:41:46<120:55:01, 21.80s/it]                                                         {'loss': 0.0, 'learning_rate': 4.993716534793501e-05, 'epoch': 6.07}
  3%|▎         | 630/20600 [3:41:46<120:55:01, 21.80s/it][INFO|trainer.py:3081] 2023-08-16 19:30:49,031 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:30:49,031 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:30:49,031 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4311, 'eval_samples_per_second': 2.04, 'eval_steps_per_second': 0.291, 'epoch': 6.07}
  3%|▎         | 630/20600 [3:41:49<120:55:01, 21.80s/it]
100%|██████████| 1/1 [00:02<00:00,  2.59s/it][A
                                             [A  3%|▎         | 631/20600 [3:42:09<123:36:15, 22.28s/it]  3%|▎         | 632/20600 [3:42:30<120:55:57, 21.80s/it]  3%|▎         | 633/20600 [3:42:52<120:52:02, 21.79s/it]  3%|▎         | 634/20600 [3:43:07<109:45:16, 19.79s/it]  3%|▎         | 635/20600 [3:43:30<115:30:46, 20.83s/it]  3%|▎         | 636/20600 [3:43:49<111:26:17, 20.10s/it]  3%|▎         | 637/20600 [3:44:14<120:02:43, 21.65s/it]  3%|▎         | 638/20600 [3:44:34<117:06:25, 21.12s/it]  3%|▎         | 639/20600 [3:45:00<125:25:21, 22.62s/it]  3%|▎         | 640/20600 [3:45:31<138:58:28, 25.07s/it]                                                         {'loss': 0.0, 'learning_rate': 4.993443491701748e-05, 'epoch': 6.17}
  3%|▎         | 640/20600 [3:45:31<138:58:28, 25.07s/it][INFO|trainer.py:3081] 2023-08-16 19:34:33,699 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:34:33,700 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:34:33,700 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 5.1581, 'eval_samples_per_second': 1.357, 'eval_steps_per_second': 0.194, 'epoch': 6.17}
  3%|▎         | 640/20600 [3:45:36<138:58:28, 25.07s/it]
100%|██████████| 1/1 [00:04<00:00,  4.32s/it][A
                                             [A  3%|▎         | 641/20600 [3:45:50<129:59:26, 23.45s/it]  3%|▎         | 642/20600 [3:46:08<120:32:12, 21.74s/it]  3%|▎         | 643/20600 [3:46:32<123:56:51, 22.36s/it]  3%|▎         | 644/20600 [3:46:56<127:01:10, 22.91s/it]  3%|▎         | 645/20600 [3:47:17<124:22:59, 22.44s/it]  3%|▎         | 646/20600 [3:47:43<129:03:41, 23.28s/it]  3%|▎         | 647/20600 [3:48:03<124:17:54, 22.43s/it]  3%|▎         | 648/20600 [3:48:25<124:02:35, 22.38s/it]  3%|▎         | 649/20600 [3:48:45<119:55:48, 21.64s/it]  3%|▎         | 650/20600 [3:49:07<119:52:29, 21.63s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9931646494545405e-05, 'epoch': 6.27}
  3%|▎         | 650/20600 [3:49:07<119:52:29, 21.63s/it][INFO|trainer.py:3081] 2023-08-16 19:38:09,953 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:38:09,954 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:38:09,954 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.113, 'eval_samples_per_second': 0.863, 'eval_steps_per_second': 0.123, 'epoch': 6.27}
  3%|▎         | 650/20600 [3:49:15<119:52:29, 21.63s/it]
100%|██████████| 1/1 [00:07<00:00,  7.27s/it][A
                                             [A  3%|▎         | 651/20600 [3:49:30<122:07:32, 22.04s/it]  3%|▎         | 652/20600 [3:49:55<126:51:43, 22.89s/it]  3%|▎         | 653/20600 [3:50:15<123:05:04, 22.21s/it]  3%|▎         | 654/20600 [3:50:36<120:28:31, 21.74s/it]  3%|▎         | 655/20600 [3:50:55<115:40:20, 20.88s/it]  3%|▎         | 656/20600 [3:51:31<140:15:22, 25.32s/it]  3%|▎         | 657/20600 [3:51:46<122:56:37, 22.19s/it]  3%|▎         | 658/20600 [3:52:07<121:20:23, 21.90s/it]  3%|▎         | 659/20600 [3:52:24<112:56:29, 20.39s/it]  3%|▎         | 660/20600 [3:52:42<109:43:05, 19.81s/it]                                                         {'loss': 0.0, 'learning_rate': 4.992880008700398e-05, 'epoch': 6.36}
  3%|▎         | 660/20600 [3:52:42<109:43:05, 19.81s/it][INFO|trainer.py:3081] 2023-08-16 19:41:45,081 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:41:45,082 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:41:45,082 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2265, 'eval_samples_per_second': 0.969, 'eval_steps_per_second': 0.138, 'epoch': 6.36}
  3%|▎         | 660/20600 [3:52:49<109:43:05, 19.81s/it]
100%|██████████| 1/1 [00:06<00:00,  6.31s/it][A
                                             [A  3%|▎         | 661/20600 [3:53:14<129:43:38, 23.42s/it]  3%|▎         | 662/20600 [3:53:33<122:30:20, 22.12s/it]  3%|▎         | 663/20600 [3:53:59<129:41:53, 23.42s/it]  3%|▎         | 664/20600 [3:54:21<125:43:49, 22.70s/it]  3%|▎         | 665/20600 [3:54:37<115:45:51, 20.91s/it]  3%|▎         | 666/20600 [3:55:04<125:52:22, 22.73s/it]  3%|▎         | 667/20600 [3:55:24<120:44:59, 21.81s/it]  3%|▎         | 668/20600 [3:55:53<133:13:23, 24.06s/it]  3%|▎         | 669/20600 [3:56:11<122:36:55, 22.15s/it]  3%|▎         | 670/20600 [3:56:28<114:06:06, 20.61s/it]                                                         {'loss': 0.0, 'learning_rate': 4.992589570101328e-05, 'epoch': 6.46}
  3%|▎         | 670/20600 [3:56:28<114:06:06, 20.61s/it][INFO|trainer.py:3081] 2023-08-16 19:45:30,884 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:45:30,884 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:45:30,884 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9915, 'eval_samples_per_second': 1.754, 'eval_steps_per_second': 0.251, 'epoch': 6.46}
  3%|▎         | 670/20600 [3:56:32<114:06:06, 20.61s/it]
100%|██████████| 1/1 [00:03<00:00,  3.08s/it][A
                                             [A  3%|▎         | 671/20600 [3:56:49<115:17:09, 20.83s/it]  3%|▎         | 672/20600 [3:57:07<109:27:08, 19.77s/it]  3%|▎         | 673/20600 [3:57:25<106:30:28, 19.24s/it]  3%|▎         | 674/20600 [3:57:41<102:02:12, 18.43s/it]  3%|▎         | 675/20600 [3:58:03<107:40:52, 19.46s/it]  3%|▎         | 676/20600 [3:58:21<105:59:03, 19.15s/it]  3%|▎         | 677/20600 [3:58:37<99:47:01, 18.03s/it]   3%|▎         | 678/20600 [3:58:54<97:36:47, 17.64s/it]  3%|▎         | 679/20600 [3:59:11<97:17:56, 17.58s/it]  3%|▎         | 680/20600 [3:59:34<105:37:55, 19.09s/it]                                                         {'loss': 0.0, 'learning_rate': 4.99229333433282e-05, 'epoch': 6.55}
  3%|▎         | 680/20600 [3:59:34<105:37:55, 19.09s/it][INFO|trainer.py:3081] 2023-08-16 19:48:36,569 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:48:36,570 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:48:36,570 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4408, 'eval_samples_per_second': 2.034, 'eval_steps_per_second': 0.291, 'epoch': 6.55}
  3%|▎         | 680/20600 [3:59:37<105:37:55, 19.09s/it]
100%|██████████| 1/1 [00:02<00:00,  2.59s/it][A
                                             [A  3%|▎         | 681/20600 [3:59:53<106:00:21, 19.16s/it]  3%|▎         | 682/20600 [4:00:18<115:14:58, 20.83s/it]  3%|▎         | 683/20600 [4:00:33<106:54:17, 19.32s/it]  3%|▎         | 684/20600 [4:00:52<105:00:43, 18.98s/it]  3%|▎         | 685/20600 [4:01:21<122:23:45, 22.13s/it]  3%|▎         | 686/20600 [4:01:39<116:13:16, 21.01s/it]  3%|▎         | 687/20600 [4:01:58<112:24:40, 20.32s/it]  3%|▎         | 688/20600 [4:02:21<116:09:26, 21.00s/it]  3%|▎         | 689/20600 [4:02:45<121:59:00, 22.06s/it]  3%|▎         | 690/20600 [4:03:08<123:07:52, 22.26s/it]                                                         {'loss': 0.0, 'learning_rate': 4.991991302083849e-05, 'epoch': 6.65}
  3%|▎         | 690/20600 [4:03:08<123:07:52, 22.26s/it][INFO|trainer.py:3081] 2023-08-16 19:52:11,044 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:52:11,044 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:52:11,044 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4619, 'eval_samples_per_second': 2.022, 'eval_steps_per_second': 0.289, 'epoch': 6.65}
  3%|▎         | 690/20600 [4:03:12<123:07:52, 22.26s/it]
100%|██████████| 1/1 [00:02<00:00,  2.60s/it][A
                                             [A  3%|▎         | 691/20600 [4:03:28<118:38:07, 21.45s/it]  3%|▎         | 692/20600 [4:03:56<130:46:40, 23.65s/it]  3%|▎         | 693/20600 [4:04:14<120:41:24, 21.83s/it]  3%|▎         | 694/20600 [4:04:34<117:53:21, 21.32s/it]  3%|▎         | 695/20600 [4:04:51<111:19:55, 20.14s/it]  3%|▎         | 696/20600 [4:05:09<106:18:31, 19.23s/it]  3%|▎         | 697/20600 [4:05:27<105:15:01, 19.04s/it]  3%|▎         | 698/20600 [4:05:46<104:16:20, 18.86s/it]  3%|▎         | 699/20600 [4:06:03<101:46:58, 18.41s/it]  3%|▎         | 700/20600 [4:06:21<101:51:34, 18.43s/it]                                                         {'loss': 0.0, 'learning_rate': 4.991683474056871e-05, 'epoch': 6.75}
  3%|▎         | 700/20600 [4:06:21<101:51:34, 18.43s/it][INFO|trainer.py:3081] 2023-08-16 19:55:24,436 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:55:24,437 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:55:24,437 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9555, 'eval_samples_per_second': 1.77, 'eval_steps_per_second': 0.253, 'epoch': 6.75}
  3%|▎         | 700/20600 [4:06:25<101:51:34, 18.43s/it]
100%|██████████| 1/1 [00:03<00:00,  3.09s/it][A
                                             [A  3%|▎         | 701/20600 [4:06:42<104:41:07, 18.94s/it]  3%|▎         | 702/20600 [4:07:03<108:15:21, 19.59s/it]  3%|▎         | 703/20600 [4:07:20<104:38:28, 18.93s/it]  3%|▎         | 704/20600 [4:07:41<108:41:40, 19.67s/it]  3%|▎         | 705/20600 [4:07:57<102:17:07, 18.51s/it]  3%|▎         | 706/20600 [4:08:20<109:58:31, 19.90s/it]  3%|▎         | 707/20600 [4:08:37<104:22:41, 18.89s/it]  3%|▎         | 708/20600 [4:08:55<102:42:19, 18.59s/it]  3%|▎         | 709/20600 [4:09:10<97:03:59, 17.57s/it]   3%|▎         | 710/20600 [4:09:27<95:23:29, 17.27s/it]                                                        {'loss': 0.0, 'learning_rate': 4.9913698509678173e-05, 'epoch': 6.84}
  3%|▎         | 710/20600 [4:09:27<95:23:29, 17.27s/it][INFO|trainer.py:3081] 2023-08-16 19:58:29,567 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 19:58:29,567 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 19:58:29,567 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                        
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8091, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 0.263, 'epoch': 6.84}
  3%|▎         | 710/20600 [4:09:30<95:23:29, 17.27s/it]
100%|██████████| 1/1 [00:02<00:00,  2.90s/it][A
                                             [A  3%|▎         | 711/20600 [4:09:53<110:45:08, 20.05s/it]  3%|▎         | 712/20600 [4:10:09<104:07:19, 18.85s/it]  3%|▎         | 713/20600 [4:10:33<112:49:26, 20.42s/it]  3%|▎         | 714/20600 [4:10:55<115:28:38, 20.91s/it]  3%|▎         | 715/20600 [4:11:13<110:56:56, 20.09s/it]  3%|▎         | 716/20600 [4:11:33<109:25:08, 19.81s/it]  3%|▎         | 717/20600 [4:11:50<105:41:19, 19.14s/it]  3%|▎         | 718/20600 [4:12:17<118:55:00, 21.53s/it]  3%|▎         | 719/20600 [4:12:37<115:57:00, 21.00s/it]  3%|▎         | 720/20600 [4:12:59<117:26:48, 21.27s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9910504335461036e-05, 'epoch': 6.94}
  3%|▎         | 720/20600 [4:12:59<117:26:48, 21.27s/it][INFO|trainer.py:3081] 2023-08-16 20:02:01,966 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:02:01,966 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:02:01,966 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 9.3003, 'eval_samples_per_second': 0.753, 'eval_steps_per_second': 0.108, 'epoch': 6.94}
  3%|▎         | 720/20600 [4:13:08<117:26:48, 21.27s/it]
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A
                                             [A  4%|▎         | 721/20600 [4:13:26<126:44:51, 22.95s/it]  4%|▎         | 722/20600 [4:13:42<116:07:24, 21.03s/it]  4%|▎         | 723/20600 [4:14:03<115:45:06, 20.96s/it]  4%|▎         | 724/20600 [4:14:23<114:01:46, 20.65s/it]  4%|▎         | 725/20600 [4:14:49<123:19:42, 22.34s/it]  4%|▎         | 726/20600 [4:15:26<146:40:20, 26.57s/it]  4%|▎         | 727/20600 [4:15:42<129:34:32, 23.47s/it]  4%|▎         | 728/20600 [4:16:05<128:38:59, 23.31s/it]  4%|▎         | 729/20600 [4:16:22<118:33:05, 21.48s/it]  4%|▎         | 730/20600 [4:16:41<113:34:24, 20.58s/it]                                                         {'loss': 0.0, 'learning_rate': 4.990725222534619e-05, 'epoch': 7.04}
  4%|▎         | 730/20600 [4:16:41<113:34:24, 20.58s/it][INFO|trainer.py:3081] 2023-08-16 20:05:43,686 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:05:43,686 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:05:43,686 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0371, 'eval_samples_per_second': 1.734, 'eval_steps_per_second': 0.248, 'epoch': 7.04}
  4%|▎         | 730/20600 [4:16:45<113:34:24, 20.58s/it]
100%|██████████| 1/1 [00:03<00:00,  3.13s/it][A
                                             [A  4%|▎         | 731/20600 [4:17:17<140:07:28, 25.39s/it]  4%|▎         | 732/20600 [4:17:33<124:23:29, 22.54s/it]  4%|▎         | 733/20600 [4:17:54<122:04:21, 22.12s/it]  4%|▎         | 734/20600 [4:18:17<123:01:26, 22.29s/it]  4%|▎         | 735/20600 [4:18:42<127:21:32, 23.08s/it]  4%|▎         | 736/20600 [4:18:59<116:46:13, 21.16s/it]  4%|▎         | 737/20600 [4:19:20<117:21:54, 21.27s/it]  4%|▎         | 738/20600 [4:19:38<111:10:11, 20.15s/it]  4%|▎         | 739/20600 [4:19:54<104:26:35, 18.93s/it]  4%|▎         | 740/20600 [4:20:10<100:37:12, 18.24s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9903942186897234e-05, 'epoch': 7.13}
  4%|▎         | 740/20600 [4:20:10<100:37:12, 18.24s/it][INFO|trainer.py:3081] 2023-08-16 20:09:13,408 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:09:13,408 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:09:13,408 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0521, 'eval_samples_per_second': 1.727, 'eval_steps_per_second': 0.247, 'epoch': 7.13}
  4%|▎         | 740/20600 [4:20:14<100:37:12, 18.24s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A  4%|▎         | 741/20600 [4:20:37<114:33:53, 20.77s/it]  4%|▎         | 742/20600 [4:20:56<111:59:17, 20.30s/it]  4%|▎         | 743/20600 [4:21:12<105:08:51, 19.06s/it]  4%|▎         | 744/20600 [4:21:35<110:25:22, 20.02s/it]  4%|▎         | 745/20600 [4:22:03<123:53:17, 22.46s/it]  4%|▎         | 746/20600 [4:22:22<118:48:52, 21.54s/it]  4%|▎         | 747/20600 [4:22:39<110:58:53, 20.12s/it]  4%|▎         | 748/20600 [4:23:02<115:11:03, 20.89s/it]  4%|▎         | 749/20600 [4:23:16<103:46:49, 18.82s/it]  4%|▎         | 750/20600 [4:23:38<109:30:35, 19.86s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9900574227812564e-05, 'epoch': 7.23}
  4%|▎         | 750/20600 [4:23:38<109:30:35, 19.86s/it][INFO|trainer.py:3081] 2023-08-16 20:12:41,046 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:12:41,046 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:12:41,046 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6623, 'eval_samples_per_second': 1.911, 'eval_steps_per_second': 0.273, 'epoch': 7.23}
  4%|▎         | 750/20600 [4:23:42<109:30:35, 19.86s/it]
100%|██████████| 1/1 [00:02<00:00,  2.79s/it][A
                                             [A  4%|▎         | 751/20600 [4:23:58<109:55:30, 19.94s/it]  4%|▎         | 752/20600 [4:24:24<119:41:02, 21.71s/it]  4%|▎         | 753/20600 [4:24:44<117:25:50, 21.30s/it]  4%|▎         | 754/20600 [4:25:09<123:33:04, 22.41s/it]  4%|▎         | 755/20600 [4:25:33<124:56:08, 22.66s/it]  4%|▎         | 756/20600 [4:25:50<116:39:08, 21.16s/it]  4%|▎         | 757/20600 [4:26:11<115:36:00, 20.97s/it]  4%|▎         | 758/20600 [4:26:32<115:35:13, 20.97s/it]  4%|▎         | 759/20600 [4:26:57<121:53:45, 22.12s/it]  4%|▎         | 760/20600 [4:27:15<116:35:14, 21.15s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9897148355925235e-05, 'epoch': 7.33}
  4%|▎         | 760/20600 [4:27:15<116:35:14, 21.15s/it][INFO|trainer.py:3081] 2023-08-16 20:16:18,465 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:16:18,466 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:16:18,466 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3606, 'eval_samples_per_second': 2.083, 'eval_steps_per_second': 0.298, 'epoch': 7.33}
  4%|▎         | 760/20600 [4:27:19<116:35:14, 21.15s/it]
100%|██████████| 1/1 [00:02<00:00,  2.48s/it][A
                                             [A  4%|▎         | 761/20600 [4:27:33<109:52:32, 19.94s/it]  4%|▎         | 762/20600 [4:27:56<114:50:07, 20.84s/it]  4%|▎         | 763/20600 [4:28:13<109:15:47, 19.83s/it]  4%|▎         | 764/20600 [4:28:29<103:23:01, 18.76s/it]  4%|▎         | 765/20600 [4:28:45<98:38:59, 17.90s/it]   4%|▎         | 766/20600 [4:29:05<101:39:44, 18.45s/it]  4%|▎         | 767/20600 [4:29:28<109:25:15, 19.86s/it]  4%|▎         | 768/20600 [4:29:47<108:31:11, 19.70s/it]  4%|▎         | 769/20600 [4:30:03<101:47:20, 18.48s/it]  4%|▎         | 770/20600 [4:30:19<96:59:17, 17.61s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9893664579203e-05, 'epoch': 7.42}
  4%|▎         | 770/20600 [4:30:19<96:59:17, 17.61s/it][INFO|trainer.py:3081] 2023-08-16 20:19:21,563 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:19:21,563 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:19:21,563 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                        
                                     [A{'eval_loss': nan, 'eval_runtime': 4.9275, 'eval_samples_per_second': 1.421, 'eval_steps_per_second': 0.203, 'epoch': 7.42}
  4%|▎         | 770/20600 [4:30:24<96:59:17, 17.61s/it]
100%|██████████| 1/1 [00:04<00:00,  4.01s/it][A
                                             [A  4%|▎         | 771/20600 [4:30:50<119:37:59, 21.72s/it]  4%|▎         | 772/20600 [4:31:07<112:17:17, 20.39s/it]  4%|▍         | 773/20600 [4:31:34<123:19:40, 22.39s/it]  4%|▍         | 774/20600 [4:31:53<117:35:09, 21.35s/it]  4%|▍         | 775/20600 [4:32:10<109:46:26, 19.93s/it]  4%|▍         | 776/20600 [4:32:37<120:58:10, 21.97s/it]  4%|▍         | 777/20600 [4:32:53<112:24:15, 20.41s/it]  4%|▍         | 778/20600 [4:33:18<119:14:50, 21.66s/it]  4%|▍         | 779/20600 [4:33:35<112:28:32, 20.43s/it]  4%|▍         | 780/20600 [4:33:56<113:16:30, 20.57s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9890122905748314e-05, 'epoch': 7.52}
  4%|▍         | 780/20600 [4:33:56<113:16:30, 20.57s/it][INFO|trainer.py:3081] 2023-08-16 20:22:59,318 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:22:59,318 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:22:59,318 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8787, 'eval_samples_per_second': 1.018, 'eval_steps_per_second': 0.145, 'epoch': 7.52}
  4%|▍         | 780/20600 [4:34:03<113:16:30, 20.57s/it]
100%|██████████| 1/1 [00:06<00:00,  6.02s/it][A
                                             [A  4%|▍         | 781/20600 [4:34:18<115:11:29, 20.92s/it]  4%|▍         | 782/20600 [4:34:35<108:17:29, 19.67s/it]  4%|▍         | 783/20600 [4:34:53<105:17:23, 19.13s/it]  4%|▍         | 784/20600 [4:35:21<120:32:08, 21.90s/it]  4%|▍         | 785/20600 [4:35:37<111:15:02, 20.21s/it]  4%|▍         | 786/20600 [4:36:02<118:49:47, 21.59s/it]  4%|▍         | 787/20600 [4:36:27<123:40:44, 22.47s/it]  4%|▍         | 788/20600 [4:36:44<114:31:22, 20.81s/it]  4%|▍         | 789/20600 [4:37:05<115:36:00, 21.01s/it]  4%|▍         | 790/20600 [4:37:24<112:11:45, 20.39s/it]                                                         {'loss': 0.0, 'learning_rate': 4.988652334379825e-05, 'epoch': 7.61}
  4%|▍         | 790/20600 [4:37:24<112:11:45, 20.39s/it][INFO|trainer.py:3081] 2023-08-16 20:26:26,977 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:26:26,977 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:26:26,977 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 6.2826, 'eval_samples_per_second': 1.114, 'eval_steps_per_second': 0.159, 'epoch': 7.61}
  4%|▍         | 790/20600 [4:37:30<112:11:45, 20.39s/it]
100%|██████████| 1/1 [00:05<00:00,  5.38s/it][A
                                             [A  4%|▍         | 791/20600 [4:37:47<117:17:14, 21.32s/it]  4%|▍         | 792/20600 [4:38:17<130:37:04, 23.74s/it]  4%|▍         | 793/20600 [4:38:35<121:09:41, 22.02s/it]  4%|▍         | 794/20600 [4:38:54<115:48:45, 21.05s/it]  4%|▍         | 795/20600 [4:39:13<113:11:25, 20.57s/it]  4%|▍         | 796/20600 [4:39:31<109:06:21, 19.83s/it]  4%|▍         | 797/20600 [4:39:55<115:28:04, 20.99s/it]  4%|▍         | 798/20600 [4:40:19<121:15:42, 22.05s/it]  4%|▍         | 799/20600 [4:40:46<128:31:12, 23.37s/it]  4%|▍         | 800/20600 [4:41:03<117:36:37, 21.38s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9882865901724544e-05, 'epoch': 7.71}
  4%|▍         | 800/20600 [4:41:03<117:36:37, 21.38s/it][INFO|trainer.py:3081] 2023-08-16 20:30:05,624 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:30:05,625 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:30:05,625 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0857, 'eval_samples_per_second': 1.713, 'eval_steps_per_second': 0.245, 'epoch': 7.71}
  4%|▍         | 800/20600 [4:41:07<117:36:37, 21.38s/it]
100%|██████████| 1/1 [00:03<00:00,  3.21s/it][A
                                             [A08/16/2023 20:30:09 - INFO - llmtuner.tuner.core.trainer - Saving model checkpoint to ../outputs/Ihin/Ihin-sft-llama2/checkpoint-800
  4%|▍         | 801/20600 [4:41:29<125:13:17, 22.77s/it]  4%|▍         | 802/20600 [4:41:48<119:24:38, 21.71s/it]  4%|▍         | 803/20600 [4:42:11<121:14:05, 22.05s/it]  4%|▍         | 804/20600 [4:42:36<126:39:56, 23.03s/it]  4%|▍         | 805/20600 [4:42:56<121:08:25, 22.03s/it]  4%|▍         | 806/20600 [4:43:18<121:18:27, 22.06s/it]  4%|▍         | 807/20600 [4:43:37<116:29:53, 21.19s/it]  4%|▍         | 808/20600 [4:43:57<114:46:38, 20.88s/it]  4%|▍         | 809/20600 [4:44:15<108:53:58, 19.81s/it]  4%|▍         | 810/20600 [4:44:38<114:43:26, 20.87s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9879150588033526e-05, 'epoch': 7.81}
  4%|▍         | 810/20600 [4:44:38<114:43:26, 20.87s/it][INFO|trainer.py:3081] 2023-08-16 20:33:40,820 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:33:40,820 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:33:40,820 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3936, 'eval_samples_per_second': 0.834, 'eval_steps_per_second': 0.119, 'epoch': 7.81}
  4%|▍         | 810/20600 [4:44:46<114:43:26, 20.87s/it]
100%|██████████| 1/1 [00:07<00:00,  7.49s/it][A
                                             [A  4%|▍         | 811/20600 [4:45:06<126:24:51, 23.00s/it]  4%|▍         | 812/20600 [4:45:33<133:05:24, 24.21s/it]  4%|▍         | 813/20600 [4:45:52<124:02:34, 22.57s/it]  4%|▍         | 814/20600 [4:46:10<117:53:18, 21.45s/it]  4%|▍         | 815/20600 [4:46:38<127:11:00, 23.14s/it]  4%|▍         | 816/20600 [4:46:59<123:54:57, 22.55s/it]  4%|▍         | 817/20600 [4:47:23<126:24:34, 23.00s/it]  4%|▍         | 818/20600 [4:47:43<121:32:38, 22.12s/it]  4%|▍         | 819/20600 [4:48:00<112:50:47, 20.54s/it]  4%|▍         | 820/20600 [4:48:21<114:16:08, 20.80s/it]                                                         {'loss': 0.0, 'learning_rate': 4.987537741136613e-05, 'epoch': 7.9}
  4%|▍         | 820/20600 [4:48:21<114:16:08, 20.80s/it][INFO|trainer.py:3081] 2023-08-16 20:37:24,032 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:37:24,033 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:37:24,033 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1244, 'eval_samples_per_second': 1.697, 'eval_steps_per_second': 0.242, 'epoch': 7.9}
  4%|▍         | 820/20600 [4:48:25<114:16:08, 20.80s/it]
100%|██████████| 1/1 [00:03<00:00,  3.26s/it][A
                                             [A  4%|▍         | 821/20600 [4:48:39<110:18:12, 20.08s/it]  4%|▍         | 822/20600 [4:49:02<114:29:44, 20.84s/it]  4%|▍         | 823/20600 [4:49:23<115:25:47, 21.01s/it]  4%|▍         | 824/20600 [4:49:45<115:56:50, 21.11s/it]  4%|▍         | 825/20600 [4:50:02<109:16:31, 19.89s/it]  4%|▍         | 826/20600 [4:50:16<99:18:13, 18.08s/it]   4%|▍         | 827/20600 [4:50:32<95:48:39, 17.44s/it]  4%|▍         | 828/20600 [4:50:56<107:06:34, 19.50s/it]  4%|▍         | 829/20600 [4:51:20<114:58:34, 20.94s/it]  4%|▍         | 830/20600 [4:51:46<123:36:14, 22.51s/it]                                                         {'loss': 0.0, 'learning_rate': 4.987154638049787e-05, 'epoch': 8.0}
  4%|▍         | 830/20600 [4:51:46<123:36:14, 22.51s/it][INFO|trainer.py:3081] 2023-08-16 20:40:49,415 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:40:49,415 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:40:49,415 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2731, 'eval_samples_per_second': 0.962, 'eval_steps_per_second': 0.137, 'epoch': 8.0}
  4%|▍         | 830/20600 [4:51:54<123:36:14, 22.51s/it]
100%|██████████| 1/1 [00:06<00:00,  6.42s/it][A
                                             [A  4%|▍         | 831/20600 [4:52:14<131:34:34, 23.96s/it]  4%|▍         | 832/20600 [4:52:35<127:47:57, 23.27s/it]  4%|▍         | 833/20600 [4:52:54<120:20:45, 21.92s/it]  4%|▍         | 834/20600 [4:53:12<113:34:39, 20.69s/it]  4%|▍         | 835/20600 [4:53:29<107:49:49, 19.64s/it]  4%|▍         | 836/20600 [4:53:46<103:31:55, 18.86s/it]  4%|▍         | 837/20600 [4:54:08<108:12:48, 19.71s/it]  4%|▍         | 838/20600 [4:54:24<102:17:22, 18.63s/it]  4%|▍         | 839/20600 [4:54:41<100:08:21, 18.24s/it]  4%|▍         | 840/20600 [4:54:58<98:07:44, 17.88s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9867657504338805e-05, 'epoch': 8.1}
  4%|▍         | 840/20600 [4:54:58<98:07:44, 17.88s/it][INFO|trainer.py:3081] 2023-08-16 20:44:01,417 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:44:01,418 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:44:01,418 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                        
                                     [A{'eval_loss': nan, 'eval_runtime': 7.16, 'eval_samples_per_second': 0.978, 'eval_steps_per_second': 0.14, 'epoch': 8.1}
  4%|▍         | 840/20600 [4:55:06<98:07:44, 17.88s/it]
100%|██████████| 1/1 [00:06<00:00,  6.12s/it][A
                                             [A  4%|▍         | 841/20600 [4:55:24<110:33:05, 20.14s/it]  4%|▍         | 842/20600 [4:55:46<114:04:43, 20.79s/it]  4%|▍         | 843/20600 [4:56:03<108:17:20, 19.73s/it]  4%|▍         | 844/20600 [4:56:24<108:57:39, 19.86s/it]  4%|▍         | 845/20600 [4:56:40<102:55:47, 18.76s/it]  4%|▍         | 846/20600 [4:57:06<115:56:42, 21.13s/it]  4%|▍         | 847/20600 [4:57:26<113:41:59, 20.72s/it]  4%|▍         | 848/20600 [4:57:51<119:38:22, 21.81s/it]  4%|▍         | 849/20600 [4:58:21<133:47:57, 24.39s/it]  4%|▍         | 850/20600 [4:58:39<124:04:59, 22.62s/it]                                                         {'loss': 0.0, 'learning_rate': 4.986371079193354e-05, 'epoch': 8.19}
  4%|▍         | 850/20600 [4:58:39<124:04:59, 22.62s/it][INFO|trainer.py:3081] 2023-08-16 20:47:42,410 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:47:42,410 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:47:42,410 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4886, 'eval_samples_per_second': 2.007, 'eval_steps_per_second': 0.287, 'epoch': 8.19}
  4%|▍         | 850/20600 [4:58:43<124:04:59, 22.62s/it]
100%|██████████| 1/1 [00:02<00:00,  2.59s/it][A
                                             [A  4%|▍         | 851/20600 [4:59:07<132:41:11, 24.19s/it]  4%|▍         | 852/20600 [4:59:26<123:32:53, 22.52s/it]  4%|▍         | 853/20600 [4:59:44<115:40:12, 21.09s/it]  4%|▍         | 854/20600 [5:00:01<109:02:14, 19.88s/it]  4%|▍         | 855/20600 [5:00:37<135:39:57, 24.74s/it]  4%|▍         | 856/20600 [5:01:04<139:52:11, 25.50s/it]  4%|▍         | 857/20600 [5:01:24<130:43:44, 23.84s/it]  4%|▍         | 858/20600 [5:01:44<123:45:28, 22.57s/it]  4%|▍         | 859/20600 [5:02:10<130:15:59, 23.76s/it]  4%|▍         | 860/20600 [5:02:28<120:51:47, 22.04s/it]                                                         {'loss': 0.0, 'learning_rate': 4.985970625246119e-05, 'epoch': 8.29}
  4%|▍         | 860/20600 [5:02:28<120:51:47, 22.04s/it][INFO|trainer.py:3081] 2023-08-16 20:51:31,183 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:51:31,184 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:51:31,184 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3857, 'eval_samples_per_second': 2.068, 'eval_steps_per_second': 0.295, 'epoch': 8.29}
  4%|▍         | 860/20600 [5:02:32<120:51:47, 22.04s/it]
100%|██████████| 1/1 [00:02<00:00,  2.55s/it][A
                                             [A  4%|▍         | 861/20600 [5:02:48<117:03:46, 21.35s/it]  4%|▍         | 862/20600 [5:03:14<124:46:58, 22.76s/it]  4%|▍         | 863/20600 [5:03:37<124:30:48, 22.71s/it]  4%|▍         | 864/20600 [5:03:54<115:23:25, 21.05s/it]  4%|▍         | 865/20600 [5:04:14<114:15:33, 20.84s/it]  4%|▍         | 866/20600 [5:04:32<108:41:07, 19.83s/it]  4%|▍         | 867/20600 [5:04:49<104:46:14, 19.11s/it]  4%|▍         | 868/20600 [5:05:09<106:11:24, 19.37s/it]  4%|▍         | 869/20600 [5:05:32<111:45:47, 20.39s/it]  4%|▍         | 870/20600 [5:05:55<116:14:31, 21.21s/it]                                                         {'loss': 0.0, 'learning_rate': 4.985564389523535e-05, 'epoch': 8.39}
  4%|▍         | 870/20600 [5:05:55<116:14:31, 21.21s/it][INFO|trainer.py:3081] 2023-08-16 20:54:57,871 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:54:57,871 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:54:57,871 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4391, 'eval_samples_per_second': 0.941, 'eval_steps_per_second': 0.134, 'epoch': 8.39}
  4%|▍         | 870/20600 [5:06:02<116:14:31, 21.21s/it]
100%|██████████| 1/1 [00:06<00:00,  6.61s/it][A
                                             [A  4%|▍         | 871/20600 [5:06:19<121:45:26, 22.22s/it]  4%|▍         | 872/20600 [5:06:35<110:57:17, 20.25s/it]  4%|▍         | 873/20600 [5:06:51<103:52:46, 18.96s/it]  4%|▍         | 874/20600 [5:07:09<102:58:04, 18.79s/it]  4%|▍         | 875/20600 [5:07:33<111:26:54, 20.34s/it]  4%|▍         | 876/20600 [5:07:52<108:23:13, 19.78s/it]  4%|▍         | 877/20600 [5:08:08<102:33:52, 18.72s/it]  4%|▍         | 878/20600 [5:08:31<109:18:55, 19.95s/it]  4%|▍         | 879/20600 [5:08:46<101:22:11, 18.50s/it]  4%|▍         | 880/20600 [5:09:03<98:27:19, 17.97s/it]                                                         {'loss': 0.0, 'learning_rate': 4.98515237297041e-05, 'epoch': 8.48}
  4%|▍         | 880/20600 [5:09:03<98:27:19, 17.97s/it][INFO|trainer.py:3081] 2023-08-16 20:58:05,812 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 20:58:05,812 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 20:58:05,813 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                        
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1188, 'eval_samples_per_second': 1.7, 'eval_steps_per_second': 0.243, 'epoch': 8.48}
  4%|▍         | 880/20600 [5:09:07<98:27:19, 17.97s/it]
100%|██████████| 1/1 [00:03<00:00,  3.27s/it][A
                                             [A  4%|▍         | 881/20600 [5:09:33<117:43:19, 21.49s/it]  4%|▍         | 882/20600 [5:09:49<110:06:21, 20.10s/it]  4%|▍         | 883/20600 [5:10:06<104:14:58, 19.03s/it]  4%|▍         | 884/20600 [5:10:22<100:07:44, 18.28s/it]  4%|▍         | 885/20600 [5:10:46<108:31:23, 19.82s/it]  4%|▍         | 886/20600 [5:11:04<106:07:29, 19.38s/it]  4%|▍         | 887/20600 [5:11:28<113:05:36, 20.65s/it]  4%|▍         | 888/20600 [5:11:44<105:23:29, 19.25s/it]  4%|▍         | 889/20600 [5:12:00<100:21:30, 18.33s/it]  4%|▍         | 890/20600 [5:12:26<112:28:32, 20.54s/it]                                                         {'loss': 0.0, 'learning_rate': 4.984734576544997e-05, 'epoch': 8.58}
  4%|▍         | 890/20600 [5:12:26<112:28:32, 20.54s/it][INFO|trainer.py:3081] 2023-08-16 21:01:28,685 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:01:28,685 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:01:28,685 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6907, 'eval_samples_per_second': 1.897, 'eval_steps_per_second': 0.271, 'epoch': 8.58}
  4%|▍         | 890/20600 [5:12:29<112:28:32, 20.54s/it]
100%|██████████| 1/1 [00:02<00:00,  2.82s/it][A
                                             [A  4%|▍         | 891/20600 [5:12:49<116:12:15, 21.23s/it]  4%|▍         | 892/20600 [5:13:05<108:24:40, 19.80s/it]  4%|▍         | 893/20600 [5:13:33<121:27:40, 22.19s/it]  4%|▍         | 894/20600 [5:13:48<110:35:23, 20.20s/it]  4%|▍         | 895/20600 [5:14:08<108:53:27, 19.89s/it]  4%|▍         | 896/20600 [5:14:26<107:00:30, 19.55s/it]  4%|▍         | 897/20600 [5:14:51<115:30:42, 21.11s/it]  4%|▍         | 898/20600 [5:15:12<114:59:56, 21.01s/it]  4%|▍         | 899/20600 [5:15:31<111:17:30, 20.34s/it]  4%|▍         | 900/20600 [5:15:52<112:19:13, 20.53s/it]                                                         {'loss': 0.0, 'learning_rate': 4.98431100121899e-05, 'epoch': 8.67}
  4%|▍         | 900/20600 [5:15:52<112:19:13, 20.53s/it][INFO|trainer.py:3081] 2023-08-16 21:04:54,488 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:04:54,488 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:04:54,488 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6732, 'eval_samples_per_second': 1.906, 'eval_steps_per_second': 0.272, 'epoch': 8.67}
  4%|▍         | 900/20600 [5:15:55<112:19:13, 20.53s/it]
100%|██████████| 1/1 [00:02<00:00,  2.84s/it][A
                                             [A  4%|▍         | 901/20600 [5:16:15<116:28:56, 21.29s/it]  4%|▍         | 902/20600 [5:16:41<124:10:53, 22.70s/it]  4%|▍         | 903/20600 [5:17:03<123:38:35, 22.60s/it]  4%|▍         | 904/20600 [5:17:22<118:14:46, 21.61s/it]  4%|▍         | 905/20600 [5:17:47<123:03:55, 22.49s/it]  4%|▍         | 906/20600 [5:18:06<117:05:30, 21.40s/it]  4%|▍         | 907/20600 [5:18:39<136:11:02, 24.90s/it]  4%|▍         | 908/20600 [5:19:01<131:25:25, 24.03s/it]  4%|▍         | 909/20600 [5:19:25<132:17:35, 24.19s/it]  4%|▍         | 910/20600 [5:19:42<119:18:32, 21.81s/it]                                                         {'loss': 0.0, 'learning_rate': 4.983881647977525e-05, 'epoch': 8.77}
  4%|▍         | 910/20600 [5:19:42<119:18:32, 21.81s/it][INFO|trainer.py:3081] 2023-08-16 21:08:44,508 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:08:44,508 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:08:44,509 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6135, 'eval_samples_per_second': 1.517, 'eval_steps_per_second': 0.217, 'epoch': 8.77}
  4%|▍         | 910/20600 [5:19:46<119:18:32, 21.81s/it]
100%|██████████| 1/1 [00:03<00:00,  3.76s/it][A
                                             [A  4%|▍         | 911/20600 [5:20:07<126:03:50, 23.05s/it]  4%|▍         | 912/20600 [5:20:33<129:34:21, 23.69s/it]  4%|▍         | 913/20600 [5:20:51<121:35:57, 22.24s/it]  4%|▍         | 914/20600 [5:21:10<116:02:10, 21.22s/it]  4%|▍         | 915/20600 [5:21:35<121:11:51, 22.16s/it]  4%|▍         | 916/20600 [5:21:53<115:35:01, 21.14s/it]  4%|▍         | 917/20600 [5:22:12<111:38:43, 20.42s/it]  4%|▍         | 918/20600 [5:22:33<112:26:53, 20.57s/it]  4%|▍         | 919/20600 [5:22:52<109:02:05, 19.94s/it]  4%|▍         | 920/20600 [5:23:17<117:42:34, 21.53s/it]                                                         {'loss': 0.0, 'learning_rate': 4.983446517819174e-05, 'epoch': 8.87}
  4%|▍         | 920/20600 [5:23:17<117:42:34, 21.53s/it][INFO|trainer.py:3081] 2023-08-16 21:12:19,823 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:12:19,823 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:12:19,823 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9969, 'eval_samples_per_second': 1.751, 'eval_steps_per_second': 0.25, 'epoch': 8.87}
  4%|▍         | 920/20600 [5:23:21<117:42:34, 21.53s/it]
100%|██████████| 1/1 [00:03<00:00,  3.17s/it][A
                                             [A  4%|▍         | 921/20600 [5:23:34<110:31:02, 20.22s/it]  4%|▍         | 922/20600 [5:23:56<113:43:33, 20.81s/it]  4%|▍         | 923/20600 [5:24:13<107:49:59, 19.73s/it]  4%|▍         | 924/20600 [5:24:35<110:55:28, 20.30s/it]  4%|▍         | 925/20600 [5:24:54<109:21:39, 20.01s/it]  4%|▍         | 926/20600 [5:25:14<108:33:53, 19.87s/it]  4%|▍         | 927/20600 [5:25:32<106:18:53, 19.45s/it]  5%|▍         | 928/20600 [5:25:51<105:20:29, 19.28s/it]  5%|▍         | 929/20600 [5:26:12<108:16:04, 19.81s/it]  5%|▍         | 930/20600 [5:26:32<107:21:33, 19.65s/it]                                                         {'loss': 0.0, 'learning_rate': 4.9830056117559475e-05, 'epoch': 8.96}
  5%|▍         | 930/20600 [5:26:32<107:21:33, 19.65s/it][INFO|trainer.py:3081] 2023-08-16 21:15:34,541 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:15:34,541 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:15:34,541 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.086, 'eval_samples_per_second': 0.866, 'eval_steps_per_second': 0.124, 'epoch': 8.96}
  5%|▍         | 930/20600 [5:26:40<107:21:33, 19.65s/it]
100%|██████████| 1/1 [00:07<00:00,  7.20s/it][A
                                             [A  5%|▍         | 931/20600 [5:27:00<122:00:09, 22.33s/it]  5%|▍         | 932/20600 [5:27:17<112:20:00, 20.56s/it]  5%|▍         | 933/20600 [5:27:39<116:01:31, 21.24s/it]  5%|▍         | 934/20600 [5:27:55<107:34:18, 19.69s/it]  5%|▍         | 935/20600 [5:28:11<101:02:32, 18.50s/it]  5%|▍         | 936/20600 [5:28:34<107:39:57, 19.71s/it]  5%|▍         | 937/20600 [5:28:49<100:47:46, 18.45s/it]  5%|▍         | 938/20600 [5:29:10<103:53:55, 19.02s/it]  5%|▍         | 939/20600 [5:29:31<108:18:15, 19.83s/it]  5%|▍         | 940/20600 [5:29:49<105:01:51, 19.23s/it]                                                         {'loss': 0.0, 'learning_rate': 4.982558930813288e-05, 'epoch': 9.06}
  5%|▍         | 940/20600 [5:29:49<105:01:51, 19.23s/it][INFO|trainer.py:3081] 2023-08-16 21:18:52,144 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:18:52,144 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:18:52,144 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9697, 'eval_samples_per_second': 1.763, 'eval_steps_per_second': 0.252, 'epoch': 9.06}
  5%|▍         | 940/20600 [5:29:53<105:01:51, 19.23s/it]
100%|██████████| 1/1 [00:03<00:00,  3.11s/it][A
                                             [A  5%|▍         | 941/20600 [5:30:12<110:45:38, 20.28s/it]  5%|▍         | 942/20600 [5:30:30<107:36:53, 19.71s/it]  5%|▍         | 943/20600 [5:30:57<118:33:50, 21.71s/it]  5%|▍         | 944/20600 [5:31:13<109:17:44, 20.02s/it]  5%|▍         | 945/20600 [5:31:31<105:55:05, 19.40s/it]  5%|▍         | 946/20600 [5:31:53<111:14:15, 20.38s/it]  5%|▍         | 947/20600 [5:32:09<103:55:13, 19.04s/it]  5%|▍         | 948/20600 [5:32:28<102:41:09, 18.81s/it]  5%|▍         | 949/20600 [5:32:54<114:36:30, 21.00s/it]  5%|▍         | 950/20600 [5:33:11<108:30:25, 19.88s/it]                                                         {'loss': 0.0, 'learning_rate': 4.982106476030068e-05, 'epoch': 9.16}
  5%|▍         | 950/20600 [5:33:11<108:30:25, 19.88s/it][INFO|trainer.py:3081] 2023-08-16 21:22:13,869 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:22:13,870 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:22:13,870 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9532, 'eval_samples_per_second': 1.771, 'eval_steps_per_second': 0.253, 'epoch': 9.16}
  5%|▍         | 950/20600 [5:33:15<108:30:25, 19.88s/it]
100%|██████████| 1/1 [00:02<00:00,  2.97s/it][A
                                             [A  5%|▍         | 951/20600 [5:33:40<123:14:26, 22.58s/it]  5%|▍         | 952/20600 [5:34:00<119:53:32, 21.97s/it]  5%|▍         | 953/20600 [5:34:26<125:40:55, 23.03s/it]  5%|▍         | 954/20600 [5:34:43<115:54:27, 21.24s/it]  5%|▍         | 955/20600 [5:35:08<122:46:48, 22.50s/it]  5%|▍         | 956/20600 [5:35:23<110:01:26, 20.16s/it]  5%|▍         | 957/20600 [5:35:39<103:00:10, 18.88s/it]  5%|▍         | 958/20600 [5:36:04<113:42:27, 20.84s/it]  5%|▍         | 959/20600 [5:36:24<111:19:49, 20.41s/it]  5%|▍         | 960/20600 [5:36:49<118:39:58, 21.75s/it]                                                         {'loss': 0.0, 'learning_rate': 4.98164824845859e-05, 'epoch': 9.25}
  5%|▍         | 960/20600 [5:36:49<118:39:58, 21.75s/it][INFO|trainer.py:3081] 2023-08-16 21:25:51,590 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:25:51,590 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:25:51,590 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5017, 'eval_samples_per_second': 1.999, 'eval_steps_per_second': 0.286, 'epoch': 9.25}
  5%|▍         | 960/20600 [5:36:52<118:39:58, 21.75s/it]
100%|██████████| 1/1 [00:02<00:00,  2.61s/it][A
                                             [A  5%|▍         | 961/20600 [5:37:17<128:59:21, 23.64s/it]  5%|▍         | 962/20600 [5:37:39<127:06:41, 23.30s/it]  5%|▍         | 963/20600 [5:38:01<124:08:28, 22.76s/it]  5%|▍         | 964/20600 [5:38:26<129:02:14, 23.66s/it]  5%|▍         | 965/20600 [5:38:45<120:44:25, 22.14s/it]  5%|▍         | 966/20600 [5:39:03<113:26:03, 20.80s/it]  5%|▍         | 967/20600 [5:39:27<119:18:47, 21.88s/it]  5%|▍         | 968/20600 [5:39:47<116:17:31, 21.32s/it]  5%|▍         | 969/20600 [5:40:10<118:57:31, 21.82s/it]  5%|▍         | 970/20600 [5:40:34<122:13:19, 22.41s/it]                                                         {'loss': 0.0, 'learning_rate': 4.981184249164582e-05, 'epoch': 9.35}
  5%|▍         | 970/20600 [5:40:34<122:13:19, 22.41s/it][INFO|trainer.py:3081] 2023-08-16 21:29:36,869 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:29:36,869 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:29:36,869 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.755, 'eval_samples_per_second': 1.864, 'eval_steps_per_second': 0.266, 'epoch': 9.35}
  5%|▍         | 970/20600 [5:40:38<122:13:19, 22.41s/it]
100%|██████████| 1/1 [00:02<00:00,  2.88s/it][A
                                             [A  5%|▍         | 971/20600 [5:40:59<127:17:14, 23.34s/it]  5%|▍         | 972/20600 [5:41:16<115:48:02, 21.24s/it]  5%|▍         | 973/20600 [5:41:40<121:24:44, 22.27s/it]  5%|▍         | 974/20600 [5:41:58<113:12:19, 20.77s/it]  5%|▍         | 975/20600 [5:42:15<107:44:59, 19.77s/it]  5%|▍         | 976/20600 [5:42:35<108:10:24, 19.84s/it]  5%|▍         | 977/20600 [5:42:56<109:52:26, 20.16s/it]  5%|▍         | 978/20600 [5:43:24<123:00:37, 22.57s/it]  5%|▍         | 979/20600 [5:43:45<120:50:21, 22.17s/it]  5%|▍         | 980/20600 [5:44:11<125:32:35, 23.04s/it]                                                         {'loss': 0.0, 'learning_rate': 4.980714479227196e-05, 'epoch': 9.45}
  5%|▍         | 980/20600 [5:44:11<125:32:35, 23.04s/it][INFO|trainer.py:3081] 2023-08-16 21:33:13,481 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:33:13,481 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:33:13,481 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3749, 'eval_samples_per_second': 2.074, 'eval_steps_per_second': 0.296, 'epoch': 9.45}
  5%|▍         | 980/20600 [5:44:14<125:32:35, 23.04s/it]
100%|██████████| 1/1 [00:02<00:00,  2.51s/it][A
                                             [A  5%|▍         | 981/20600 [5:44:30<119:03:21, 21.85s/it]  5%|▍         | 982/20600 [5:44:46<109:32:31, 20.10s/it]  5%|▍         | 983/20600 [5:45:06<109:12:26, 20.04s/it]  5%|▍         | 984/20600 [5:45:24<106:48:42, 19.60s/it]  5%|▍         | 985/20600 [5:45:44<106:32:59, 19.56s/it]  5%|▍         | 986/20600 [5:46:00<100:54:09, 18.52s/it]  5%|▍         | 987/20600 [5:46:18<100:45:36, 18.49s/it]  5%|▍         | 988/20600 [5:46:41<108:32:16, 19.92s/it]  5%|▍         | 989/20600 [5:47:02<109:04:09, 20.02s/it]  5%|▍         | 990/20600 [5:47:22<108:58:26, 20.01s/it]                                                         {'loss': 0.0, 'learning_rate': 4.980238939739005e-05, 'epoch': 9.54}
  5%|▍         | 990/20600 [5:47:22<108:58:26, 20.01s/it][INFO|trainer.py:3081] 2023-08-16 21:36:24,521 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:36:24,521 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:36:24,521 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6724, 'eval_samples_per_second': 1.906, 'eval_steps_per_second': 0.272, 'epoch': 9.54}
  5%|▍         | 990/20600 [5:47:25<108:58:26, 20.01s/it]
100%|██████████| 1/1 [00:02<00:00,  2.80s/it][A
                                             [A  5%|▍         | 991/20600 [5:47:52<125:21:52, 23.02s/it]  5%|▍         | 992/20600 [5:48:10<117:35:56, 21.59s/it]  5%|▍         | 993/20600 [5:48:37<126:50:08, 23.29s/it]  5%|▍         | 994/20600 [5:48:56<118:55:38, 21.84s/it]  5%|▍         | 995/20600 [5:49:13<111:17:03, 20.43s/it]  5%|▍         | 996/20600 [5:49:35<114:04:25, 20.95s/it]  5%|▍         | 997/20600 [5:49:51<105:31:25, 19.38s/it]  5%|▍         | 998/20600 [5:50:11<107:41:18, 19.78s/it]  5%|▍         | 999/20600 [5:50:28<101:54:28, 18.72s/it]  5%|▍         | 1000/20600 [5:51:00<124:10:15, 22.81s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9797576318060004e-05, 'epoch': 9.64}
  5%|▍         | 1000/20600 [5:51:00<124:10:15, 22.81s/it][INFO|trainer.py:3081] 2023-08-16 21:40:02,864 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:40:02,864 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:40:02,864 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.7787, 'eval_samples_per_second': 1.033, 'eval_steps_per_second': 0.148, 'epoch': 9.64}
  5%|▍         | 1000/20600 [5:51:07<124:10:15, 22.81s/it]
100%|██████████| 1/1 [00:05<00:00,  5.93s/it][A
                                             [A  5%|▍         | 1001/20600 [5:51:23<124:21:44, 22.84s/it]  5%|▍         | 1002/20600 [5:51:39<113:44:19, 20.89s/it]  5%|▍         | 1003/20600 [5:52:06<123:23:36, 22.67s/it]  5%|▍         | 1004/20600 [5:52:30<125:09:23, 22.99s/it]  5%|▍         | 1005/20600 [5:52:47<115:44:30, 21.26s/it]  5%|▍         | 1006/20600 [5:53:08<115:20:17, 21.19s/it]  5%|▍         | 1007/20600 [5:53:24<106:06:58, 19.50s/it]  5%|▍         | 1008/20600 [5:53:48<113:37:01, 20.88s/it]  5%|▍         | 1009/20600 [5:54:07<111:18:31, 20.45s/it]  5%|▍         | 1010/20600 [5:54:33<119:41:37, 22.00s/it]                                                          {'loss': 0.0, 'learning_rate': 4.97927055654759e-05, 'epoch': 9.73}
  5%|▍         | 1010/20600 [5:54:33<119:41:37, 22.00s/it][INFO|trainer.py:3081] 2023-08-16 21:43:35,646 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:43:35,646 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:43:35,646 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.474, 'eval_samples_per_second': 0.826, 'eval_steps_per_second': 0.118, 'epoch': 9.73}
  5%|▍         | 1010/20600 [5:54:41<119:41:37, 22.00s/it]
100%|██████████| 1/1 [00:07<00:00,  7.62s/it][A
                                             [A  5%|▍         | 1011/20600 [5:54:56<121:38:08, 22.35s/it]  5%|▍         | 1012/20600 [5:55:17<120:06:53, 22.08s/it]  5%|▍         | 1013/20600 [5:55:41<123:23:22, 22.68s/it]  5%|▍         | 1014/20600 [5:56:04<122:48:06, 22.57s/it]  5%|▍         | 1015/20600 [5:56:23<117:41:35, 21.63s/it]  5%|▍         | 1016/20600 [5:56:57<136:51:13, 25.16s/it]  5%|▍         | 1017/20600 [5:57:13<123:23:50, 22.68s/it]  5%|▍         | 1018/20600 [5:57:38<126:02:59, 23.17s/it]  5%|▍         | 1019/20600 [5:57:55<117:05:17, 21.53s/it]  5%|▍         | 1020/20600 [5:58:13<110:59:09, 20.41s/it]                                                          {'loss': 0.0, 'learning_rate': 4.978777715096594e-05, 'epoch': 9.83}
  5%|▍         | 1020/20600 [5:58:13<110:59:09, 20.41s/it][INFO|trainer.py:3081] 2023-08-16 21:47:16,186 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:47:16,186 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:47:16,186 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3169, 'eval_samples_per_second': 0.842, 'eval_steps_per_second': 0.12, 'epoch': 9.83}
  5%|▍         | 1020/20600 [5:58:22<110:59:09, 20.41s/it]
100%|██████████| 1/1 [00:07<00:00,  7.39s/it][A
                                             [A  5%|▍         | 1021/20600 [5:58:37<116:32:06, 21.43s/it]  5%|▍         | 1022/20600 [5:58:58<115:08:35, 21.17s/it]  5%|▍         | 1023/20600 [5:59:22<119:40:09, 22.01s/it]  5%|▍         | 1024/20600 [5:59:38<110:37:07, 20.34s/it]  5%|▍         | 1025/20600 [5:59:59<111:44:54, 20.55s/it]  5%|▍         | 1026/20600 [6:00:20<113:04:59, 20.80s/it]  5%|▍         | 1027/20600 [6:00:37<105:29:15, 19.40s/it]  5%|▍         | 1028/20600 [6:01:01<113:56:02, 20.96s/it]  5%|▍         | 1029/20600 [6:01:18<106:51:49, 19.66s/it]  5%|▌         | 1030/20600 [6:01:35<102:47:19, 18.91s/it]                                                          {'loss': 0.0, 'learning_rate': 4.978279108599244e-05, 'epoch': 9.93}
  5%|▌         | 1030/20600 [6:01:35<102:47:19, 18.91s/it][INFO|trainer.py:3081] 2023-08-16 21:50:37,919 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:50:37,920 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:50:37,920 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.742, 'eval_samples_per_second': 1.871, 'eval_steps_per_second': 0.267, 'epoch': 9.93}
  5%|▌         | 1030/20600 [6:01:39<102:47:19, 18.91s/it]
100%|██████████| 1/1 [00:02<00:00,  2.84s/it][A
                                             [A  5%|▌         | 1031/20600 [6:01:56<106:53:23, 19.66s/it]  5%|▌         | 1032/20600 [6:02:22<116:20:38, 21.40s/it]  5%|▌         | 1033/20600 [6:02:40<110:50:35, 20.39s/it]  5%|▌         | 1034/20600 [6:03:02<113:56:47, 20.97s/it]  5%|▌         | 1035/20600 [6:03:21<109:43:32, 20.19s/it]  5%|▌         | 1036/20600 [6:03:38<105:05:13, 19.34s/it]  5%|▌         | 1037/20600 [6:04:01<110:58:27, 20.42s/it]  5%|▌         | 1038/20600 [6:04:15<99:56:37, 18.39s/it]   5%|▌         | 1039/20600 [6:04:40<112:06:16, 20.63s/it]  5%|▌         | 1040/20600 [6:05:02<113:57:19, 20.97s/it]                                                          {'loss': 0.0, 'learning_rate': 4.977774738215182e-05, 'epoch': 10.02}
  5%|▌         | 1040/20600 [6:05:02<113:57:19, 20.97s/it][INFO|trainer.py:3081] 2023-08-16 21:54:05,105 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:54:05,105 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:54:05,105 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.9462, 'eval_samples_per_second': 1.415, 'eval_steps_per_second': 0.202, 'epoch': 10.02}
  5%|▌         | 1040/20600 [6:05:07<113:57:19, 20.97s/it]
100%|██████████| 1/1 [00:04<00:00,  4.09s/it][A
                                             [A  5%|▌         | 1041/20600 [6:05:27<120:45:12, 22.23s/it]  5%|▌         | 1042/20600 [6:05:44<112:27:18, 20.70s/it]  5%|▌         | 1043/20600 [6:06:06<113:44:11, 20.94s/it]  5%|▌         | 1044/20600 [6:06:24<108:17:39, 19.94s/it]  5%|▌         | 1045/20600 [6:06:41<103:34:40, 19.07s/it]  5%|▌         | 1046/20600 [6:06:59<102:19:16, 18.84s/it]  5%|▌         | 1047/20600 [6:07:24<113:11:22, 20.84s/it]  5%|▌         | 1048/20600 [6:07:44<112:00:06, 20.62s/it]  5%|▌         | 1049/20600 [6:08:04<110:08:52, 20.28s/it]  5%|▌         | 1050/20600 [6:08:27<114:43:06, 21.12s/it]                                                          {'loss': 0.0, 'learning_rate': 4.977264605117452e-05, 'epoch': 10.12}
  5%|▌         | 1050/20600 [6:08:27<114:43:06, 21.12s/it][INFO|trainer.py:3081] 2023-08-16 21:57:30,031 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 21:57:30,031 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 21:57:30,031 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.1867, 'eval_samples_per_second': 0.762, 'eval_steps_per_second': 0.109, 'epoch': 10.12}
  5%|▌         | 1050/20600 [6:08:36<114:43:06, 21.12s/it]
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A
                                             [A  5%|▌         | 1051/20600 [6:08:59<132:58:58, 24.49s/it]  5%|▌         | 1052/20600 [6:09:23<132:16:52, 24.36s/it]  5%|▌         | 1053/20600 [6:09:46<128:42:33, 23.70s/it]  5%|▌         | 1054/20600 [6:10:04<119:45:13, 22.06s/it]  5%|▌         | 1055/20600 [6:10:28<122:37:25, 22.59s/it]  5%|▌         | 1056/20600 [6:10:58<135:10:54, 24.90s/it]  5%|▌         | 1057/20600 [6:11:23<135:01:36, 24.87s/it]  5%|▌         | 1058/20600 [6:11:52<142:09:31, 26.19s/it]  5%|▌         | 1059/20600 [6:12:14<135:00:51, 24.87s/it]  5%|▌         | 1060/20600 [6:12:32<123:33:48, 22.77s/it]                                                          {'loss': 0.0, 'learning_rate': 4.976748710492501e-05, 'epoch': 10.22}
  5%|▌         | 1060/20600 [6:12:32<123:33:48, 22.77s/it][INFO|trainer.py:3081] 2023-08-16 22:01:34,656 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:01:34,656 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:01:34,656 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.9546, 'eval_samples_per_second': 0.782, 'eval_steps_per_second': 0.112, 'epoch': 10.22}
  5%|▌         | 1060/20600 [6:12:41<123:33:48, 22.77s/it]
100%|██████████| 1/1 [00:08<00:00,  8.09s/it][A
                                             [A  5%|▌         | 1061/20600 [6:12:55<125:14:02, 23.07s/it]  5%|▌         | 1062/20600 [6:13:16<120:44:30, 22.25s/it]  5%|▌         | 1063/20600 [6:13:34<114:11:10, 21.04s/it]  5%|▌         | 1064/20600 [6:13:55<114:43:51, 21.14s/it]  5%|▌         | 1065/20600 [6:14:12<107:50:02, 19.87s/it]  5%|▌         | 1066/20600 [6:14:35<112:15:15, 20.69s/it]  5%|▌         | 1067/20600 [6:15:02<123:28:41, 22.76s/it]  5%|▌         | 1068/20600 [6:15:21<116:56:57, 21.56s/it]  5%|▌         | 1069/20600 [6:15:40<113:02:59, 20.84s/it]  5%|▌         | 1070/20600 [6:16:06<121:17:04, 22.36s/it]                                                          {'loss': 0.0, 'learning_rate': 4.976227055540179e-05, 'epoch': 10.31}
  5%|▌         | 1070/20600 [6:16:06<121:17:04, 22.36s/it][INFO|trainer.py:3081] 2023-08-16 22:05:09,278 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:05:09,278 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:05:09,278 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3617, 'eval_samples_per_second': 2.082, 'eval_steps_per_second': 0.297, 'epoch': 10.31}
  5%|▌         | 1070/20600 [6:16:10<121:17:04, 22.36s/it]
100%|██████████| 1/1 [00:02<00:00,  2.50s/it][A
                                             [A  5%|▌         | 1071/20600 [6:16:24<113:55:11, 21.00s/it]  5%|▌         | 1072/20600 [6:16:50<121:25:34, 22.38s/it]  5%|▌         | 1073/20600 [6:17:07<113:43:31, 20.97s/it]  5%|▌         | 1074/20600 [6:17:31<117:28:22, 21.66s/it]  5%|▌         | 1075/20600 [6:17:46<107:00:52, 19.73s/it]  5%|▌         | 1076/20600 [6:18:01<100:07:07, 18.46s/it]  5%|▌         | 1077/20600 [6:18:29<114:19:31, 21.08s/it]  5%|▌         | 1078/20600 [6:18:44<104:32:09, 19.28s/it]  5%|▌         | 1079/20600 [6:19:13<121:27:46, 22.40s/it]  5%|▌         | 1080/20600 [6:19:33<117:19:10, 21.64s/it]                                                          {'loss': 0.0, 'learning_rate': 4.97569964147373e-05, 'epoch': 10.41}
  5%|▌         | 1080/20600 [6:19:33<117:19:10, 21.64s/it][INFO|trainer.py:3081] 2023-08-16 22:08:36,192 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:08:36,193 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:08:36,193 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3899, 'eval_samples_per_second': 2.065, 'eval_steps_per_second': 0.295, 'epoch': 10.41}
  5%|▌         | 1080/20600 [6:19:37<117:19:10, 21.64s/it]
100%|██████████| 1/1 [00:02<00:00,  2.51s/it][A
                                             [A  5%|▌         | 1081/20600 [6:19:55<118:17:30, 21.82s/it]  5%|▌         | 1082/20600 [6:20:15<114:31:59, 21.13s/it]  5%|▌         | 1083/20600 [6:20:39<119:23:02, 22.02s/it]  5%|▌         | 1084/20600 [6:21:00<117:09:10, 21.61s/it]  5%|▌         | 1085/20600 [6:21:21<116:47:14, 21.54s/it]  5%|▌         | 1086/20600 [6:21:39<110:24:24, 20.37s/it]  5%|▌         | 1087/20600 [6:22:00<112:21:50, 20.73s/it]  5%|▌         | 1088/20600 [6:22:22<113:15:03, 20.89s/it]  5%|▌         | 1089/20600 [6:22:42<112:24:08, 20.74s/it]  5%|▌         | 1090/20600 [6:23:01<109:14:08, 20.16s/it]                                                          {'loss': 0.0, 'learning_rate': 4.975166469519793e-05, 'epoch': 10.51}
  5%|▌         | 1090/20600 [6:23:01<109:14:08, 20.16s/it][INFO|trainer.py:3081] 2023-08-16 22:12:03,747 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:12:03,748 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:12:03,748 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.7803, 'eval_samples_per_second': 1.464, 'eval_steps_per_second': 0.209, 'epoch': 10.51}
  5%|▌         | 1090/20600 [6:23:06<109:14:08, 20.16s/it]
100%|██████████| 1/1 [00:03<00:00,  3.87s/it][A
                                             [A  5%|▌         | 1091/20600 [6:23:23<112:44:25, 20.80s/it]  5%|▌         | 1092/20600 [6:23:45<114:37:19, 21.15s/it]  5%|▌         | 1093/20600 [6:24:02<108:32:38, 20.03s/it]  5%|▌         | 1094/20600 [6:24:19<102:10:03, 18.86s/it]  5%|▌         | 1095/20600 [6:24:38<102:29:00, 18.92s/it]  5%|▌         | 1096/20600 [6:24:56<101:57:45, 18.82s/it]  5%|▌         | 1097/20600 [6:25:13<97:57:32, 18.08s/it]   5%|▌         | 1098/20600 [6:25:29<95:37:09, 17.65s/it]  5%|▌         | 1099/20600 [6:25:49<98:57:29, 18.27s/it]  5%|▌         | 1100/20600 [6:26:11<105:20:39, 19.45s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9746275409184e-05, 'epoch': 10.6}
  5%|▌         | 1100/20600 [6:26:11<105:20:39, 19.45s/it][INFO|trainer.py:3081] 2023-08-16 22:15:14,126 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:15:14,127 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:15:14,127 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0148, 'eval_samples_per_second': 1.744, 'eval_steps_per_second': 0.249, 'epoch': 10.6}
  5%|▌         | 1100/20600 [6:26:15<105:20:39, 19.45s/it]
100%|██████████| 1/1 [00:03<00:00,  3.16s/it][A
                                             [A  5%|▌         | 1101/20600 [6:26:43<126:14:34, 23.31s/it]  5%|▌         | 1102/20600 [6:27:04<121:13:16, 22.38s/it]  5%|▌         | 1103/20600 [6:27:22<114:35:58, 21.16s/it]  5%|▌         | 1104/20600 [6:27:40<109:45:22, 20.27s/it]  5%|▌         | 1105/20600 [6:28:01<111:06:04, 20.52s/it]  5%|▌         | 1106/20600 [6:28:20<108:15:10, 19.99s/it]  5%|▌         | 1107/20600 [6:28:39<106:41:34, 19.70s/it]  5%|▌         | 1108/20600 [6:29:01<109:40:59, 20.26s/it]  5%|▌         | 1109/20600 [6:29:20<107:40:38, 19.89s/it]  5%|▌         | 1110/20600 [6:29:42<111:23:38, 20.58s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9740828569229695e-05, 'epoch': 10.7}
  5%|▌         | 1110/20600 [6:29:42<111:23:38, 20.58s/it][INFO|trainer.py:3081] 2023-08-16 22:18:44,810 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:18:44,810 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:18:44,810 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2413, 'eval_samples_per_second': 0.967, 'eval_steps_per_second': 0.138, 'epoch': 10.7}
  5%|▌         | 1110/20600 [6:29:49<111:23:38, 20.58s/it]
100%|██████████| 1/1 [00:06<00:00,  6.39s/it][A
                                             [A  5%|▌         | 1111/20600 [6:30:03<112:26:18, 20.77s/it]  5%|▌         | 1112/20600 [6:30:24<112:41:46, 20.82s/it]  5%|▌         | 1113/20600 [6:30:56<131:08:16, 24.23s/it]  5%|▌         | 1114/20600 [6:31:13<119:56:51, 22.16s/it]  5%|▌         | 1115/20600 [6:31:32<113:49:59, 21.03s/it]  5%|▌         | 1116/20600 [6:31:49<106:41:20, 19.71s/it]  5%|▌         | 1117/20600 [6:32:15<118:10:37, 21.84s/it]  5%|▌         | 1118/20600 [6:32:36<115:34:42, 21.36s/it]  5%|▌         | 1119/20600 [6:32:59<118:34:46, 21.91s/it]  5%|▌         | 1120/20600 [6:33:28<130:59:23, 24.21s/it]                                                          {'loss': 0.0, 'learning_rate': 4.973532418800307e-05, 'epoch': 10.8}
  5%|▌         | 1120/20600 [6:33:28<130:59:23, 24.21s/it][INFO|trainer.py:3081] 2023-08-16 22:22:31,308 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:22:31,308 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:22:31,308 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3819, 'eval_samples_per_second': 2.07, 'eval_steps_per_second': 0.296, 'epoch': 10.8}
  5%|▌         | 1120/20600 [6:33:32<130:59:23, 24.21s/it]
100%|██████████| 1/1 [00:02<00:00,  2.52s/it][A
                                             [A  5%|▌         | 1121/20600 [6:33:52<129:52:45, 24.00s/it]  5%|▌         | 1122/20600 [6:34:11<121:19:48, 22.42s/it]  5%|▌         | 1123/20600 [6:34:33<121:52:27, 22.53s/it]  5%|▌         | 1124/20600 [6:34:49<109:57:35, 20.33s/it]  5%|▌         | 1125/20600 [6:35:09<109:26:55, 20.23s/it]  5%|▌         | 1126/20600 [6:35:38<124:43:23, 23.06s/it]  5%|▌         | 1127/20600 [6:35:56<115:49:49, 21.41s/it]  5%|▌         | 1128/20600 [6:36:19<118:20:33, 21.88s/it]  5%|▌         | 1129/20600 [6:36:38<113:48:53, 21.04s/it]  5%|▌         | 1130/20600 [6:36:55<107:36:00, 19.90s/it]                                                          {'loss': 0.0, 'learning_rate': 4.972976227830602e-05, 'epoch': 10.89}
  5%|▌         | 1130/20600 [6:36:55<107:36:00, 19.90s/it][INFO|trainer.py:3081] 2023-08-16 22:25:58,046 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:25:58,046 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:25:58,046 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6585, 'eval_samples_per_second': 1.913, 'eval_steps_per_second': 0.273, 'epoch': 10.89}
  5%|▌         | 1130/20600 [6:36:59<107:36:00, 19.90s/it]
100%|██████████| 1/1 [00:02<00:00,  2.79s/it][A
                                             [A  5%|▌         | 1131/20600 [6:37:19<113:52:58, 21.06s/it]  5%|▌         | 1132/20600 [6:37:37<108:38:59, 20.09s/it]  6%|▌         | 1133/20600 [6:37:54<104:20:53, 19.30s/it]  6%|▌         | 1134/20600 [6:38:13<104:27:31, 19.32s/it]  6%|▌         | 1135/20600 [6:38:31<102:11:10, 18.90s/it]  6%|▌         | 1136/20600 [6:38:53<106:24:53, 19.68s/it]  6%|▌         | 1137/20600 [6:39:14<109:20:02, 20.22s/it]  6%|▌         | 1138/20600 [6:39:34<107:54:01, 19.96s/it]  6%|▌         | 1139/20600 [6:39:54<108:07:57, 20.00s/it]  6%|▌         | 1140/20600 [6:40:15<109:43:38, 20.30s/it]                                                          {'loss': 0.0, 'learning_rate': 4.97241428530742e-05, 'epoch': 10.99}
  6%|▌         | 1140/20600 [6:40:15<109:43:38, 20.30s/it][INFO|trainer.py:3081] 2023-08-16 22:29:17,821 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:29:17,821 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:29:17,821 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4978, 'eval_samples_per_second': 0.934, 'eval_steps_per_second': 0.133, 'epoch': 10.99}
  6%|▌         | 1140/20600 [6:40:22<109:43:38, 20.30s/it]
100%|██████████| 1/1 [00:06<00:00,  6.62s/it][A
                                             [A  6%|▌         | 1141/20600 [6:40:44<123:58:39, 22.94s/it]  6%|▌         | 1142/20600 [6:41:05<121:03:48, 22.40s/it]  6%|▌         | 1143/20600 [6:41:31<126:48:09, 23.46s/it]  6%|▌         | 1144/20600 [6:41:49<118:30:45, 21.93s/it]  6%|▌         | 1145/20600 [6:42:08<113:50:08, 21.06s/it]  6%|▌         | 1146/20600 [6:42:31<116:07:13, 21.49s/it]  6%|▌         | 1147/20600 [6:42:47<107:08:19, 19.83s/it]  6%|▌         | 1148/20600 [6:43:09<110:40:14, 20.48s/it]  6%|▌         | 1149/20600 [6:43:26<105:25:03, 19.51s/it]  6%|▌         | 1150/20600 [6:43:47<108:26:46, 20.07s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9718465925377064e-05, 'epoch': 11.08}
  6%|▌         | 1150/20600 [6:43:47<108:26:46, 20.07s/it][INFO|trainer.py:3081] 2023-08-16 22:32:50,458 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:32:50,458 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:32:50,458 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.9184, 'eval_samples_per_second': 1.183, 'eval_steps_per_second': 0.169, 'epoch': 11.08}
  6%|▌         | 1150/20600 [6:43:53<108:26:46, 20.07s/it]
100%|██████████| 1/1 [00:05<00:00,  5.08s/it][A
                                             [A  6%|▌         | 1151/20600 [6:44:08<109:23:42, 20.25s/it]  6%|▌         | 1152/20600 [6:44:28<109:13:42, 20.22s/it]  6%|▌         | 1153/20600 [6:44:48<109:00:35, 20.18s/it]  6%|▌         | 1154/20600 [6:45:07<106:51:52, 19.78s/it]  6%|▌         | 1155/20600 [6:45:26<105:09:27, 19.47s/it]  6%|▌         | 1156/20600 [6:45:40<97:01:23, 17.96s/it]   6%|▌         | 1157/20600 [6:45:59<97:16:12, 18.01s/it]  6%|▌         | 1158/20600 [6:46:22<106:09:41, 19.66s/it]  6%|▌         | 1159/20600 [6:46:40<104:07:49, 19.28s/it]  6%|▌         | 1160/20600 [6:46:57<99:57:18, 18.51s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9712731508417785e-05, 'epoch': 11.18}
  6%|▌         | 1160/20600 [6:46:57<99:57:18, 18.51s/it][INFO|trainer.py:3081] 2023-08-16 22:36:00,139 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:36:00,139 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:36:00,139 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8795, 'eval_samples_per_second': 1.804, 'eval_steps_per_second': 0.258, 'epoch': 11.18}
  6%|▌         | 1160/20600 [6:47:01<99:57:18, 18.51s/it]
100%|██████████| 1/1 [00:02<00:00,  2.94s/it][A
                                             [A  6%|▌         | 1161/20600 [6:47:24<113:07:09, 20.95s/it]  6%|▌         | 1162/20600 [6:47:50<121:41:13, 22.54s/it]  6%|▌         | 1163/20600 [6:48:13<122:25:31, 22.67s/it]  6%|▌         | 1164/20600 [6:48:30<113:28:25, 21.02s/it]  6%|▌         | 1165/20600 [6:48:54<117:22:26, 21.74s/it]  6%|▌         | 1166/20600 [6:49:10<107:59:11, 20.00s/it]  6%|▌         | 1167/20600 [6:49:30<108:23:17, 20.08s/it]  6%|▌         | 1168/20600 [6:49:50<108:38:51, 20.13s/it]  6%|▌         | 1169/20600 [6:50:11<109:14:58, 20.24s/it]  6%|▌         | 1170/20600 [6:50:38<121:12:36, 22.46s/it]                                                          {'loss': 0.0, 'learning_rate': 4.970693961553326e-05, 'epoch': 11.28}
  6%|▌         | 1170/20600 [6:50:38<121:12:36, 22.46s/it][INFO|trainer.py:3081] 2023-08-16 22:39:41,180 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:39:41,180 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:39:41,180 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0529, 'eval_samples_per_second': 1.727, 'eval_steps_per_second': 0.247, 'epoch': 11.28}
  6%|▌         | 1170/20600 [6:50:42<121:12:36, 22.46s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A  6%|▌         | 1171/20600 [6:51:04<127:14:04, 23.58s/it]  6%|▌         | 1172/20600 [6:51:26<124:36:58, 23.09s/it]  6%|▌         | 1173/20600 [6:51:49<123:52:59, 22.96s/it]  6%|▌         | 1174/20600 [6:52:03<110:08:47, 20.41s/it]  6%|▌         | 1175/20600 [6:52:30<119:40:21, 22.18s/it]  6%|▌         | 1176/20600 [6:52:52<119:23:28, 22.13s/it]  6%|▌         | 1177/20600 [6:53:10<112:34:15, 20.86s/it]  6%|▌         | 1178/20600 [6:53:28<108:52:26, 20.18s/it]  6%|▌         | 1179/20600 [6:53:46<105:09:19, 19.49s/it]  6%|▌         | 1180/20600 [6:54:06<106:04:35, 19.66s/it]                                                          {'loss': 0.0, 'learning_rate': 4.970109026019406e-05, 'epoch': 11.37}
  6%|▌         | 1180/20600 [6:54:06<106:04:35, 19.66s/it][INFO|trainer.py:3081] 2023-08-16 22:43:09,203 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:43:09,204 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:43:09,204 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.7615, 'eval_samples_per_second': 0.799, 'eval_steps_per_second': 0.114, 'epoch': 11.37}
  6%|▌         | 1180/20600 [6:54:15<106:04:35, 19.66s/it]
100%|██████████| 1/1 [00:07<00:00,  7.84s/it][A
                                             [A  6%|▌         | 1181/20600 [6:54:34<119:46:03, 22.20s/it]  6%|▌         | 1182/20600 [6:54:53<113:51:56, 21.11s/it]  6%|▌         | 1183/20600 [6:55:12<111:14:52, 20.63s/it]  6%|▌         | 1184/20600 [6:55:35<115:02:44, 21.33s/it]  6%|▌         | 1185/20600 [6:55:54<111:00:17, 20.58s/it]  6%|▌         | 1186/20600 [6:56:16<113:08:33, 20.98s/it]  6%|▌         | 1187/20600 [6:56:38<114:15:44, 21.19s/it]  6%|▌         | 1188/20600 [6:56:56<109:15:06, 20.26s/it]  6%|▌         | 1189/20600 [6:57:15<106:55:58, 19.83s/it]  6%|▌         | 1190/20600 [6:57:39<113:30:00, 21.05s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9695183456004366e-05, 'epoch': 11.47}
  6%|▌         | 1190/20600 [6:57:39<113:30:00, 21.05s/it][INFO|trainer.py:3081] 2023-08-16 22:46:41,608 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:46:41,608 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:46:41,608 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.4317, 'eval_samples_per_second': 1.088, 'eval_steps_per_second': 0.155, 'epoch': 11.47}
  6%|▌         | 1190/20600 [6:57:45<113:30:00, 21.05s/it]
100%|██████████| 1/1 [00:05<00:00,  5.55s/it][A
                                             [A  6%|▌         | 1191/20600 [6:58:02<117:18:16, 21.76s/it]  6%|▌         | 1192/20600 [6:58:25<119:40:25, 22.20s/it]  6%|▌         | 1193/20600 [6:58:51<125:15:13, 23.23s/it]  6%|▌         | 1194/20600 [6:59:09<116:45:13, 21.66s/it]  6%|▌         | 1195/20600 [6:59:33<120:34:21, 22.37s/it]  6%|▌         | 1196/20600 [6:59:50<111:31:29, 20.69s/it]  6%|▌         | 1197/20600 [7:00:07<106:09:18, 19.70s/it]  6%|▌         | 1198/20600 [7:00:25<102:48:24, 19.08s/it]  6%|▌         | 1199/20600 [7:00:43<101:41:13, 18.87s/it]  6%|▌         | 1200/20600 [7:01:00<99:03:33, 18.38s/it]                                                          {'loss': 0.0, 'learning_rate': 4.968921921670202e-05, 'epoch': 11.57}
  6%|▌         | 1200/20600 [7:01:00<99:03:33, 18.38s/it][INFO|trainer.py:3081] 2023-08-16 22:50:03,311 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:50:03,311 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:50:03,311 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.7776, 'eval_samples_per_second': 0.9, 'eval_steps_per_second': 0.129, 'epoch': 11.57}
  6%|▌         | 1200/20600 [7:01:08<99:03:33, 18.38s/it]
100%|██████████| 1/1 [00:06<00:00,  6.91s/it][A
                                             [A  6%|▌         | 1201/20600 [7:01:27<112:03:03, 20.79s/it]  6%|▌         | 1202/20600 [7:01:51<117:49:25, 21.87s/it]  6%|▌         | 1203/20600 [7:02:11<114:40:35, 21.28s/it]  6%|▌         | 1204/20600 [7:02:29<109:51:13, 20.39s/it]  6%|▌         | 1205/20600 [7:02:48<106:35:17, 19.78s/it]  6%|▌         | 1206/20600 [7:03:18<123:53:25, 23.00s/it]  6%|▌         | 1207/20600 [7:03:39<120:17:50, 22.33s/it]  6%|▌         | 1208/20600 [7:04:01<119:13:45, 22.13s/it]  6%|▌         | 1209/20600 [7:04:26<125:02:21, 23.21s/it]  6%|▌         | 1210/20600 [7:04:47<120:49:30, 22.43s/it]                                                          {'loss': 0.0, 'learning_rate': 4.968319755615841e-05, 'epoch': 11.66}
  6%|▌         | 1210/20600 [7:04:47<120:49:30, 22.43s/it][INFO|trainer.py:3081] 2023-08-16 22:53:49,990 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:53:49,990 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:53:49,990 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.42, 'eval_samples_per_second': 0.943, 'eval_steps_per_second': 0.135, 'epoch': 11.66}
  6%|▌         | 1210/20600 [7:04:54<120:49:30, 22.43s/it]
100%|██████████| 1/1 [00:06<00:00,  6.52s/it][A
                                             [A  6%|▌         | 1211/20600 [7:05:15<130:18:24, 24.19s/it]  6%|▌         | 1212/20600 [7:05:39<128:41:30, 23.90s/it]  6%|▌         | 1213/20600 [7:05:58<121:28:18, 22.56s/it]  6%|▌         | 1214/20600 [7:06:16<114:49:35, 21.32s/it]  6%|▌         | 1215/20600 [7:06:37<113:18:07, 21.04s/it]  6%|▌         | 1216/20600 [7:07:01<118:04:59, 21.93s/it]  6%|▌         | 1217/20600 [7:07:19<111:27:04, 20.70s/it]  6%|▌         | 1218/20600 [7:07:42<116:17:43, 21.60s/it]  6%|▌         | 1219/20600 [7:08:03<114:29:25, 21.27s/it]  6%|▌         | 1220/20600 [7:08:27<119:53:51, 22.27s/it]                                                          {'loss': 0.0, 'learning_rate': 4.967711848837849e-05, 'epoch': 11.76}
  6%|▌         | 1220/20600 [7:08:27<119:53:51, 22.27s/it][INFO|trainer.py:3081] 2023-08-16 22:57:30,396 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 22:57:30,396 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 22:57:30,396 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9943, 'eval_samples_per_second': 1.753, 'eval_steps_per_second': 0.25, 'epoch': 11.76}
  6%|▌         | 1220/20600 [7:08:31<119:53:51, 22.27s/it]
100%|██████████| 1/1 [00:03<00:00,  3.09s/it][A
                                             [A  6%|▌         | 1221/20600 [7:08:51<121:51:54, 22.64s/it]  6%|▌         | 1222/20600 [7:09:17<126:57:10, 23.59s/it]  6%|▌         | 1223/20600 [7:09:36<119:13:40, 22.15s/it]  6%|▌         | 1224/20600 [7:09:51<109:01:11, 20.26s/it]  6%|▌         | 1225/20600 [7:10:17<117:12:17, 21.78s/it]  6%|▌         | 1226/20600 [7:10:35<112:09:44, 20.84s/it]  6%|▌         | 1227/20600 [7:11:06<127:39:34, 23.72s/it]  6%|▌         | 1228/20600 [7:11:27<123:22:34, 22.93s/it]  6%|▌         | 1229/20600 [7:11:46<117:48:32, 21.89s/it]  6%|▌         | 1230/20600 [7:12:10<120:02:39, 22.31s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9670982027500724e-05, 'epoch': 11.86}
  6%|▌         | 1230/20600 [7:12:10<120:02:39, 22.31s/it][INFO|trainer.py:3081] 2023-08-16 23:01:12,595 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:01:12,595 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:01:12,595 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7048, 'eval_samples_per_second': 1.889, 'eval_steps_per_second': 0.27, 'epoch': 11.86}
  6%|▌         | 1230/20600 [7:12:13<120:02:39, 22.31s/it]
100%|██████████| 1/1 [00:02<00:00,  2.83s/it][A
                                             [A  6%|▌         | 1231/20600 [7:12:30<116:19:57, 21.62s/it]  6%|▌         | 1232/20600 [7:12:56<124:09:47, 23.08s/it]  6%|▌         | 1233/20600 [7:13:12<112:57:47, 21.00s/it]  6%|▌         | 1234/20600 [7:13:29<106:15:00, 19.75s/it]  6%|▌         | 1235/20600 [7:13:49<107:00:23, 19.89s/it]  6%|▌         | 1236/20600 [7:14:06<102:25:43, 19.04s/it]  6%|▌         | 1237/20600 [7:14:25<102:12:24, 19.00s/it]  6%|▌         | 1238/20600 [7:14:46<105:41:30, 19.65s/it]  6%|▌         | 1239/20600 [7:15:09<110:30:09, 20.55s/it]  6%|▌         | 1240/20600 [7:15:34<116:46:24, 21.71s/it]                                                          {'loss': 0.0, 'learning_rate': 4.966478818779704e-05, 'epoch': 11.95}
  6%|▌         | 1240/20600 [7:15:34<116:46:24, 21.71s/it][INFO|trainer.py:3081] 2023-08-16 23:04:36,498 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:04:36,498 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:04:36,498 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8842, 'eval_samples_per_second': 1.802, 'eval_steps_per_second': 0.257, 'epoch': 11.95}
  6%|▌         | 1240/20600 [7:15:37<116:46:24, 21.71s/it]
100%|██████████| 1/1 [00:03<00:00,  3.03s/it][A
                                             [A  6%|▌         | 1241/20600 [7:15:55<117:00:57, 21.76s/it]  6%|▌         | 1242/20600 [7:16:13<109:40:20, 20.40s/it]  6%|▌         | 1243/20600 [7:16:30<104:45:11, 19.48s/it]  6%|▌         | 1244/20600 [7:16:48<102:44:24, 19.11s/it]  6%|▌         | 1245/20600 [7:17:14<113:18:35, 21.08s/it]  6%|▌         | 1246/20600 [7:17:36<114:58:34, 21.39s/it]  6%|▌         | 1247/20600 [7:17:53<107:33:31, 20.01s/it]  6%|▌         | 1248/20600 [7:18:12<105:51:10, 19.69s/it]  6%|▌         | 1249/20600 [7:18:31<105:38:12, 19.65s/it]  6%|▌         | 1250/20600 [7:18:51<105:24:37, 19.61s/it]                                                          {'loss': 0.0, 'learning_rate': 4.965853698367286e-05, 'epoch': 12.05}
  6%|▌         | 1250/20600 [7:18:51<105:24:37, 19.61s/it][INFO|trainer.py:3081] 2023-08-16 23:07:53,763 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:07:53,763 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:07:53,763 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.9996, 'eval_samples_per_second': 1.167, 'eval_steps_per_second': 0.167, 'epoch': 12.05}
  6%|▌         | 1250/20600 [7:18:57<105:24:37, 19.61s/it]
100%|██████████| 1/1 [00:05<00:00,  5.12s/it][A
                                             [A  6%|▌         | 1251/20600 [7:19:19<118:38:13, 22.07s/it]  6%|▌         | 1252/20600 [7:19:38<113:51:00, 21.18s/it]  6%|▌         | 1253/20600 [7:19:59<113:18:10, 21.08s/it]  6%|▌         | 1254/20600 [7:20:19<111:30:04, 20.75s/it]  6%|▌         | 1255/20600 [7:20:36<106:23:16, 19.80s/it]  6%|▌         | 1256/20600 [7:20:57<108:30:27, 20.19s/it]  6%|▌         | 1257/20600 [7:21:19<111:29:24, 20.75s/it]  6%|▌         | 1258/20600 [7:21:38<108:19:12, 20.16s/it]  6%|▌         | 1259/20600 [7:22:00<111:28:23, 20.75s/it]  6%|▌         | 1260/20600 [7:22:20<110:03:46, 20.49s/it]                                                          {'loss': 0.0, 'learning_rate': 4.965222842966698e-05, 'epoch': 12.14}
  6%|▌         | 1260/20600 [7:22:20<110:03:46, 20.49s/it][INFO|trainer.py:3081] 2023-08-16 23:11:23,034 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:11:23,034 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:11:23,034 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.4124, 'eval_samples_per_second': 0.832, 'eval_steps_per_second': 0.119, 'epoch': 12.14}
  6%|▌         | 1260/20600 [7:22:28<110:03:46, 20.49s/it]
100%|██████████| 1/1 [00:07<00:00,  7.53s/it][A
                                             [A  6%|▌         | 1261/20600 [7:22:45<117:24:21, 21.86s/it]  6%|▌         | 1262/20600 [7:23:08<119:19:05, 22.21s/it]  6%|▌         | 1263/20600 [7:23:27<113:23:58, 21.11s/it]  6%|▌         | 1264/20600 [7:23:46<110:04:08, 20.49s/it]  6%|▌         | 1265/20600 [7:24:07<112:03:07, 20.86s/it]  6%|▌         | 1266/20600 [7:24:37<125:20:41, 23.34s/it]  6%|▌         | 1267/20600 [7:24:58<121:47:07, 22.68s/it]  6%|▌         | 1268/20600 [7:25:15<112:37:07, 20.97s/it]  6%|▌         | 1269/20600 [7:25:46<129:27:55, 24.11s/it]  6%|▌         | 1270/20600 [7:26:07<124:29:17, 23.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9645862540451596e-05, 'epoch': 12.24}
  6%|▌         | 1270/20600 [7:26:07<124:29:17, 23.18s/it][INFO|trainer.py:3081] 2023-08-16 23:15:10,146 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:15:10,146 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:15:10,146 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.0456, 'eval_samples_per_second': 1.158, 'eval_steps_per_second': 0.165, 'epoch': 12.24}
  6%|▌         | 1270/20600 [7:26:13<124:29:17, 23.18s/it]
100%|██████████| 1/1 [00:05<00:00,  5.17s/it][A
                                             [A  6%|▌         | 1271/20600 [7:26:28<120:59:54, 22.54s/it]  6%|▌         | 1272/20600 [7:26:52<122:23:18, 22.80s/it]  6%|▌         | 1273/20600 [7:27:13<120:47:33, 22.50s/it]  6%|▌         | 1274/20600 [7:27:35<118:55:28, 22.15s/it]  6%|▌         | 1275/20600 [7:27:48<105:02:21, 19.57s/it]  6%|▌         | 1276/20600 [7:28:12<111:28:46, 20.77s/it]  6%|▌         | 1277/20600 [7:28:29<105:03:51, 19.57s/it]  6%|▌         | 1278/20600 [7:28:52<111:21:28, 20.75s/it]  6%|▌         | 1279/20600 [7:29:10<106:38:00, 19.87s/it]  6%|▌         | 1280/20600 [7:29:35<114:53:51, 21.41s/it]                                                          {'loss': 0.0, 'learning_rate': 4.963943933083225e-05, 'epoch': 12.34}
  6%|▌         | 1280/20600 [7:29:35<114:53:51, 21.41s/it][INFO|trainer.py:3081] 2023-08-16 23:18:37,928 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:18:37,928 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:18:37,928 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3194, 'eval_samples_per_second': 0.956, 'eval_steps_per_second': 0.137, 'epoch': 12.34}
  6%|▌         | 1280/20600 [7:29:42<114:53:51, 21.41s/it]
100%|██████████| 1/1 [00:06<00:00,  6.43s/it][A
                                             [A  6%|▌         | 1281/20600 [7:29:57<115:40:34, 21.56s/it]  6%|▌         | 1282/20600 [7:30:15<109:24:46, 20.39s/it]  6%|▌         | 1283/20600 [7:30:34<107:52:31, 20.10s/it]  6%|▌         | 1284/20600 [7:30:55<109:21:01, 20.38s/it]  6%|▌         | 1285/20600 [7:31:12<103:42:30, 19.33s/it]  6%|▌         | 1286/20600 [7:31:36<111:57:49, 20.87s/it]  6%|▌         | 1287/20600 [7:31:55<108:28:39, 20.22s/it]  6%|▋         | 1288/20600 [7:32:17<110:52:06, 20.67s/it]  6%|▋         | 1289/20600 [7:32:35<106:28:45, 19.85s/it]  6%|▋         | 1290/20600 [7:32:56<108:45:23, 20.28s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9632958815747795e-05, 'epoch': 12.43}
  6%|▋         | 1290/20600 [7:32:56<108:45:23, 20.28s/it][INFO|trainer.py:3081] 2023-08-16 23:21:58,921 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:21:58,921 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:21:58,921 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.5997, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.132, 'epoch': 12.43}
  6%|▋         | 1290/20600 [7:33:04<108:45:23, 20.28s/it]
100%|██████████| 1/1 [00:06<00:00,  6.75s/it][A
                                             [A  6%|▋         | 1291/20600 [7:33:29<128:40:08, 23.99s/it]  6%|▋         | 1292/20600 [7:33:45<116:46:07, 21.77s/it]  6%|▋         | 1293/20600 [7:34:03<110:42:42, 20.64s/it]  6%|▋         | 1294/20600 [7:34:23<109:52:34, 20.49s/it]  6%|▋         | 1295/20600 [7:34:47<114:45:49, 21.40s/it]  6%|▋         | 1296/20600 [7:35:08<114:24:15, 21.34s/it]  6%|▋         | 1297/20600 [7:35:31<116:37:55, 21.75s/it]  6%|▋         | 1298/20600 [7:35:57<123:51:29, 23.10s/it]  6%|▋         | 1299/20600 [7:36:20<122:53:41, 22.92s/it]  6%|▋         | 1300/20600 [7:36:41<119:48:14, 22.35s/it]                                                          {'loss': 0.0, 'learning_rate': 4.962642101027036e-05, 'epoch': 12.53}
  6%|▋         | 1300/20600 [7:36:41<119:48:14, 22.35s/it][INFO|trainer.py:3081] 2023-08-16 23:25:43,507 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:25:43,507 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:25:43,507 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.9119, 'eval_samples_per_second': 1.184, 'eval_steps_per_second': 0.169, 'epoch': 12.53}
  6%|▋         | 1300/20600 [7:36:46<119:48:14, 22.35s/it]
100%|██████████| 1/1 [00:05<00:00,  5.05s/it][A
                                             [A  6%|▋         | 1301/20600 [7:37:01<116:22:03, 21.71s/it]  6%|▋         | 1302/20600 [7:37:21<114:39:39, 21.39s/it]  6%|▋         | 1303/20600 [7:37:42<112:53:08, 21.06s/it]  6%|▋         | 1304/20600 [7:38:04<114:15:27, 21.32s/it]  6%|▋         | 1305/20600 [7:38:25<114:53:54, 21.44s/it]  6%|▋         | 1306/20600 [7:38:42<106:28:53, 19.87s/it]  6%|▋         | 1307/20600 [7:39:01<105:40:29, 19.72s/it]  6%|▋         | 1308/20600 [7:39:21<105:33:15, 19.70s/it]  6%|▋         | 1309/20600 [7:39:38<102:27:44, 19.12s/it]  6%|▋         | 1310/20600 [7:39:58<102:56:35, 19.21s/it]                                                          {'loss': 0.0, 'learning_rate': 4.961982592960535e-05, 'epoch': 12.63}
  6%|▋         | 1310/20600 [7:39:58<102:56:35, 19.21s/it][INFO|trainer.py:3081] 2023-08-16 23:29:00,719 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:29:00,719 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:29:00,719 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8728, 'eval_samples_per_second': 1.807, 'eval_steps_per_second': 0.258, 'epoch': 12.63}
  6%|▋         | 1310/20600 [7:40:02<102:56:35, 19.21s/it]
100%|██████████| 1/1 [00:02<00:00,  2.96s/it][A
                                             [A  6%|▋         | 1311/20600 [7:40:21<109:24:53, 20.42s/it]  6%|▋         | 1312/20600 [7:40:45<115:06:10, 21.48s/it]  6%|▋         | 1313/20600 [7:41:01<107:10:13, 20.00s/it]  6%|▋         | 1314/20600 [7:41:27<116:06:34, 21.67s/it]  6%|▋         | 1315/20600 [7:41:53<122:13:54, 22.82s/it]  6%|▋         | 1316/20600 [7:42:12<117:31:36, 21.94s/it]  6%|▋         | 1317/20600 [7:42:31<112:42:40, 21.04s/it]  6%|▋         | 1318/20600 [7:42:54<114:45:18, 21.43s/it]  6%|▋         | 1319/20600 [7:43:15<113:55:25, 21.27s/it]  6%|▋         | 1320/20600 [7:43:36<113:53:37, 21.27s/it]                                                          {'loss': 0.0, 'learning_rate': 4.961317358909131e-05, 'epoch': 12.72}
  6%|▋         | 1320/20600 [7:43:36<113:53:37, 21.27s/it][INFO|trainer.py:3081] 2023-08-16 23:32:38,860 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:32:38,861 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:32:38,861 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.5217, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.117, 'epoch': 12.72}
  6%|▋         | 1320/20600 [7:43:44<113:53:37, 21.27s/it]
100%|██████████| 1/1 [00:07<00:00,  7.69s/it][A
                                             [A  6%|▋         | 1321/20600 [7:43:58<114:39:35, 21.41s/it]  6%|▋         | 1322/20600 [7:44:24<121:50:07, 22.75s/it]  6%|▋         | 1323/20600 [7:44:39<110:13:41, 20.59s/it]  6%|▋         | 1324/20600 [7:45:03<115:07:47, 21.50s/it]  6%|▋         | 1325/20600 [7:45:19<106:21:52, 19.87s/it]  6%|▋         | 1326/20600 [7:45:42<111:53:10, 20.90s/it]  6%|▋         | 1327/20600 [7:45:59<106:04:22, 19.81s/it]  6%|▋         | 1328/20600 [7:46:17<103:20:09, 19.30s/it]  6%|▋         | 1329/20600 [7:46:43<113:41:16, 21.24s/it]  6%|▋         | 1330/20600 [7:47:09<121:42:27, 22.74s/it]                                                          {'loss': 0.0, 'learning_rate': 4.960646400420003e-05, 'epoch': 12.82}
  6%|▋         | 1330/20600 [7:47:09<121:42:27, 22.74s/it][INFO|trainer.py:3081] 2023-08-16 23:36:12,391 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:36:12,392 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:36:12,392 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.892, 'eval_samples_per_second': 1.799, 'eval_steps_per_second': 0.257, 'epoch': 12.82}
  6%|▋         | 1330/20600 [7:47:13<121:42:27, 22.74s/it]
100%|██████████| 1/1 [00:03<00:00,  3.02s/it][A
                                             [A  6%|▋         | 1331/20600 [7:47:30<118:45:26, 22.19s/it]  6%|▋         | 1332/20600 [7:48:00<130:22:49, 24.36s/it]  6%|▋         | 1333/20600 [7:48:17<119:30:12, 22.33s/it]  6%|▋         | 1334/20600 [7:48:44<126:28:15, 23.63s/it]  6%|▋         | 1335/20600 [7:49:02<117:52:38, 22.03s/it]  6%|▋         | 1336/20600 [7:49:24<117:17:44, 21.92s/it]  6%|▋         | 1337/20600 [7:49:41<109:35:44, 20.48s/it]  6%|▋         | 1338/20600 [7:50:05<115:46:08, 21.64s/it]  6%|▋         | 1339/20600 [7:50:30<119:42:16, 22.37s/it]  7%|▋         | 1340/20600 [7:50:50<116:08:08, 21.71s/it]                                                          {'loss': 0.0, 'learning_rate': 4.95996971905364e-05, 'epoch': 12.92}
  7%|▋         | 1340/20600 [7:50:50<116:08:08, 21.71s/it][INFO|trainer.py:3081] 2023-08-16 23:39:52,645 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:39:52,646 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:39:52,646 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8195, 'eval_samples_per_second': 1.833, 'eval_steps_per_second': 0.262, 'epoch': 12.92}
  7%|▋         | 1340/20600 [7:50:54<116:08:08, 21.71s/it]
100%|██████████| 1/1 [00:02<00:00,  2.94s/it][A
                                             [A  7%|▋         | 1341/20600 [7:51:09<112:04:01, 20.95s/it]  7%|▋         | 1342/20600 [7:51:30<111:49:02, 20.90s/it]  7%|▋         | 1343/20600 [7:51:47<106:44:57, 19.96s/it]  7%|▋         | 1344/20600 [7:52:06<104:36:32, 19.56s/it]  7%|▋         | 1345/20600 [7:52:25<102:53:14, 19.24s/it]  7%|▋         | 1346/20600 [7:52:46<106:58:28, 20.00s/it]  7%|▋         | 1347/20600 [7:53:06<107:11:04, 20.04s/it]  7%|▋         | 1348/20600 [7:53:25<105:00:41, 19.64s/it]  7%|▋         | 1349/20600 [7:53:46<106:23:50, 19.90s/it]  7%|▋         | 1350/20600 [7:54:06<106:43:46, 19.96s/it]                                                          {'loss': 0.0, 'learning_rate': 4.95928731638384e-05, 'epoch': 13.01}
  7%|▋         | 1350/20600 [7:54:06<106:43:46, 19.96s/it][INFO|trainer.py:3081] 2023-08-16 23:43:08,704 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:43:08,705 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:43:08,705 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.656, 'eval_samples_per_second': 0.914, 'eval_steps_per_second': 0.131, 'epoch': 13.01}
  7%|▋         | 1350/20600 [7:54:13<106:43:46, 19.96s/it]
100%|██████████| 1/1 [00:06<00:00,  6.77s/it][A
                                             [A  7%|▋         | 1351/20600 [7:54:30<113:00:50, 21.14s/it]  7%|▋         | 1352/20600 [7:54:52<115:21:31, 21.58s/it]  7%|▋         | 1353/20600 [7:55:10<108:54:12, 20.37s/it]  7%|▋         | 1354/20600 [7:55:37<120:41:59, 22.58s/it]  7%|▋         | 1355/20600 [7:55:51<106:21:22, 19.90s/it]  7%|▋         | 1356/20600 [7:56:08<100:44:01, 18.84s/it]  7%|▋         | 1357/20600 [7:56:27<101:40:50, 19.02s/it]  7%|▋         | 1358/20600 [7:56:45<100:49:44, 18.86s/it]  7%|▋         | 1359/20600 [7:57:05<101:35:32, 19.01s/it]  7%|▋         | 1360/20600 [7:57:22<98:12:29, 18.38s/it]                                                          {'loss': 0.0, 'learning_rate': 4.958599193997712e-05, 'epoch': 13.11}
  7%|▋         | 1360/20600 [7:57:22<98:12:29, 18.38s/it][INFO|trainer.py:3081] 2023-08-16 23:46:24,677 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:46:24,678 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:46:24,678 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4124, 'eval_samples_per_second': 0.944, 'eval_steps_per_second': 0.135, 'epoch': 13.11}
  7%|▋         | 1360/20600 [7:57:29<98:12:29, 18.38s/it]
100%|██████████| 1/1 [00:06<00:00,  6.47s/it][A
                                             [A  7%|▋         | 1361/20600 [7:57:46<107:17:57, 20.08s/it]  7%|▋         | 1362/20600 [7:58:03<102:21:27, 19.15s/it]  7%|▋         | 1363/20600 [7:58:20<99:00:33, 18.53s/it]   7%|▋         | 1364/20600 [7:58:39<99:57:19, 18.71s/it]  7%|▋         | 1365/20600 [7:59:00<104:09:06, 19.49s/it]  7%|▋         | 1366/20600 [7:59:18<102:04:52, 19.11s/it]  7%|▋         | 1367/20600 [7:59:42<109:15:11, 20.45s/it]  7%|▋         | 1368/20600 [7:59:59<103:42:10, 19.41s/it]  7%|▋         | 1369/20600 [8:00:20<106:38:01, 19.96s/it]  7%|▋         | 1370/20600 [8:00:45<114:58:29, 21.52s/it]                                                          {'loss': 0.0, 'learning_rate': 4.957905353495661e-05, 'epoch': 13.2}
  7%|▋         | 1370/20600 [8:00:45<114:58:29, 21.52s/it][INFO|trainer.py:3081] 2023-08-16 23:49:48,437 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:49:48,437 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:49:48,437 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0749, 'eval_samples_per_second': 1.718, 'eval_steps_per_second': 0.245, 'epoch': 13.2}
  7%|▋         | 1370/20600 [8:00:50<114:58:29, 21.52s/it]
100%|██████████| 1/1 [00:03<00:00,  3.22s/it][A
                                             [A  7%|▋         | 1371/20600 [8:01:09<118:09:03, 22.12s/it]  7%|▋         | 1372/20600 [8:01:26<110:24:11, 20.67s/it]  7%|▋         | 1373/20600 [8:01:45<107:40:35, 20.16s/it]  7%|▋         | 1374/20600 [8:02:09<113:23:56, 21.23s/it]  7%|▋         | 1375/20600 [8:02:37<124:39:55, 23.34s/it]  7%|▋         | 1376/20600 [8:03:00<123:52:17, 23.20s/it]  7%|▋         | 1377/20600 [8:03:18<116:01:46, 21.73s/it]  7%|▋         | 1378/20600 [8:03:44<122:02:45, 22.86s/it]  7%|▋         | 1379/20600 [8:04:02<113:38:53, 21.29s/it]  7%|▋         | 1380/20600 [8:04:32<128:12:25, 24.01s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9572057964913975e-05, 'epoch': 13.3}
  7%|▋         | 1380/20600 [8:04:32<128:12:25, 24.01s/it][INFO|trainer.py:3081] 2023-08-16 23:53:34,860 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:53:34,860 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:53:34,860 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0628, 'eval_samples_per_second': 1.723, 'eval_steps_per_second': 0.246, 'epoch': 13.3}
  7%|▋         | 1380/20600 [8:04:36<128:12:25, 24.01s/it]
100%|██████████| 1/1 [00:03<00:00,  3.18s/it][A
                                             [A  7%|▋         | 1381/20600 [8:04:59<133:01:14, 24.92s/it]  7%|▋         | 1382/20600 [8:05:19<124:53:21, 23.39s/it]  7%|▋         | 1383/20600 [8:05:42<124:36:33, 23.34s/it]  7%|▋         | 1384/20600 [8:05:58<112:41:26, 21.11s/it]  7%|▋         | 1385/20600 [8:06:19<112:59:30, 21.17s/it]  7%|▋         | 1386/20600 [8:06:45<119:41:53, 22.43s/it]  7%|▋         | 1387/20600 [8:07:05<116:44:11, 21.87s/it]  7%|▋         | 1388/20600 [8:07:24<112:10:55, 21.02s/it]  7%|▋         | 1389/20600 [8:07:43<108:06:39, 20.26s/it]  7%|▋         | 1390/20600 [8:08:00<102:47:57, 19.26s/it]                                                          {'loss': 0.0, 'learning_rate': 4.956500524611923e-05, 'epoch': 13.4}
  7%|▋         | 1390/20600 [8:08:00<102:47:57, 19.26s/it][INFO|trainer.py:3081] 2023-08-16 23:57:02,559 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-16 23:57:02,559 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-16 23:57:02,559 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.9937, 'eval_samples_per_second': 0.876, 'eval_steps_per_second': 0.125, 'epoch': 13.4}
  7%|▋         | 1390/20600 [8:08:08<102:47:57, 19.26s/it]
100%|██████████| 1/1 [00:07<00:00,  7.09s/it][A
                                             [A  7%|▋         | 1391/20600 [8:08:31<123:01:04, 23.06s/it]  7%|▋         | 1392/20600 [8:08:49<113:21:14, 21.25s/it]  7%|▋         | 1393/20600 [8:09:07<108:14:42, 20.29s/it]  7%|▋         | 1394/20600 [8:09:33<118:12:01, 22.16s/it]  7%|▋         | 1395/20600 [8:09:52<112:52:43, 21.16s/it]  7%|▋         | 1396/20600 [8:10:08<105:15:21, 19.73s/it]  7%|▋         | 1397/20600 [8:10:28<105:17:25, 19.74s/it]  7%|▋         | 1398/20600 [8:10:53<113:26:17, 21.27s/it]  7%|▋         | 1399/20600 [8:11:13<111:40:04, 20.94s/it]  7%|▋         | 1400/20600 [8:11:34<111:30:51, 20.91s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9557895394975334e-05, 'epoch': 13.49}
  7%|▋         | 1400/20600 [8:11:34<111:30:51, 20.91s/it][INFO|trainer.py:3081] 2023-08-17 00:00:36,885 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:00:36,886 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:00:36,886 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0193, 'eval_samples_per_second': 1.742, 'eval_steps_per_second': 0.249, 'epoch': 13.49}
  7%|▋         | 1400/20600 [8:11:38<111:30:51, 20.91s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A  7%|▋         | 1401/20600 [8:11:58<116:53:42, 21.92s/it]  7%|▋         | 1402/20600 [8:12:17<112:25:40, 21.08s/it]  7%|▋         | 1403/20600 [8:12:32<101:49:33, 19.10s/it]  7%|▋         | 1404/20600 [8:13:06<125:20:00, 23.50s/it]  7%|▋         | 1405/20600 [8:13:23<115:05:05, 21.58s/it]  7%|▋         | 1406/20600 [8:13:38<105:51:54, 19.86s/it]  7%|▋         | 1407/20600 [8:13:58<104:54:24, 19.68s/it]  7%|▋         | 1408/20600 [8:14:20<108:54:06, 20.43s/it]  7%|▋         | 1409/20600 [8:14:37<103:20:10, 19.38s/it]  7%|▋         | 1410/20600 [8:14:58<106:28:16, 19.97s/it]                                                          {'loss': 0.0, 'learning_rate': 4.955072842801809e-05, 'epoch': 13.59}
  7%|▋         | 1410/20600 [8:14:58<106:28:16, 19.97s/it][INFO|trainer.py:3081] 2023-08-17 00:04:01,206 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:04:01,206 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:04:01,206 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6831, 'eval_samples_per_second': 1.901, 'eval_steps_per_second': 0.272, 'epoch': 13.59}
  7%|▋         | 1410/20600 [8:15:02<106:28:16, 19.97s/it]
100%|██████████| 1/1 [00:02<00:00,  2.83s/it][A
                                             [A  7%|▋         | 1411/20600 [8:15:18<105:56:43, 19.88s/it]  7%|▋         | 1412/20600 [8:15:38<106:38:48, 20.01s/it]  7%|▋         | 1413/20600 [8:16:11<127:43:55, 23.97s/it]  7%|▋         | 1414/20600 [8:16:35<126:36:08, 23.76s/it]  7%|▋         | 1415/20600 [8:16:50<113:14:28, 21.25s/it]  7%|▋         | 1416/20600 [8:17:04<101:54:38, 19.12s/it]  7%|▋         | 1417/20600 [8:17:26<105:48:04, 19.86s/it]  7%|▋         | 1418/20600 [8:17:42<100:33:08, 18.87s/it]  7%|▋         | 1419/20600 [8:17:59<97:36:16, 18.32s/it]   7%|▋         | 1420/20600 [8:18:17<96:50:37, 18.18s/it]                                                         {'loss': 0.0, 'learning_rate': 4.954350436191617e-05, 'epoch': 13.69}
  7%|▋         | 1420/20600 [8:18:17<96:50:37, 18.18s/it][INFO|trainer.py:3081] 2023-08-17 00:07:20,239 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:07:20,240 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:07:20,240 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0069, 'eval_samples_per_second': 1.747, 'eval_steps_per_second': 0.25, 'epoch': 13.69}
  7%|▋         | 1420/20600 [8:18:21<96:50:37, 18.18s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A  7%|▋         | 1421/20600 [8:18:40<103:49:27, 19.49s/it]  7%|▋         | 1422/20600 [8:19:00<105:21:16, 19.78s/it]  7%|▋         | 1423/20600 [8:19:22<109:15:33, 20.51s/it]  7%|▋         | 1424/20600 [8:19:41<106:40:15, 20.03s/it]  7%|▋         | 1425/20600 [8:20:04<111:04:52, 20.85s/it]  7%|▋         | 1426/20600 [8:20:20<102:30:55, 19.25s/it]  7%|▋         | 1427/20600 [8:20:47<116:09:31, 21.81s/it]  7%|▋         | 1428/20600 [8:21:10<117:11:27, 22.01s/it]  7%|▋         | 1429/20600 [8:21:37<125:33:50, 23.58s/it]  7%|▋         | 1430/20600 [8:21:57<119:47:19, 22.50s/it]                                                          {'loss': 0.0, 'learning_rate': 4.953622321347101e-05, 'epoch': 13.78}
  7%|▋         | 1430/20600 [8:21:57<119:47:19, 22.50s/it][INFO|trainer.py:3081] 2023-08-17 00:11:00,085 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:11:00,086 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:11:00,086 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.013, 'eval_samples_per_second': 0.777, 'eval_steps_per_second': 0.111, 'epoch': 13.78}
  7%|▋         | 1430/20600 [8:22:06<119:47:19, 22.50s/it]
100%|██████████| 1/1 [00:08<00:00,  8.12s/it][A
                                             [A  7%|▋         | 1431/20600 [8:22:23<125:01:47, 23.48s/it]  7%|▋         | 1432/20600 [8:22:41<115:49:08, 21.75s/it]  7%|▋         | 1433/20600 [8:23:02<114:30:13, 21.51s/it]  7%|▋         | 1434/20600 [8:23:21<111:16:08, 20.90s/it]  7%|▋         | 1435/20600 [8:23:40<108:04:39, 20.30s/it]  7%|▋         | 1436/20600 [8:23:57<102:10:09, 19.19s/it]  7%|▋         | 1437/20600 [8:24:12<96:28:45, 18.12s/it]   7%|▋         | 1438/20600 [8:24:44<117:35:05, 22.09s/it]  7%|▋         | 1439/20600 [8:25:01<110:29:05, 20.76s/it]  7%|▋         | 1440/20600 [8:25:19<105:23:15, 19.80s/it]                                                          {'loss': 0.0, 'learning_rate': 4.952888499961684e-05, 'epoch': 13.88}
  7%|▋         | 1440/20600 [8:25:19<105:23:15, 19.80s/it][INFO|trainer.py:3081] 2023-08-17 00:14:21,709 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:14:21,709 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:14:21,709 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0057, 'eval_samples_per_second': 0.777, 'eval_steps_per_second': 0.111, 'epoch': 13.88}
  7%|▋         | 1440/20600 [8:25:28<105:23:15, 19.80s/it]
100%|██████████| 1/1 [00:08<00:00,  8.10s/it][A
                                             [A  7%|▋         | 1441/20600 [8:25:47<118:43:17, 22.31s/it]  7%|▋         | 1442/20600 [8:26:05<112:06:57, 21.07s/it]  7%|▋         | 1443/20600 [8:26:23<106:46:38, 20.07s/it]  7%|▋         | 1444/20600 [8:26:41<103:11:27, 19.39s/it]  7%|▋         | 1445/20600 [8:26:57<98:25:44, 18.50s/it]   7%|▋         | 1446/20600 [8:27:17<101:34:00, 19.09s/it]  7%|▋         | 1447/20600 [8:27:35<98:30:40, 18.52s/it]   7%|▋         | 1448/20600 [8:27:58<106:13:11, 19.97s/it]  7%|▋         | 1449/20600 [8:28:22<112:37:25, 21.17s/it]  7%|▋         | 1450/20600 [8:28:50<122:56:50, 23.11s/it]                                                          {'loss': 0.0, 'learning_rate': 4.952148973742061e-05, 'epoch': 13.98}
  7%|▋         | 1450/20600 [8:28:50<122:56:50, 23.11s/it][INFO|trainer.py:3081] 2023-08-17 00:17:52,628 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:17:52,628 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:17:52,628 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.0429, 'eval_samples_per_second': 1.158, 'eval_steps_per_second': 0.165, 'epoch': 13.98}
  7%|▋         | 1450/20600 [8:28:56<122:56:50, 23.11s/it]
100%|██████████| 1/1 [00:05<00:00,  5.21s/it][A
                                             [A  7%|▋         | 1451/20600 [8:29:13<122:53:44, 23.10s/it]  7%|▋         | 1452/20600 [8:29:31<114:50:40, 21.59s/it]  7%|▋         | 1453/20600 [8:29:57<122:02:52, 22.95s/it]  7%|▋         | 1454/20600 [8:30:22<125:53:27, 23.67s/it]  7%|▋         | 1455/20600 [8:30:45<124:51:27, 23.48s/it]  7%|▋         | 1456/20600 [8:31:05<119:03:24, 22.39s/it]  7%|▋         | 1457/20600 [8:31:23<111:25:22, 20.95s/it]  7%|▋         | 1458/20600 [8:31:41<107:42:47, 20.26s/it]  7%|▋         | 1459/20600 [8:32:03<109:24:00, 20.58s/it]  7%|▋         | 1460/20600 [8:32:17<99:31:47, 18.72s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9514037444081914e-05, 'epoch': 14.07}
  7%|▋         | 1460/20600 [8:32:17<99:31:47, 18.72s/it][INFO|trainer.py:3081] 2023-08-17 00:21:20,067 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:21:20,067 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:21:20,067 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.5089, 'eval_samples_per_second': 0.823, 'eval_steps_per_second': 0.118, 'epoch': 14.07}
  7%|▋         | 1460/20600 [8:32:26<99:31:47, 18.72s/it]
100%|██████████| 1/1 [00:07<00:00,  7.59s/it][A
                                             [A  7%|▋         | 1461/20600 [8:32:43<110:15:04, 20.74s/it]  7%|▋         | 1462/20600 [8:33:04<110:53:49, 20.86s/it]  7%|▋         | 1463/20600 [8:33:33<124:25:14, 23.41s/it]  7%|▋         | 1464/20600 [8:33:54<120:21:42, 22.64s/it]  7%|▋         | 1465/20600 [8:34:15<117:14:59, 22.06s/it]  7%|▋         | 1466/20600 [8:34:33<111:24:54, 20.96s/it]  7%|▋         | 1467/20600 [8:34:50<104:50:41, 19.73s/it]  7%|▋         | 1468/20600 [8:35:11<107:15:48, 20.18s/it]  7%|▋         | 1469/20600 [8:35:30<105:02:33, 19.77s/it]  7%|▋         | 1470/20600 [8:35:53<110:54:16, 20.87s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9506528136933014e-05, 'epoch': 14.17}
  7%|▋         | 1470/20600 [8:35:53<110:54:16, 20.87s/it][INFO|trainer.py:3081] 2023-08-17 00:24:56,301 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:24:56,301 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:24:56,301 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0316, 'eval_samples_per_second': 1.736, 'eval_steps_per_second': 0.248, 'epoch': 14.17}
  7%|▋         | 1470/20600 [8:35:57<110:54:16, 20.87s/it]
100%|██████████| 1/1 [00:03<00:00,  3.21s/it][A
                                             [A  7%|▋         | 1471/20600 [8:36:17<114:36:41, 21.57s/it]  7%|▋         | 1472/20600 [8:36:36<110:39:10, 20.83s/it]  7%|▋         | 1473/20600 [8:36:57<111:29:41, 20.99s/it]  7%|▋         | 1474/20600 [8:37:15<107:03:56, 20.15s/it]  7%|▋         | 1475/20600 [8:37:34<105:23:55, 19.84s/it]  7%|▋         | 1476/20600 [8:37:54<105:39:18, 19.89s/it]  7%|▋         | 1477/20600 [8:38:18<111:26:13, 20.98s/it]  7%|▋         | 1478/20600 [8:38:37<107:58:48, 20.33s/it]  7%|▋         | 1479/20600 [8:38:55<104:32:25, 19.68s/it]  7%|▋         | 1480/20600 [8:39:23<118:29:40, 22.31s/it]                                                          {'loss': 0.0, 'learning_rate': 4.949896183343878e-05, 'epoch': 14.27}
  7%|▋         | 1480/20600 [8:39:23<118:29:40, 22.31s/it][INFO|trainer.py:3081] 2023-08-17 00:28:26,232 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:28:26,232 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:28:26,232 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.3105, 'eval_samples_per_second': 0.752, 'eval_steps_per_second': 0.107, 'epoch': 14.27}
  7%|▋         | 1480/20600 [8:39:33<118:29:40, 22.31s/it]
100%|██████████| 1/1 [00:08<00:00,  8.44s/it][A
                                             [A  7%|▋         | 1481/20600 [8:39:52<128:18:54, 24.16s/it]  7%|▋         | 1482/20600 [8:40:12<121:51:10, 22.95s/it]  7%|▋         | 1483/20600 [8:40:28<111:20:58, 20.97s/it]  7%|▋         | 1484/20600 [8:40:58<124:39:45, 23.48s/it]  7%|▋         | 1485/20600 [8:41:16<115:57:16, 21.84s/it]  7%|▋         | 1486/20600 [8:41:36<113:25:13, 21.36s/it]  7%|▋         | 1487/20600 [8:41:56<111:48:13, 21.06s/it]  7%|▋         | 1488/20600 [8:42:19<115:05:24, 21.68s/it]  7%|▋         | 1489/20600 [8:42:41<115:48:54, 21.82s/it]  7%|▋         | 1490/20600 [8:43:01<112:09:36, 21.13s/it]                                                          {'loss': 0.0, 'learning_rate': 4.949133855119664e-05, 'epoch': 14.36}
  7%|▋         | 1490/20600 [8:43:01<112:09:36, 21.13s/it][INFO|trainer.py:3081] 2023-08-17 00:32:03,902 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:32:03,902 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:32:03,902 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0089, 'eval_samples_per_second': 0.777, 'eval_steps_per_second': 0.111, 'epoch': 14.36}
  7%|▋         | 1490/20600 [8:43:10<112:09:36, 21.13s/it]
100%|██████████| 1/1 [00:08<00:00,  8.11s/it][A
                                             [A  7%|▋         | 1491/20600 [8:43:30<124:56:42, 23.54s/it]  7%|▋         | 1492/20600 [8:43:50<119:42:40, 22.55s/it]  7%|▋         | 1493/20600 [8:44:13<119:20:51, 22.49s/it]  7%|▋         | 1494/20600 [8:44:34<116:57:53, 22.04s/it]  7%|▋         | 1495/20600 [8:45:00<123:02:33, 23.19s/it]  7%|▋         | 1496/20600 [8:45:15<110:05:06, 20.74s/it]  7%|▋         | 1497/20600 [8:45:40<117:15:05, 22.10s/it]  7%|▋         | 1498/20600 [8:46:04<120:49:47, 22.77s/it]  7%|▋         | 1499/20600 [8:46:26<119:25:54, 22.51s/it]  7%|▋         | 1500/20600 [8:46:49<119:53:06, 22.60s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9483658307936504e-05, 'epoch': 14.46}
  7%|▋         | 1500/20600 [8:46:49<119:53:06, 22.60s/it][INFO|trainer.py:3081] 2023-08-17 00:35:51,846 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:35:51,846 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:35:51,846 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2171, 'eval_samples_per_second': 0.97, 'eval_steps_per_second': 0.139, 'epoch': 14.46}
  7%|▋         | 1500/20600 [8:46:56<119:53:06, 22.60s/it]
100%|██████████| 1/1 [00:06<00:00,  6.37s/it][A
                                             [A  7%|▋         | 1501/20600 [8:47:14<124:20:56, 23.44s/it]  7%|▋         | 1502/20600 [8:47:34<118:20:58, 22.31s/it]  7%|▋         | 1503/20600 [8:47:53<113:36:22, 21.42s/it]  7%|▋         | 1504/20600 [8:48:14<112:59:09, 21.30s/it]  7%|▋         | 1505/20600 [8:48:31<106:21:10, 20.05s/it]  7%|▋         | 1506/20600 [8:48:54<110:06:42, 20.76s/it]  7%|▋         | 1507/20600 [8:49:14<109:30:39, 20.65s/it]  7%|▋         | 1508/20600 [8:49:33<106:22:17, 20.06s/it]  7%|▋         | 1509/20600 [8:49:50<102:01:38, 19.24s/it]  7%|▋         | 1510/20600 [8:50:08<98:54:32, 18.65s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9475921121520804e-05, 'epoch': 14.55}
  7%|▋         | 1510/20600 [8:50:08<98:54:32, 18.65s/it][INFO|trainer.py:3081] 2023-08-17 00:39:10,514 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:39:10,514 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:39:10,514 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 7.9416, 'eval_samples_per_second': 0.881, 'eval_steps_per_second': 0.126, 'epoch': 14.55}
  7%|▋         | 1510/20600 [8:50:15<98:54:32, 18.65s/it]
100%|██████████| 1/1 [00:07<00:00,  7.04s/it][A
                                             [A  7%|▋         | 1511/20600 [8:50:38<117:13:15, 22.11s/it]  7%|▋         | 1512/20600 [8:50:59<115:28:19, 21.78s/it]  7%|▋         | 1513/20600 [8:51:18<111:35:53, 21.05s/it]  7%|▋         | 1514/20600 [8:51:37<108:03:35, 20.38s/it]  7%|▋         | 1515/20600 [8:51:54<103:20:30, 19.49s/it]  7%|▋         | 1516/20600 [8:52:12<101:03:55, 19.06s/it]  7%|▋         | 1517/20600 [8:52:30<99:27:11, 18.76s/it]   7%|▋         | 1518/20600 [8:52:48<96:53:53, 18.28s/it]  7%|▋         | 1519/20600 [8:53:09<101:32:54, 19.16s/it]  7%|▋         | 1520/20600 [8:53:29<103:09:47, 19.46s/it]                                                          {'loss': 0.0, 'learning_rate': 4.94681270099444e-05, 'epoch': 14.65}
  7%|▋         | 1520/20600 [8:53:29<103:09:47, 19.46s/it][INFO|trainer.py:3081] 2023-08-17 00:42:31,950 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:42:31,950 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:42:31,950 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0833, 'eval_samples_per_second': 0.988, 'eval_steps_per_second': 0.141, 'epoch': 14.65}
  7%|▋         | 1520/20600 [8:53:36<103:09:47, 19.46s/it]
100%|██████████| 1/1 [00:06<00:00,  6.24s/it][A
                                             [A  7%|▋         | 1521/20600 [8:53:52<108:34:15, 20.49s/it]  7%|▋         | 1522/20600 [8:54:09<103:08:40, 19.46s/it]  7%|▋         | 1523/20600 [8:54:27<101:23:02, 19.13s/it]  7%|▋         | 1524/20600 [8:54:44<96:55:48, 18.29s/it]   7%|▋         | 1525/20600 [8:55:03<98:57:20, 18.68s/it]  7%|▋         | 1526/20600 [8:55:21<97:56:40, 18.49s/it]  7%|▋         | 1527/20600 [8:55:39<96:49:34, 18.28s/it]  7%|▋         | 1528/20600 [8:55:56<95:14:50, 17.98s/it]  7%|▋         | 1529/20600 [8:56:18<101:15:13, 19.11s/it]  7%|▋         | 1530/20600 [8:56:35<97:54:36, 18.48s/it]                                                          {'loss': 0.0, 'learning_rate': 4.946027599133451e-05, 'epoch': 14.75}
  7%|▋         | 1530/20600 [8:56:35<97:54:36, 18.48s/it][INFO|trainer.py:3081] 2023-08-17 00:45:38,047 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:45:38,047 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:45:38,047 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 8.8226, 'eval_samples_per_second': 0.793, 'eval_steps_per_second': 0.113, 'epoch': 14.75}
  7%|▋         | 1530/20600 [8:56:44<97:54:36, 18.48s/it]
100%|██████████| 1/1 [00:07<00:00,  7.98s/it][A
                                             [A  7%|▋         | 1531/20600 [8:57:09<122:20:13, 23.10s/it]  7%|▋         | 1532/20600 [8:57:27<114:35:41, 21.64s/it]  7%|▋         | 1533/20600 [8:57:46<109:59:42, 20.77s/it]  7%|▋         | 1534/20600 [8:58:06<109:17:02, 20.63s/it]  7%|▋         | 1535/20600 [8:58:25<106:09:18, 20.05s/it]  7%|▋         | 1536/20600 [8:58:50<113:25:04, 21.42s/it]  7%|▋         | 1537/20600 [8:59:08<109:28:06, 20.67s/it]  7%|▋         | 1538/20600 [8:59:37<121:45:06, 22.99s/it]  7%|▋         | 1539/20600 [8:59:58<119:24:07, 22.55s/it]  7%|▋         | 1540/20600 [9:00:15<110:03:46, 20.79s/it]                                                          {'loss': 0.0, 'learning_rate': 4.945236808395077e-05, 'epoch': 14.84}
  7%|▋         | 1540/20600 [9:00:15<110:03:46, 20.79s/it][INFO|trainer.py:3081] 2023-08-17 00:49:18,028 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:49:18,028 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:49:18,028 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.056, 'eval_samples_per_second': 0.869, 'eval_steps_per_second': 0.124, 'epoch': 14.84}
  7%|▋         | 1540/20600 [9:00:23<110:03:46, 20.79s/it]
100%|██████████| 1/1 [00:07<00:00,  7.13s/it][A
                                             [A  7%|▋         | 1541/20600 [9:00:49<131:25:39, 24.82s/it]  7%|▋         | 1542/20600 [9:01:10<124:26:51, 23.51s/it]  7%|▋         | 1543/20600 [9:01:40<135:53:31, 25.67s/it]  7%|▋         | 1544/20600 [9:02:00<126:12:50, 23.84s/it]  8%|▊         | 1545/20600 [9:02:25<128:09:07, 24.21s/it]  8%|▊         | 1546/20600 [9:02:43<118:07:54, 22.32s/it]  8%|▊         | 1547/20600 [9:03:10<125:04:04, 23.63s/it]  8%|▊         | 1548/20600 [9:03:27<115:41:27, 21.86s/it]  8%|▊         | 1549/20600 [9:03:43<105:09:48, 19.87s/it]  8%|▊         | 1550/20600 [9:04:08<113:06:28, 21.37s/it]                                                          {'loss': 0.0, 'learning_rate': 4.944440330618507e-05, 'epoch': 14.94}
  8%|▊         | 1550/20600 [9:04:08<113:06:28, 21.37s/it][INFO|trainer.py:3081] 2023-08-17 00:53:10,513 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:53:10,514 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:53:10,514 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.644, 'eval_samples_per_second': 1.921, 'eval_steps_per_second': 0.274, 'epoch': 14.94}
  8%|▊         | 1550/20600 [9:04:11<113:06:28, 21.37s/it]
100%|██████████| 1/1 [00:02<00:00,  2.78s/it][A
                                             [A  8%|▊         | 1551/20600 [9:04:29<112:28:56, 21.26s/it]  8%|▊         | 1552/20600 [9:04:52<115:52:48, 21.90s/it]  8%|▊         | 1553/20600 [9:05:07<105:27:22, 19.93s/it]  8%|▊         | 1554/20600 [9:05:33<115:13:57, 21.78s/it]  8%|▊         | 1555/20600 [9:05:54<113:00:32, 21.36s/it]  8%|▊         | 1556/20600 [9:06:12<108:26:11, 20.50s/it]  8%|▊         | 1557/20600 [9:06:30<104:48:11, 19.81s/it]  8%|▊         | 1558/20600 [9:06:52<106:56:26, 20.22s/it]  8%|▊         | 1559/20600 [9:07:09<102:56:47, 19.46s/it]  8%|▊         | 1560/20600 [9:07:27<100:12:41, 18.95s/it]                                                          {'loss': 0.0, 'learning_rate': 4.943638167656158e-05, 'epoch': 15.04}
  8%|▊         | 1560/20600 [9:07:27<100:12:41, 18.95s/it][INFO|trainer.py:3081] 2023-08-17 00:56:30,022 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:56:30,022 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:56:30,022 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5843, 'eval_samples_per_second': 1.953, 'eval_steps_per_second': 0.279, 'epoch': 15.04}
  8%|▊         | 1560/20600 [9:07:31<100:12:41, 18.95s/it]
100%|██████████| 1/1 [00:02<00:00,  2.66s/it][A
                                             [A  8%|▊         | 1561/20600 [9:07:47<101:06:12, 19.12s/it]  8%|▊         | 1562/20600 [9:08:08<105:12:07, 19.89s/it]  8%|▊         | 1563/20600 [9:08:26<101:38:02, 19.22s/it]  8%|▊         | 1564/20600 [9:08:45<100:54:12, 19.08s/it]  8%|▊         | 1565/20600 [9:09:08<107:28:11, 20.33s/it]  8%|▊         | 1566/20600 [9:09:25<101:35:53, 19.22s/it]  8%|▊         | 1567/20600 [9:09:41<97:13:25, 18.39s/it]   8%|▊         | 1568/20600 [9:10:01<100:13:11, 18.96s/it]  8%|▊         | 1569/20600 [9:10:21<101:30:33, 19.20s/it]  8%|▊         | 1570/20600 [9:10:45<108:37:38, 20.55s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9428303213736706e-05, 'epoch': 15.13}
  8%|▊         | 1570/20600 [9:10:45<108:37:38, 20.55s/it][INFO|trainer.py:3081] 2023-08-17 00:59:47,717 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 00:59:47,717 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 00:59:47,717 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3578, 'eval_samples_per_second': 2.085, 'eval_steps_per_second': 0.298, 'epoch': 15.13}
  8%|▊         | 1570/20600 [9:10:48<108:37:38, 20.55s/it]
100%|██████████| 1/1 [00:02<00:00,  2.48s/it][A
                                             [A  8%|▊         | 1571/20600 [9:11:03<105:10:52, 19.90s/it]  8%|▊         | 1572/20600 [9:11:24<106:18:10, 20.11s/it]  8%|▊         | 1573/20600 [9:11:39<98:45:32, 18.69s/it]   8%|▊         | 1574/20600 [9:12:04<108:36:36, 20.55s/it]  8%|▊         | 1575/20600 [9:12:23<106:04:57, 20.07s/it]  8%|▊         | 1576/20600 [9:12:41<103:10:58, 19.53s/it]  8%|▊         | 1577/20600 [9:13:04<107:56:36, 20.43s/it]  8%|▊         | 1578/20600 [9:13:23<105:45:13, 20.01s/it]  8%|▊         | 1579/20600 [9:13:51<119:30:08, 22.62s/it]  8%|▊         | 1580/20600 [9:14:11<114:24:14, 21.65s/it]                                                          {'loss': 0.0, 'learning_rate': 4.942016793649902e-05, 'epoch': 15.23}
  8%|▊         | 1580/20600 [9:14:11<114:24:14, 21.65s/it][INFO|trainer.py:3081] 2023-08-17 01:03:14,009 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:03:14,010 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:03:14,010 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0383, 'eval_samples_per_second': 0.774, 'eval_steps_per_second': 0.111, 'epoch': 15.23}
  8%|▊         | 1580/20600 [9:14:20<114:24:14, 21.65s/it]
100%|██████████| 1/1 [00:08<00:00,  8.19s/it][A
                                             [A  8%|▊         | 1581/20600 [9:14:42<128:59:09, 24.42s/it]  8%|▊         | 1582/20600 [9:15:02<122:38:54, 23.22s/it]  8%|▊         | 1583/20600 [9:15:23<118:12:38, 22.38s/it]  8%|▊         | 1584/20600 [9:15:41<112:31:27, 21.30s/it]  8%|▊         | 1585/20600 [9:15:59<107:24:53, 20.34s/it]  8%|▊         | 1586/20600 [9:16:21<109:57:56, 20.82s/it]  8%|▊         | 1587/20600 [9:16:39<104:34:49, 19.80s/it]  8%|▊         | 1588/20600 [9:16:56<100:16:30, 18.99s/it]  8%|▊         | 1589/20600 [9:17:20<107:39:05, 20.39s/it]  8%|▊         | 1590/20600 [9:17:39<106:32:07, 20.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.941197586376925e-05, 'epoch': 15.33}
  8%|▊         | 1590/20600 [9:17:39<106:32:07, 20.18s/it][INFO|trainer.py:3081] 2023-08-17 01:06:42,217 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:06:42,217 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:06:42,217 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4765, 'eval_samples_per_second': 2.014, 'eval_steps_per_second': 0.288, 'epoch': 15.33}
  8%|▊         | 1590/20600 [9:17:43<106:32:07, 20.18s/it]
100%|██████████| 1/1 [00:02<00:00,  2.54s/it][A
                                             [A  8%|▊         | 1591/20600 [9:18:07<118:33:11, 22.45s/it]  8%|▊         | 1592/20600 [9:18:22<106:24:11, 20.15s/it]  8%|▊         | 1593/20600 [9:18:46<113:34:03, 21.51s/it]  8%|▊         | 1594/20600 [9:19:06<110:44:58, 20.98s/it]  8%|▊         | 1595/20600 [9:19:29<113:24:49, 21.48s/it]  8%|▊         | 1596/20600 [9:19:48<109:21:37, 20.72s/it]  8%|▊         | 1597/20600 [9:20:06<105:11:24, 19.93s/it]  8%|▊         | 1598/20600 [9:20:25<103:49:24, 19.67s/it]  8%|▊         | 1599/20600 [9:20:52<115:51:54, 21.95s/it]  8%|▊         | 1600/20600 [9:21:11<111:03:27, 21.04s/it]                                                          {'loss': 0.0, 'learning_rate': 4.94037270146002e-05, 'epoch': 15.42}
  8%|▊         | 1600/20600 [9:21:11<111:03:27, 21.04s/it][INFO|trainer.py:3081] 2023-08-17 01:10:14,125 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:10:14,126 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:10:14,126 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0955, 'eval_samples_per_second': 1.709, 'eval_steps_per_second': 0.244, 'epoch': 15.42}
  8%|▊         | 1600/20600 [9:21:15<111:03:27, 21.04s/it]
100%|██████████| 1/1 [00:03<00:00,  3.18s/it][A
                                             [A08/17/2023 01:10:18 - INFO - llmtuner.tuner.core.trainer - Saving model checkpoint to ../outputs/Ihin/Ihin-sft-llama2/checkpoint-1600
  8%|▊         | 1601/20600 [9:21:40<123:12:56, 23.35s/it]  8%|▊         | 1602/20600 [9:21:57<112:58:18, 21.41s/it]  8%|▊         | 1603/20600 [9:22:14<106:13:38, 20.13s/it]  8%|▊         | 1604/20600 [9:22:41<117:25:11, 22.25s/it]  8%|▊         | 1605/20600 [9:23:00<112:40:56, 21.36s/it]  8%|▊         | 1606/20600 [9:23:18<107:15:53, 20.33s/it]  8%|▊         | 1607/20600 [9:23:39<107:56:26, 20.46s/it]  8%|▊         | 1608/20600 [9:24:06<118:43:54, 22.51s/it]  8%|▊         | 1609/20600 [9:24:24<110:27:27, 20.94s/it]  8%|▊         | 1610/20600 [9:24:40<103:03:11, 19.54s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9395421408176736e-05, 'epoch': 15.52}
  8%|▊         | 1610/20600 [9:24:40<103:03:11, 19.54s/it][INFO|trainer.py:3081] 2023-08-17 01:13:42,877 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:13:42,877 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:13:42,877 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9204, 'eval_samples_per_second': 1.786, 'eval_steps_per_second': 0.255, 'epoch': 15.52}
  8%|▊         | 1610/20600 [9:24:44<103:03:11, 19.54s/it]
100%|██████████| 1/1 [00:03<00:00,  3.04s/it][A
                                             [A  8%|▊         | 1611/20600 [9:25:08<116:29:58, 22.09s/it]  8%|▊         | 1612/20600 [9:25:30<115:57:12, 21.98s/it]  8%|▊         | 1613/20600 [9:25:49<111:52:32, 21.21s/it]  8%|▊         | 1614/20600 [9:26:07<106:36:24, 20.21s/it]  8%|▊         | 1615/20600 [9:26:32<114:56:23, 21.80s/it]  8%|▊         | 1616/20600 [9:26:55<116:18:48, 22.06s/it]  8%|▊         | 1617/20600 [9:27:12<108:06:29, 20.50s/it]  8%|▊         | 1618/20600 [9:27:30<104:05:47, 19.74s/it]  8%|▊         | 1619/20600 [9:27:46<98:05:58, 18.61s/it]   8%|▊         | 1620/20600 [9:28:03<95:48:18, 18.17s/it]                                                         {'loss': 0.0, 'learning_rate': 4.93870590638157e-05, 'epoch': 15.61}
  8%|▊         | 1620/20600 [9:28:03<95:48:18, 18.17s/it][INFO|trainer.py:3081] 2023-08-17 01:17:06,061 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:17:06,061 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:17:06,061 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                         
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0595, 'eval_samples_per_second': 1.724, 'eval_steps_per_second': 0.246, 'epoch': 15.61}
  8%|▊         | 1620/20600 [9:28:07<95:48:18, 18.17s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A  8%|▊         | 1621/20600 [9:28:25<102:10:52, 19.38s/it]  8%|▊         | 1622/20600 [9:28:46<105:03:38, 19.93s/it]  8%|▊         | 1623/20600 [9:29:08<106:57:06, 20.29s/it]  8%|▊         | 1624/20600 [9:29:26<103:49:04, 19.70s/it]  8%|▊         | 1625/20600 [9:29:50<110:24:05, 20.95s/it]  8%|▊         | 1626/20600 [9:30:10<108:55:36, 20.67s/it]  8%|▊         | 1627/20600 [9:30:29<106:08:30, 20.14s/it]  8%|▊         | 1628/20600 [9:30:45<100:42:26, 19.11s/it]  8%|▊         | 1629/20600 [9:31:05<101:09:25, 19.20s/it]  8%|▊         | 1630/20600 [9:31:25<103:04:23, 19.56s/it]                                                          {'loss': 0.0, 'learning_rate': 4.937864000096593e-05, 'epoch': 15.71}
  8%|▊         | 1630/20600 [9:31:25<103:04:23, 19.56s/it][INFO|trainer.py:3081] 2023-08-17 01:20:28,216 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:20:28,216 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:20:28,216 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.5494, 'eval_samples_per_second': 1.261, 'eval_steps_per_second': 0.18, 'epoch': 15.71}
  8%|▊         | 1630/20600 [9:31:31<103:04:23, 19.56s/it]
100%|██████████| 1/1 [00:04<00:00,  4.72s/it][A
                                             [A  8%|▊         | 1631/20600 [9:31:49<110:12:22, 20.92s/it]  8%|▊         | 1632/20600 [9:32:07<104:53:30, 19.91s/it]  8%|▊         | 1633/20600 [9:32:24<101:08:30, 19.20s/it]  8%|▊         | 1634/20600 [9:32:45<103:16:46, 19.60s/it]  8%|▊         | 1635/20600 [9:33:06<105:36:24, 20.05s/it]  8%|▊         | 1636/20600 [9:33:23<100:13:30, 19.03s/it]  8%|▊         | 1637/20600 [9:33:40<97:14:55, 18.46s/it]   8%|▊         | 1638/20600 [9:34:05<108:32:23, 20.61s/it]  8%|▊         | 1639/20600 [9:34:22<102:43:47, 19.50s/it]  8%|▊         | 1640/20600 [9:34:51<116:36:56, 22.14s/it]                                                          {'loss': 0.0, 'learning_rate': 4.937016423920815e-05, 'epoch': 15.81}
  8%|▊         | 1640/20600 [9:34:51<116:36:56, 22.14s/it][INFO|trainer.py:3081] 2023-08-17 01:23:53,653 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:23:53,653 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:23:53,653 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6428, 'eval_samples_per_second': 1.922, 'eval_steps_per_second': 0.275, 'epoch': 15.81}
  8%|▊         | 1640/20600 [9:34:54<116:36:56, 22.14s/it]
100%|██████████| 1/1 [00:02<00:00,  2.79s/it][A
                                             [A  8%|▊         | 1641/20600 [9:35:09<110:23:13, 20.96s/it]  8%|▊         | 1642/20600 [9:35:27<106:03:40, 20.14s/it]  8%|▊         | 1643/20600 [9:35:57<121:07:40, 23.00s/it]  8%|▊         | 1644/20600 [9:36:20<121:20:57, 23.05s/it]  8%|▊         | 1645/20600 [9:36:47<127:30:38, 24.22s/it]  8%|▊         | 1646/20600 [9:37:04<115:37:55, 21.96s/it]  8%|▊         | 1647/20600 [9:37:30<123:13:03, 23.40s/it]  8%|▊         | 1648/20600 [9:37:45<109:47:54, 20.86s/it]  8%|▊         | 1649/20600 [9:38:08<113:27:14, 21.55s/it]  8%|▊         | 1650/20600 [9:38:24<104:30:51, 19.85s/it]                                                          {'loss': 0.0, 'learning_rate': 4.936163179825497e-05, 'epoch': 15.9}
  8%|▊         | 1650/20600 [9:38:24<104:30:51, 19.85s/it][INFO|trainer.py:3081] 2023-08-17 01:27:27,313 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:27:27,313 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:27:27,313 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.7359, 'eval_samples_per_second': 0.801, 'eval_steps_per_second': 0.114, 'epoch': 15.9}
  8%|▊         | 1650/20600 [9:38:33<104:30:51, 19.85s/it]
100%|██████████| 1/1 [00:07<00:00,  7.83s/it][A
                                             [A  8%|▊         | 1651/20600 [9:38:53<119:02:35, 22.62s/it]  8%|▊         | 1652/20600 [9:39:19<124:02:43, 23.57s/it]  8%|▊         | 1653/20600 [9:39:38<116:07:57, 22.07s/it]  8%|▊         | 1654/20600 [9:39:56<109:38:04, 20.83s/it]  8%|▊         | 1655/20600 [9:40:18<111:43:23, 21.23s/it]  8%|▊         | 1656/20600 [9:40:37<107:58:49, 20.52s/it]  8%|▊         | 1657/20600 [9:41:00<112:29:58, 21.38s/it]  8%|▊         | 1658/20600 [9:41:18<106:49:16, 20.30s/it]  8%|▊         | 1659/20600 [9:41:44<116:26:29, 22.13s/it]  8%|▊         | 1660/20600 [9:42:02<109:30:16, 20.81s/it]                                                          {'loss': 0.0, 'learning_rate': 4.935304269795081e-05, 'epoch': 16.0}
  8%|▊         | 1660/20600 [9:42:02<109:30:16, 20.81s/it][INFO|trainer.py:3081] 2023-08-17 01:31:05,009 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:31:05,009 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:31:05,009 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.1519, 'eval_samples_per_second': 0.859, 'eval_steps_per_second': 0.123, 'epoch': 16.0}
  8%|▊         | 1660/20600 [9:42:10<109:30:16, 20.81s/it]
100%|██████████| 1/1 [00:07<00:00,  7.29s/it][A
                                             [A  8%|▊         | 1661/20600 [9:42:28<117:37:59, 22.36s/it]  8%|▊         | 1662/20600 [9:42:46<111:24:40, 21.18s/it]  8%|▊         | 1663/20600 [9:43:05<106:35:02, 20.26s/it]  8%|▊         | 1664/20600 [9:43:23<103:38:57, 19.71s/it]  8%|▊         | 1665/20600 [9:43:42<101:53:21, 19.37s/it]  8%|▊         | 1666/20600 [9:43:59<99:27:28, 18.91s/it]   8%|▊         | 1667/20600 [9:44:21<103:23:56, 19.66s/it]  8%|▊         | 1668/20600 [9:44:43<108:07:44, 20.56s/it]  8%|▊         | 1669/20600 [9:45:09<115:32:50, 21.97s/it]  8%|▊         | 1670/20600 [9:45:29<113:12:54, 21.53s/it]                                                          {'loss': 0.0, 'learning_rate': 4.934439695827188e-05, 'epoch': 16.1}
  8%|▊         | 1670/20600 [9:45:29<113:12:54, 21.53s/it][INFO|trainer.py:3081] 2023-08-17 01:34:32,195 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:34:32,195 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:34:32,195 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.4495, 'eval_samples_per_second': 1.085, 'eval_steps_per_second': 0.155, 'epoch': 16.1}
  8%|▊         | 1670/20600 [9:45:36<113:12:54, 21.53s/it]
100%|██████████| 1/1 [00:05<00:00,  5.55s/it][A
                                             [A  8%|▊         | 1671/20600 [9:45:58<123:53:13, 23.56s/it]  8%|▊         | 1672/20600 [9:46:21<123:27:13, 23.48s/it]  8%|▊         | 1673/20600 [9:46:40<117:12:23, 22.29s/it]  8%|▊         | 1674/20600 [9:47:01<113:59:33, 21.68s/it]  8%|▊         | 1675/20600 [9:47:19<108:33:38, 20.65s/it]  8%|▊         | 1676/20600 [9:47:37<104:18:44, 19.84s/it]  8%|▊         | 1677/20600 [9:47:55<102:24:24, 19.48s/it]  8%|▊         | 1678/20600 [9:48:11<96:40:37, 18.39s/it]   8%|▊         | 1679/20600 [9:48:34<103:41:25, 19.73s/it]  8%|▊         | 1680/20600 [9:48:55<106:03:48, 20.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.933569459932609e-05, 'epoch': 16.19}
  8%|▊         | 1680/20600 [9:48:55<106:03:48, 20.18s/it][INFO|trainer.py:3081] 2023-08-17 01:37:58,348 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:37:58,349 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:37:58,349 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.925, 'eval_samples_per_second': 0.883, 'eval_steps_per_second': 0.126, 'epoch': 16.19}
  8%|▊         | 1680/20600 [9:49:03<106:03:48, 20.18s/it]
100%|██████████| 1/1 [00:07<00:00,  7.05s/it][A
                                             [A  8%|▊         | 1681/20600 [9:49:19<111:57:19, 21.30s/it]  8%|▊         | 1682/20600 [9:49:36<103:57:12, 19.78s/it]  8%|▊         | 1683/20600 [9:49:58<108:07:50, 20.58s/it]  8%|▊         | 1684/20600 [9:50:17<106:20:00, 20.24s/it]  8%|▊         | 1685/20600 [9:50:35<101:36:18, 19.34s/it]  8%|▊         | 1686/20600 [9:50:54<101:23:55, 19.30s/it]  8%|▊         | 1687/20600 [9:51:17<107:43:38, 20.51s/it]  8%|▊         | 1688/20600 [9:51:35<103:46:35, 19.75s/it]  8%|▊         | 1689/20600 [9:51:53<100:20:42, 19.10s/it]  8%|▊         | 1690/20600 [9:52:16<107:27:48, 20.46s/it]                                                          {'loss': 0.0, 'learning_rate': 4.932693564135307e-05, 'epoch': 16.29}
  8%|▊         | 1690/20600 [9:52:16<107:27:48, 20.46s/it][INFO|trainer.py:3081] 2023-08-17 01:41:19,354 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:41:19,354 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:41:19,354 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6322, 'eval_samples_per_second': 1.511, 'eval_steps_per_second': 0.216, 'epoch': 16.29}
  8%|▊         | 1690/20600 [9:52:21<107:27:48, 20.46s/it]
100%|██████████| 1/1 [00:03<00:00,  3.80s/it][A
                                             [A  8%|▊         | 1691/20600 [9:52:43<116:31:18, 22.18s/it]  8%|▊         | 1692/20600 [9:53:01<111:10:20, 21.17s/it]  8%|▊         | 1693/20600 [9:53:20<106:23:19, 20.26s/it]  8%|▊         | 1694/20600 [9:53:49<120:22:17, 22.92s/it]  8%|▊         | 1695/20600 [9:54:13<121:58:34, 23.23s/it]  8%|▊         | 1696/20600 [9:54:34<119:21:13, 22.73s/it]  8%|▊         | 1697/20600 [9:54:50<109:05:25, 20.78s/it]  8%|▊         | 1698/20600 [9:55:17<118:28:58, 22.57s/it]  8%|▊         | 1699/20600 [9:55:37<114:31:17, 21.81s/it]  8%|▊         | 1700/20600 [9:56:05<124:08:10, 23.65s/it]                                                          {'loss': 0.0, 'learning_rate': 4.931812010472407e-05, 'epoch': 16.39}
  8%|▊         | 1700/20600 [9:56:05<124:08:10, 23.65s/it][INFO|trainer.py:3081] 2023-08-17 01:45:08,070 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:45:08,070 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:45:08,070 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3552, 'eval_samples_per_second': 2.086, 'eval_steps_per_second': 0.298, 'epoch': 16.39}
  8%|▊         | 1700/20600 [9:56:08<124:08:10, 23.65s/it]
100%|██████████| 1/1 [00:02<00:00,  2.53s/it][A
                                             [A  8%|▊         | 1701/20600 [9:56:26<120:15:02, 22.91s/it]  8%|▊         | 1702/20600 [9:56:46<115:02:27, 21.91s/it]  8%|▊         | 1703/20600 [9:57:03<108:10:10, 20.61s/it]  8%|▊         | 1704/20600 [9:57:21<103:53:05, 19.79s/it]  8%|▊         | 1705/20600 [9:57:47<112:29:46, 21.43s/it]  8%|▊         | 1706/20600 [9:58:06<109:45:29, 20.91s/it]  8%|▊         | 1707/20600 [9:58:33<118:30:23, 22.58s/it]  8%|▊         | 1708/20600 [9:58:52<113:16:00, 21.58s/it]  8%|▊         | 1709/20600 [9:59:09<106:14:47, 20.25s/it]  8%|▊         | 1710/20600 [9:59:34<113:49:19, 21.69s/it]                                                          {'loss': 0.0, 'learning_rate': 4.9309248009941914e-05, 'epoch': 16.48}
  8%|▊         | 1710/20600 [9:59:34<113:49:19, 21.69s/it][INFO|trainer.py:3081] 2023-08-17 01:48:37,190 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:48:37,191 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:48:37,191 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1307, 'eval_samples_per_second': 1.695, 'eval_steps_per_second': 0.242, 'epoch': 16.48}
  8%|▊         | 1710/20600 [9:59:38<113:49:19, 21.69s/it]
100%|██████████| 1/1 [00:03<00:00,  3.25s/it][A
                                             [A  8%|▊         | 1711/20600 [9:59:56<113:57:29, 21.72s/it]  8%|▊         | 1712/20600 [10:00:13<107:01:33, 20.40s/it]  8%|▊         | 1713/20600 [10:00:34<108:09:53, 20.62s/it]  8%|▊         | 1714/20600 [10:00:56<110:12:19, 21.01s/it]  8%|▊         | 1715/20600 [10:01:15<105:54:24, 20.19s/it]  8%|▊         | 1716/20600 [10:01:40<113:54:08, 21.71s/it]  8%|▊         | 1717/20600 [10:01:58<108:45:18, 20.73s/it]  8%|▊         | 1718/20600 [10:02:19<107:59:43, 20.59s/it]  8%|▊         | 1719/20600 [10:02:43<113:38:10, 21.67s/it]  8%|▊         | 1720/20600 [10:03:03<110:35:48, 21.09s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9300319377641005e-05, 'epoch': 16.58}
  8%|▊         | 1720/20600 [10:03:03<110:35:48, 21.09s/it][INFO|trainer.py:3081] 2023-08-17 01:52:05,500 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:52:05,500 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:52:05,500 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6332, 'eval_samples_per_second': 1.511, 'eval_steps_per_second': 0.216, 'epoch': 16.58}
  8%|▊         | 1720/20600 [10:03:07<110:35:48, 21.09s/it]
100%|██████████| 1/1 [00:03<00:00,  3.74s/it][A
                                             [A  8%|▊         | 1721/20600 [10:03:26<114:43:30, 21.88s/it]  8%|▊         | 1722/20600 [10:03:48<113:55:51, 21.73s/it]  8%|▊         | 1723/20600 [10:04:06<108:33:31, 20.70s/it]  8%|▊         | 1724/20600 [10:04:28<111:03:16, 21.18s/it]  8%|▊         | 1725/20600 [10:04:48<108:18:42, 20.66s/it]  8%|▊         | 1726/20600 [10:05:09<109:14:47, 20.84s/it]  8%|▊         | 1727/20600 [10:05:30<110:05:34, 21.00s/it]  8%|▊         | 1728/20600 [10:05:46<102:24:32, 19.54s/it]  8%|▊         | 1729/20600 [10:06:09<107:48:43, 20.57s/it]  8%|▊         | 1730/20600 [10:06:28<105:22:32, 20.10s/it]                                                           {'loss': 0.0, 'learning_rate': 4.929133422858718e-05, 'epoch': 16.67}
  8%|▊         | 1730/20600 [10:06:28<105:22:32, 20.10s/it][INFO|trainer.py:3081] 2023-08-17 01:55:31,392 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:55:31,392 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:55:31,392 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.7096, 'eval_samples_per_second': 1.486, 'eval_steps_per_second': 0.212, 'epoch': 16.67}
  8%|▊         | 1730/20600 [10:06:33<105:22:32, 20.10s/it]
100%|██████████| 1/1 [00:03<00:00,  3.82s/it][A
                                             [A  8%|▊         | 1731/20600 [10:06:51<109:31:34, 20.90s/it]  8%|▊         | 1732/20600 [10:07:09<104:51:49, 20.01s/it]  8%|▊         | 1733/20600 [10:07:29<103:57:04, 19.83s/it]  8%|▊         | 1734/20600 [10:07:44<97:42:35, 18.64s/it]   8%|▊         | 1735/20600 [10:08:05<100:20:36, 19.15s/it]  8%|▊         | 1736/20600 [10:08:25<101:26:30, 19.36s/it]  8%|▊         | 1737/20600 [10:08:43<100:00:06, 19.09s/it]  8%|▊         | 1738/20600 [10:09:01<97:28:59, 18.61s/it]   8%|▊         | 1739/20600 [10:09:22<102:05:59, 19.49s/it]  8%|▊         | 1740/20600 [10:09:39<97:49:06, 18.67s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9282292583677785e-05, 'epoch': 16.77}
  8%|▊         | 1740/20600 [10:09:39<97:49:06, 18.67s/it][INFO|trainer.py:3081] 2023-08-17 01:58:41,788 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 01:58:41,788 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 01:58:41,788 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.65, 'eval_samples_per_second': 1.505, 'eval_steps_per_second': 0.215, 'epoch': 16.77}
  8%|▊         | 1740/20600 [10:09:43<97:49:06, 18.67s/it]
100%|██████████| 1/1 [00:03<00:00,  3.71s/it][A
                                             [A  8%|▊         | 1741/20600 [10:10:01<103:58:43, 19.85s/it]  8%|▊         | 1742/20600 [10:10:20<101:26:58, 19.37s/it]  8%|▊         | 1743/20600 [10:10:38<99:27:24, 18.99s/it]   8%|▊         | 1744/20600 [10:11:05<111:44:55, 21.34s/it]  8%|▊         | 1745/20600 [10:11:24<108:20:06, 20.68s/it]  8%|▊         | 1746/20600 [10:11:44<106:57:13, 20.42s/it]  8%|▊         | 1747/20600 [10:12:05<108:44:18, 20.76s/it]  8%|▊         | 1748/20600 [10:12:22<103:22:21, 19.74s/it]  8%|▊         | 1749/20600 [10:12:40<100:10:08, 19.13s/it]  8%|▊         | 1750/20600 [10:13:00<100:54:31, 19.27s/it]                                                           {'loss': 0.0, 'learning_rate': 4.927319446394152e-05, 'epoch': 16.87}
  8%|▊         | 1750/20600 [10:13:00<100:54:31, 19.27s/it][INFO|trainer.py:3081] 2023-08-17 02:02:02,740 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:02:02,741 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:02:02,741 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.2511, 'eval_samples_per_second': 0.848, 'eval_steps_per_second': 0.121, 'epoch': 16.87}
  8%|▊         | 1750/20600 [10:13:08<100:54:31, 19.27s/it]
100%|██████████| 1/1 [00:07<00:00,  7.36s/it][A
                                             [A  8%|▊         | 1751/20600 [10:13:32<121:30:31, 23.21s/it]  9%|▊         | 1752/20600 [10:13:51<114:19:30, 21.84s/it]  9%|▊         | 1753/20600 [10:14:11<111:25:10, 21.28s/it]  9%|▊         | 1754/20600 [10:14:32<112:03:20, 21.41s/it]  9%|▊         | 1755/20600 [10:14:59<119:31:17, 22.83s/it]  9%|▊         | 1756/20600 [10:15:19<115:46:26, 22.12s/it]  9%|▊         | 1757/20600 [10:15:52<132:58:16, 25.40s/it]  9%|▊         | 1758/20600 [10:16:08<118:41:25, 22.68s/it]  9%|▊         | 1759/20600 [10:16:28<113:52:17, 21.76s/it]  9%|▊         | 1760/20600 [10:16:47<109:03:51, 20.84s/it]                                                           {'loss': 0.0, 'learning_rate': 4.926403989053844e-05, 'epoch': 16.96}
  9%|▊         | 1760/20600 [10:16:47<109:03:51, 20.84s/it][INFO|trainer.py:3081] 2023-08-17 02:05:49,762 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:05:49,762 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:05:49,762 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4287, 'eval_samples_per_second': 2.042, 'eval_steps_per_second': 0.292, 'epoch': 16.96}
  9%|▊         | 1760/20600 [10:16:50<109:03:51, 20.84s/it]
100%|██████████| 1/1 [00:02<00:00,  2.55s/it][A
                                             [A  9%|▊         | 1761/20600 [10:17:07<108:10:33, 20.67s/it]  9%|▊         | 1762/20600 [10:17:30<112:29:53, 21.50s/it]  9%|▊         | 1763/20600 [10:17:48<106:06:20, 20.28s/it]  9%|▊         | 1764/20600 [10:18:09<107:19:12, 20.51s/it]  9%|▊         | 1765/20600 [10:18:37<118:39:30, 22.68s/it]  9%|▊         | 1766/20600 [10:18:54<110:23:17, 21.10s/it]  9%|▊         | 1767/20600 [10:19:15<110:00:46, 21.03s/it]  9%|▊         | 1768/20600 [10:19:35<108:10:48, 20.68s/it]  9%|▊         | 1769/20600 [10:20:00<115:11:13, 22.02s/it]  9%|▊         | 1770/20600 [10:20:20<111:37:43, 21.34s/it]                                                           {'loss': 0.0, 'learning_rate': 4.925482888475991e-05, 'epoch': 17.06}
  9%|▊         | 1770/20600 [10:20:20<111:37:43, 21.34s/it][INFO|trainer.py:3081] 2023-08-17 02:09:22,743 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:09:22,743 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:09:22,743 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0116, 'eval_samples_per_second': 0.777, 'eval_steps_per_second': 0.111, 'epoch': 17.06}
  9%|▊         | 1770/20600 [10:20:29<111:37:43, 21.34s/it]
100%|██████████| 1/1 [00:08<00:00,  8.11s/it][A
                                             [A  9%|▊         | 1771/20600 [10:20:52<129:23:16, 24.74s/it]  9%|▊         | 1772/20600 [10:21:13<122:23:30, 23.40s/it]  9%|▊         | 1773/20600 [10:21:34<118:55:18, 22.74s/it]  9%|▊         | 1774/20600 [10:22:01<125:55:40, 24.08s/it]  9%|▊         | 1775/20600 [10:22:22<120:54:22, 23.12s/it]  9%|▊         | 1776/20600 [10:22:45<121:22:43, 23.21s/it]  9%|▊         | 1777/20600 [10:23:04<114:12:29, 21.84s/it]  9%|▊         | 1778/20600 [10:23:19<102:50:19, 19.67s/it]  9%|▊         | 1779/20600 [10:23:42<108:23:44, 20.73s/it]  9%|▊         | 1780/20600 [10:24:07<115:20:53, 22.06s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9245561468028524e-05, 'epoch': 17.16}
  9%|▊         | 1780/20600 [10:24:07<115:20:53, 22.06s/it][INFO|trainer.py:3081] 2023-08-17 02:13:10,034 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:13:10,035 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:13:10,035 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.99, 'eval_samples_per_second': 1.754, 'eval_steps_per_second': 0.251, 'epoch': 17.16}
  9%|▊         | 1780/20600 [10:24:11<115:20:53, 22.06s/it]
100%|██████████| 1/1 [00:03<00:00,  3.12s/it][A
                                             [A  9%|▊         | 1781/20600 [10:24:33<121:25:10, 23.23s/it]  9%|▊         | 1782/20600 [10:24:49<110:36:35, 21.16s/it]  9%|▊         | 1783/20600 [10:25:06<103:02:01, 19.71s/it]  9%|▊         | 1784/20600 [10:25:29<109:20:22, 20.92s/it]  9%|▊         | 1785/20600 [10:25:49<107:16:14, 20.52s/it]  9%|▊         | 1786/20600 [10:26:18<120:30:08, 23.06s/it]  9%|▊         | 1787/20600 [10:26:35<111:31:23, 21.34s/it]  9%|▊         | 1788/20600 [10:26:52<104:42:03, 20.04s/it]  9%|▊         | 1789/20600 [10:27:13<105:07:11, 20.12s/it]  9%|▊         | 1790/20600 [10:27:37<112:11:17, 21.47s/it]                                                           {'loss': 0.0, 'learning_rate': 4.92362376618981e-05, 'epoch': 17.25}
  9%|▊         | 1790/20600 [10:27:37<112:11:17, 21.47s/it][INFO|trainer.py:3081] 2023-08-17 02:16:40,217 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:16:40,217 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:16:40,217 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3773, 'eval_samples_per_second': 2.073, 'eval_steps_per_second': 0.296, 'epoch': 17.25}
  9%|▊         | 1790/20600 [10:27:41<112:11:17, 21.47s/it]
100%|██████████| 1/1 [00:02<00:00,  2.54s/it][A
                                             [A  9%|▊         | 1791/20600 [10:27:59<112:05:15, 21.45s/it]  9%|▊         | 1792/20600 [10:28:20<112:30:21, 21.53s/it]  9%|▊         | 1793/20600 [10:28:42<113:07:09, 21.65s/it]  9%|▊         | 1794/20600 [10:28:58<103:28:12, 19.81s/it]  9%|▊         | 1795/20600 [10:29:14<97:58:21, 18.76s/it]   9%|▊         | 1796/20600 [10:29:33<97:28:14, 18.66s/it]  9%|▊         | 1797/20600 [10:29:52<98:06:07, 18.78s/it]  9%|▊         | 1798/20600 [10:30:15<105:33:08, 20.21s/it]  9%|▊         | 1799/20600 [10:30:40<112:56:23, 21.63s/it]  9%|▊         | 1800/20600 [10:30:56<103:50:24, 19.88s/it]                                                           {'loss': 0.0, 'learning_rate': 4.922685748805357e-05, 'epoch': 17.35}
  9%|▊         | 1800/20600 [10:30:56<103:50:24, 19.88s/it][INFO|trainer.py:3081] 2023-08-17 02:19:58,881 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:19:58,882 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:19:58,882 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9001, 'eval_samples_per_second': 1.795, 'eval_steps_per_second': 0.256, 'epoch': 17.35}
  9%|▊         | 1800/20600 [10:31:00<103:50:24, 19.88s/it]
100%|██████████| 1/1 [00:03<00:00,  3.01s/it][A
                                             [A  9%|▊         | 1801/20600 [10:31:25<118:00:22, 22.60s/it]  9%|▊         | 1802/20600 [10:31:47<116:55:44, 22.39s/it]  9%|▉         | 1803/20600 [10:32:07<113:04:59, 21.66s/it]  9%|▉         | 1804/20600 [10:32:33<121:07:15, 23.20s/it]  9%|▉         | 1805/20600 [10:33:00<126:32:56, 24.24s/it]  9%|▉         | 1806/20600 [10:33:21<121:42:37, 23.31s/it]  9%|▉         | 1807/20600 [10:33:40<114:41:58, 21.97s/it]  9%|▉         | 1808/20600 [10:34:09<125:40:34, 24.08s/it]  9%|▉         | 1809/20600 [10:34:32<123:46:33, 23.71s/it]  9%|▉         | 1810/20600 [10:34:49<112:42:08, 21.59s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9217420968311005e-05, 'epoch': 17.45}
  9%|▉         | 1810/20600 [10:34:49<112:42:08, 21.59s/it][INFO|trainer.py:3081] 2023-08-17 02:23:51,624 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:23:51,624 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:23:51,624 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8559, 'eval_samples_per_second': 1.021, 'eval_steps_per_second': 0.146, 'epoch': 17.45}
  9%|▉         | 1810/20600 [10:34:56<112:42:08, 21.59s/it]
100%|██████████| 1/1 [00:05<00:00,  5.95s/it][A
                                             [A  9%|▉         | 1811/20600 [10:35:14<118:00:51, 22.61s/it]  9%|▉         | 1812/20600 [10:35:30<107:34:05, 20.61s/it]  9%|▉         | 1813/20600 [10:35:53<112:00:11, 21.46s/it]  9%|▉         | 1814/20600 [10:36:16<114:28:07, 21.94s/it]  9%|▉         | 1815/20600 [10:36:34<108:51:38, 20.86s/it]  9%|▉         | 1816/20600 [10:36:54<106:28:31, 20.41s/it]  9%|▉         | 1817/20600 [10:37:15<107:18:24, 20.57s/it]  9%|▉         | 1818/20600 [10:37:38<111:55:25, 21.45s/it]  9%|▉         | 1819/20600 [10:37:57<107:31:51, 20.61s/it]  9%|▉         | 1820/20600 [10:38:24<117:17:46, 22.48s/it]                                                           {'loss': 0.0, 'learning_rate': 4.920792812461748e-05, 'epoch': 17.54}
  9%|▉         | 1820/20600 [10:38:24<117:17:46, 22.48s/it][INFO|trainer.py:3081] 2023-08-17 02:27:26,713 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:27:26,713 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:27:26,713 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.5964, 'eval_samples_per_second': 1.523, 'eval_steps_per_second': 0.218, 'epoch': 17.54}
  9%|▉         | 1820/20600 [10:38:28<117:17:46, 22.48s/it]
100%|██████████| 1/1 [00:03<00:00,  3.69s/it][A
                                             [A  9%|▉         | 1821/20600 [10:38:43<112:08:35, 21.50s/it]  9%|▉         | 1822/20600 [10:39:04<112:00:12, 21.47s/it]  9%|▉         | 1823/20600 [10:39:21<103:53:23, 19.92s/it]  9%|▉         | 1824/20600 [10:39:37<98:39:51, 18.92s/it]   9%|▉         | 1825/20600 [10:39:53<94:05:24, 18.04s/it]  9%|▉         | 1826/20600 [10:40:20<106:59:17, 20.52s/it]  9%|▉         | 1827/20600 [10:40:37<102:01:04, 19.56s/it]  9%|▉         | 1828/20600 [10:40:53<97:12:55, 18.64s/it]   9%|▉         | 1829/20600 [10:41:15<101:57:04, 19.55s/it]  9%|▉         | 1830/20600 [10:41:35<103:18:26, 19.81s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9198378979051116e-05, 'epoch': 17.64}
  9%|▉         | 1830/20600 [10:41:35<103:18:26, 19.81s/it][INFO|trainer.py:3081] 2023-08-17 02:30:38,416 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:30:38,417 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:30:38,417 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.9043, 'eval_samples_per_second': 1.014, 'eval_steps_per_second': 0.145, 'epoch': 17.64}
  9%|▉         | 1830/20600 [10:41:42<103:18:26, 19.81s/it]
100%|██████████| 1/1 [00:05<00:00,  5.99s/it][A
                                             [A  9%|▉         | 1831/20600 [10:42:02<113:11:15, 21.71s/it]  9%|▉         | 1832/20600 [10:42:25<116:27:42, 22.34s/it]  9%|▉         | 1833/20600 [10:42:47<115:39:58, 22.19s/it]  9%|▉         | 1834/20600 [10:43:06<109:52:14, 21.08s/it]  9%|▉         | 1835/20600 [10:43:23<103:12:42, 19.80s/it]  9%|▉         | 1836/20600 [10:43:40<99:25:23, 19.08s/it]   9%|▉         | 1837/20600 [10:44:06<110:39:57, 21.23s/it]  9%|▉         | 1838/20600 [10:44:27<109:38:24, 21.04s/it]  9%|▉         | 1839/20600 [10:44:45<105:18:58, 20.21s/it]  9%|▉         | 1840/20600 [10:45:10<112:32:31, 21.60s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9188773553820924e-05, 'epoch': 17.73}
  9%|▉         | 1840/20600 [10:45:10<112:32:31, 21.60s/it][INFO|trainer.py:3081] 2023-08-17 02:34:12,843 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:34:12,843 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:34:12,843 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.2667, 'eval_samples_per_second': 1.117, 'eval_steps_per_second': 0.16, 'epoch': 17.73}
  9%|▉         | 1840/20600 [10:45:16<112:32:31, 21.60s/it]
100%|██████████| 1/1 [00:05<00:00,  5.39s/it][A
                                             [A  9%|▉         | 1841/20600 [10:45:31<112:11:23, 21.53s/it]  9%|▉         | 1842/20600 [10:45:47<102:38:52, 19.70s/it]  9%|▉         | 1843/20600 [10:46:07<103:48:54, 19.93s/it]  9%|▉         | 1844/20600 [10:46:25<99:56:10, 19.18s/it]   9%|▉         | 1845/20600 [10:46:47<105:46:20, 20.30s/it]  9%|▉         | 1846/20600 [10:47:04<100:03:28, 19.21s/it]  9%|▉         | 1847/20600 [10:47:29<109:02:09, 20.93s/it]  9%|▉         | 1848/20600 [10:47:44<99:40:20, 19.14s/it]   9%|▉         | 1849/20600 [10:48:05<102:59:16, 19.77s/it]  9%|▉         | 1850/20600 [10:48:21<96:59:10, 18.62s/it]                                                           {'loss': 0.0, 'learning_rate': 4.917911187126684e-05, 'epoch': 17.83}
  9%|▉         | 1850/20600 [10:48:21<96:59:10, 18.62s/it][INFO|trainer.py:3081] 2023-08-17 02:37:24,203 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:37:24,204 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:37:24,204 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8461, 'eval_samples_per_second': 1.022, 'eval_steps_per_second': 0.146, 'epoch': 17.83}
  9%|▉         | 1850/20600 [10:48:28<96:59:10, 18.62s/it]
100%|██████████| 1/1 [00:05<00:00,  5.97s/it][A
                                             [A  9%|▉         | 1851/20600 [10:48:48<110:17:47, 21.18s/it]  9%|▉         | 1852/20600 [10:49:05<103:48:29, 19.93s/it]  9%|▉         | 1853/20600 [10:49:27<106:15:44, 20.41s/it]  9%|▉         | 1854/20600 [10:49:51<111:19:34, 21.38s/it]  9%|▉         | 1855/20600 [10:50:08<105:33:24, 20.27s/it]  9%|▉         | 1856/20600 [10:50:31<109:30:21, 21.03s/it]  9%|▉         | 1857/20600 [10:50:52<108:57:05, 20.93s/it]  9%|▉         | 1858/20600 [10:51:12<108:29:07, 20.84s/it]  9%|▉         | 1859/20600 [10:51:36<112:40:23, 21.64s/it]  9%|▉         | 1860/20600 [10:51:58<113:19:56, 21.77s/it]                                                           {'loss': 0.0, 'learning_rate': 4.916939395385964e-05, 'epoch': 17.93}
  9%|▉         | 1860/20600 [10:51:58<113:19:56, 21.77s/it][INFO|trainer.py:3081] 2023-08-17 02:41:00,932 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:41:00,932 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:41:00,932 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.965, 'eval_samples_per_second': 1.765, 'eval_steps_per_second': 0.252, 'epoch': 17.93}
  9%|▉         | 1860/20600 [10:52:02<113:19:56, 21.77s/it]
100%|██████████| 1/1 [00:03<00:00,  3.08s/it][A
                                             [A  9%|▉         | 1861/20600 [10:52:18<111:19:18, 21.39s/it]  9%|▉         | 1862/20600 [10:52:46<121:38:10, 23.37s/it]  9%|▉         | 1863/20600 [10:53:10<122:41:39, 23.57s/it]  9%|▉         | 1864/20600 [10:53:32<119:49:16, 23.02s/it]  9%|▉         | 1865/20600 [10:53:48<108:20:58, 20.82s/it]  9%|▉         | 1866/20600 [10:54:06<104:11:53, 20.02s/it]  9%|▉         | 1867/20600 [10:54:28<107:56:14, 20.74s/it]  9%|▉         | 1868/20600 [10:54:50<109:43:45, 21.09s/it]  9%|▉         | 1869/20600 [10:55:19<121:56:48, 23.44s/it]  9%|▉         | 1870/20600 [10:55:39<115:22:45, 22.18s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9159619824200884e-05, 'epoch': 18.02}
  9%|▉         | 1870/20600 [10:55:39<115:22:45, 22.18s/it][INFO|trainer.py:3081] 2023-08-17 02:44:41,518 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:44:41,518 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:44:41,518 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3524, 'eval_samples_per_second': 2.088, 'eval_steps_per_second': 0.298, 'epoch': 18.02}
  9%|▉         | 1870/20600 [10:55:42<115:22:45, 22.18s/it]
100%|██████████| 1/1 [00:02<00:00,  2.50s/it][A
                                             [A  9%|▉         | 1871/20600 [10:55:58<111:24:13, 21.41s/it]  9%|▉         | 1872/20600 [10:56:23<117:18:57, 22.55s/it]  9%|▉         | 1873/20600 [10:56:41<109:16:27, 21.01s/it]  9%|▉         | 1874/20600 [10:57:00<106:55:59, 20.56s/it]  9%|▉         | 1875/20600 [10:57:19<104:08:02, 20.02s/it]  9%|▉         | 1876/20600 [10:57:38<101:41:30, 19.55s/it]  9%|▉         | 1877/20600 [10:57:56<100:43:02, 19.37s/it]  9%|▉         | 1878/20600 [10:58:20<107:09:19, 20.60s/it]  9%|▉         | 1879/20600 [10:58:38<103:01:17, 19.81s/it]  9%|▉         | 1880/20600 [10:59:00<106:54:57, 20.56s/it]                                                           {'loss': 0.0, 'learning_rate': 4.914978950502287e-05, 'epoch': 18.12}
  9%|▉         | 1880/20600 [10:59:00<106:54:57, 20.56s/it][INFO|trainer.py:3081] 2023-08-17 02:48:03,192 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:48:03,192 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:48:03,192 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9858, 'eval_samples_per_second': 1.756, 'eval_steps_per_second': 0.251, 'epoch': 18.12}
  9%|▉         | 1880/20600 [10:59:04<106:54:57, 20.56s/it]
100%|██████████| 1/1 [00:03<00:00,  3.16s/it][A
                                             [A  9%|▉         | 1881/20600 [10:59:27<117:18:09, 22.56s/it]  9%|▉         | 1882/20600 [10:59:45<110:08:31, 21.18s/it]  9%|▉         | 1883/20600 [11:00:07<110:56:29, 21.34s/it]  9%|▉         | 1884/20600 [11:00:28<109:41:57, 21.10s/it]  9%|▉         | 1885/20600 [11:00:44<102:07:19, 19.64s/it]  9%|▉         | 1886/20600 [11:01:03<101:47:03, 19.58s/it]  9%|▉         | 1887/20600 [11:01:21<98:47:44, 19.01s/it]   9%|▉         | 1888/20600 [11:01:45<106:39:31, 20.52s/it]  9%|▉         | 1889/20600 [11:02:09<112:07:44, 21.57s/it]  9%|▉         | 1890/20600 [11:02:28<107:51:46, 20.75s/it]                                                           {'loss': 0.0, 'learning_rate': 4.913990301918857e-05, 'epoch': 18.22}
  9%|▉         | 1890/20600 [11:02:28<107:51:46, 20.75s/it][INFO|trainer.py:3081] 2023-08-17 02:51:30,902 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:51:30,902 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:51:30,902 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 9.01, 'eval_samples_per_second': 0.777, 'eval_steps_per_second': 0.111, 'epoch': 18.22}
  9%|▉         | 1890/20600 [11:02:37<107:51:46, 20.75s/it]
100%|██████████| 1/1 [00:08<00:00,  8.14s/it][A
                                             [A  9%|▉         | 1891/20600 [11:03:00<124:44:40, 24.00s/it]  9%|▉         | 1892/20600 [11:03:17<114:16:55, 21.99s/it]  9%|▉         | 1893/20600 [11:03:32<103:53:09, 19.99s/it]  9%|▉         | 1894/20600 [11:03:54<107:21:00, 20.66s/it]  9%|▉         | 1895/20600 [11:04:11<101:07:02, 19.46s/it]  9%|▉         | 1896/20600 [11:04:35<108:54:56, 20.96s/it]  9%|▉         | 1897/20600 [11:04:51<99:51:46, 19.22s/it]   9%|▉         | 1898/20600 [11:05:17<111:33:43, 21.47s/it]  9%|▉         | 1899/20600 [11:05:34<104:02:22, 20.03s/it]  9%|▉         | 1900/20600 [11:05:48<95:20:35, 18.35s/it]                                                           {'loss': 0.0, 'learning_rate': 4.912996038969161e-05, 'epoch': 18.31}
  9%|▉         | 1900/20600 [11:05:48<95:20:35, 18.35s/it][INFO|trainer.py:3081] 2023-08-17 02:54:51,454 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:54:51,454 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:54:51,454 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4109, 'eval_samples_per_second': 0.945, 'eval_steps_per_second': 0.135, 'epoch': 18.31}
  9%|▉         | 1900/20600 [11:05:56<95:20:35, 18.35s/it]
100%|██████████| 1/1 [00:06<00:00,  6.43s/it][A
                                             [A  9%|▉         | 1901/20600 [11:06:19<114:24:30, 22.03s/it]  9%|▉         | 1902/20600 [11:06:41<113:40:12, 21.89s/it]  9%|▉         | 1903/20600 [11:07:06<119:34:47, 23.02s/it]  9%|▉         | 1904/20600 [11:07:24<111:56:34, 21.56s/it]  9%|▉         | 1905/20600 [11:07:48<115:27:09, 22.23s/it]  9%|▉         | 1906/20600 [11:08:07<109:26:15, 21.07s/it]  9%|▉         | 1907/20600 [11:08:27<108:57:27, 20.98s/it]  9%|▉         | 1908/20600 [11:08:52<114:07:12, 21.98s/it]  9%|▉         | 1909/20600 [11:09:16<117:39:51, 22.66s/it]  9%|▉         | 1910/20600 [11:09:33<108:46:50, 20.95s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9119961639656165e-05, 'epoch': 18.41}
  9%|▉         | 1910/20600 [11:09:33<108:46:50, 20.95s/it][INFO|trainer.py:3081] 2023-08-17 02:58:35,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 02:58:35,896 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 02:58:35,896 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.2371, 'eval_samples_per_second': 0.85, 'eval_steps_per_second': 0.121, 'epoch': 18.41}
  9%|▉         | 1910/20600 [11:09:41<108:46:50, 20.95s/it]
100%|██████████| 1/1 [00:07<00:00,  7.19s/it][A
                                             [A  9%|▉         | 1911/20600 [11:10:01<119:15:26, 22.97s/it]  9%|▉         | 1912/20600 [11:10:30<129:40:23, 24.98s/it]  9%|▉         | 1913/20600 [11:10:51<122:52:31, 23.67s/it]  9%|▉         | 1914/20600 [11:11:11<116:57:10, 22.53s/it]  9%|▉         | 1915/20600 [11:11:36<121:52:36, 23.48s/it]  9%|▉         | 1916/20600 [11:11:58<119:12:51, 22.97s/it]  9%|▉         | 1917/20600 [11:12:23<121:23:31, 23.39s/it]  9%|▉         | 1918/20600 [11:12:45<119:12:42, 22.97s/it]  9%|▉         | 1919/20600 [11:13:05<115:17:20, 22.22s/it]  9%|▉         | 1920/20600 [11:13:23<108:23:46, 20.89s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9109906792336945e-05, 'epoch': 18.51}
  9%|▉         | 1920/20600 [11:13:23<108:23:46, 20.89s/it][INFO|trainer.py:3081] 2023-08-17 03:02:25,823 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:02:25,823 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:02:25,823 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.5779, 'eval_samples_per_second': 0.924, 'eval_steps_per_second': 0.132, 'epoch': 18.51}
  9%|▉         | 1920/20600 [11:13:30<108:23:46, 20.89s/it]
100%|██████████| 1/1 [00:06<00:00,  6.66s/it][A
                                             [A  9%|▉         | 1921/20600 [11:13:55<126:02:32, 24.29s/it]  9%|▉         | 1922/20600 [11:14:13<116:12:41, 22.40s/it]  9%|▉         | 1923/20600 [11:14:33<112:44:52, 21.73s/it]  9%|▉         | 1924/20600 [11:14:52<107:42:14, 20.76s/it]  9%|▉         | 1925/20600 [11:15:20<119:25:51, 23.02s/it]  9%|▉         | 1926/20600 [11:15:42<117:51:32, 22.72s/it]  9%|▉         | 1927/20600 [11:15:58<106:44:38, 20.58s/it]  9%|▉         | 1928/20600 [11:16:17<104:18:58, 20.11s/it]  9%|▉         | 1929/20600 [11:16:35<101:26:31, 19.56s/it]  9%|▉         | 1930/20600 [11:16:53<98:24:07, 18.97s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9099795871119136e-05, 'epoch': 18.6}
  9%|▉         | 1930/20600 [11:16:53<98:24:07, 18.97s/it][INFO|trainer.py:3081] 2023-08-17 03:05:55,525 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:05:55,525 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:05:55,525 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0914, 'eval_samples_per_second': 1.711, 'eval_steps_per_second': 0.244, 'epoch': 18.6}
  9%|▉         | 1930/20600 [11:16:57<98:24:07, 18.97s/it]
100%|██████████| 1/1 [00:03<00:00,  3.19s/it][A
                                             [A  9%|▉         | 1931/20600 [11:17:22<114:24:50, 22.06s/it]  9%|▉         | 1932/20600 [11:17:38<105:07:01, 20.27s/it]  9%|▉         | 1933/20600 [11:17:52<95:25:37, 18.40s/it]   9%|▉         | 1934/20600 [11:18:09<92:45:12, 17.89s/it]  9%|▉         | 1935/20600 [11:18:34<103:46:19, 20.01s/it]  9%|▉         | 1936/20600 [11:18:49<97:07:37, 18.73s/it]   9%|▉         | 1937/20600 [11:19:13<104:48:56, 20.22s/it]  9%|▉         | 1938/20600 [11:19:33<104:55:27, 20.24s/it]  9%|▉         | 1939/20600 [11:19:53<104:12:28, 20.10s/it]  9%|▉         | 1940/20600 [11:20:11<100:47:07, 19.44s/it]                                                           {'loss': 0.0, 'learning_rate': 4.908962889951832e-05, 'epoch': 18.7}
  9%|▉         | 1940/20600 [11:20:11<100:47:07, 19.44s/it][INFO|trainer.py:3081] 2023-08-17 03:09:14,231 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:09:14,231 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:09:14,231 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5655, 'eval_samples_per_second': 1.963, 'eval_steps_per_second': 0.28, 'epoch': 18.7}
  9%|▉         | 1940/20600 [11:20:15<100:47:07, 19.44s/it]
100%|██████████| 1/1 [00:02<00:00,  2.70s/it][A
                                             [A  9%|▉         | 1941/20600 [11:20:31<102:23:49, 19.76s/it]  9%|▉         | 1942/20600 [11:20:47<95:56:18, 18.51s/it]   9%|▉         | 1943/20600 [11:21:04<93:20:45, 18.01s/it]  9%|▉         | 1944/20600 [11:21:31<107:46:31, 20.80s/it]  9%|▉         | 1945/20600 [11:21:59<117:50:54, 22.74s/it]  9%|▉         | 1946/20600 [11:22:16<109:04:27, 21.05s/it]  9%|▉         | 1947/20600 [11:22:33<102:59:45, 19.88s/it]  9%|▉         | 1948/20600 [11:22:53<103:19:43, 19.94s/it]  9%|▉         | 1949/20600 [11:23:14<105:36:23, 20.38s/it]  9%|▉         | 1950/20600 [11:23:38<110:41:57, 21.37s/it]                                                           {'loss': 0.0, 'learning_rate': 4.907940590118047e-05, 'epoch': 18.8}
  9%|▉         | 1950/20600 [11:23:38<110:41:57, 21.37s/it][INFO|trainer.py:3081] 2023-08-17 03:12:40,935 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:12:40,935 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:12:40,935 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.827, 'eval_samples_per_second': 1.829, 'eval_steps_per_second': 0.261, 'epoch': 18.8}
  9%|▉         | 1950/20600 [11:23:42<110:41:57, 21.37s/it]
100%|██████████| 1/1 [00:02<00:00,  2.92s/it][A
                                             [A  9%|▉         | 1951/20600 [11:23:57<106:50:43, 20.63s/it]  9%|▉         | 1952/20600 [11:24:18<107:38:07, 20.78s/it]  9%|▉         | 1953/20600 [11:24:41<110:48:09, 21.39s/it]  9%|▉         | 1954/20600 [11:25:09<121:23:59, 23.44s/it]  9%|▉         | 1955/20600 [11:25:27<112:19:26, 21.69s/it]  9%|▉         | 1956/20600 [11:25:50<114:54:27, 22.19s/it] 10%|▉         | 1957/20600 [11:26:08<109:03:28, 21.06s/it] 10%|▉         | 1958/20600 [11:26:29<108:20:28, 20.92s/it] 10%|▉         | 1959/20600 [11:26:49<106:58:47, 20.66s/it] 10%|▉         | 1960/20600 [11:27:06<101:56:03, 19.69s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9069126899881825e-05, 'epoch': 18.89}
 10%|▉         | 1960/20600 [11:27:06<101:56:03, 19.69s/it][INFO|trainer.py:3081] 2023-08-17 03:16:09,447 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:16:09,448 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:16:09,448 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.0125, 'eval_samples_per_second': 1.164, 'eval_steps_per_second': 0.166, 'epoch': 18.89}
 10%|▉         | 1960/20600 [11:27:12<101:56:03, 19.69s/it]
100%|██████████| 1/1 [00:05<00:00,  5.18s/it][A
                                             [A 10%|▉         | 1961/20600 [11:27:34<114:06:06, 22.04s/it] 10%|▉         | 1962/20600 [11:28:04<126:15:15, 24.39s/it] 10%|▉         | 1963/20600 [11:28:24<119:19:06, 23.05s/it] 10%|▉         | 1964/20600 [11:28:44<114:17:21, 22.08s/it] 10%|▉         | 1965/20600 [11:29:02<108:23:39, 20.94s/it] 10%|▉         | 1966/20600 [11:29:19<102:09:16, 19.74s/it] 10%|▉         | 1967/20600 [11:29:43<108:26:05, 20.95s/it] 10%|▉         | 1968/20600 [11:30:07<113:31:31, 21.93s/it] 10%|▉         | 1969/20600 [11:30:27<110:55:58, 21.44s/it] 10%|▉         | 1970/20600 [11:30:47<108:51:04, 21.03s/it]                                                           {'loss': 0.0, 'learning_rate': 4.90587919195289e-05, 'epoch': 18.99}
 10%|▉         | 1970/20600 [11:30:47<108:51:04, 21.03s/it][INFO|trainer.py:3081] 2023-08-17 03:19:50,186 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:19:50,186 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:19:50,186 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4322, 'eval_samples_per_second': 0.942, 'eval_steps_per_second': 0.135, 'epoch': 18.99}
 10%|▉         | 1970/20600 [11:30:55<108:51:04, 21.03s/it]
100%|██████████| 1/1 [00:06<00:00,  6.54s/it][A
                                             [A 10%|▉         | 1971/20600 [11:31:15<120:00:07, 23.19s/it] 10%|▉         | 1972/20600 [11:31:35<115:07:12, 22.25s/it] 10%|▉         | 1973/20600 [11:32:01<120:16:17, 23.24s/it] 10%|▉         | 1974/20600 [11:32:21<114:51:02, 22.20s/it] 10%|▉         | 1975/20600 [11:32:37<106:07:50, 20.51s/it] 10%|▉         | 1976/20600 [11:33:02<112:01:02, 21.65s/it] 10%|▉         | 1977/20600 [11:33:31<123:47:25, 23.93s/it] 10%|▉         | 1978/20600 [11:33:48<113:34:00, 21.95s/it] 10%|▉         | 1979/20600 [11:34:05<106:13:32, 20.54s/it] 10%|▉         | 1980/20600 [11:34:24<103:29:28, 20.01s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9048400984158396e-05, 'epoch': 19.08}
 10%|▉         | 1980/20600 [11:34:24<103:29:28, 20.01s/it][INFO|trainer.py:3081] 2023-08-17 03:23:27,260 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:23:27,260 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:23:27,260 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.5504, 'eval_samples_per_second': 1.261, 'eval_steps_per_second': 0.18, 'epoch': 19.08}
 10%|▉         | 1980/20600 [11:34:30<103:29:28, 20.01s/it]
100%|██████████| 1/1 [00:04<00:00,  4.65s/it][A
                                             [A 10%|▉         | 1981/20600 [11:34:44<102:52:00, 19.89s/it] 10%|▉         | 1982/20600 [11:35:00<97:41:36, 18.89s/it]  10%|▉         | 1983/20600 [11:35:23<102:46:00, 19.87s/it] 10%|▉         | 1984/20600 [11:35:41<100:57:25, 19.52s/it] 10%|▉         | 1985/20600 [11:36:05<107:47:18, 20.85s/it] 10%|▉         | 1986/20600 [11:36:22<102:09:04, 19.76s/it] 10%|▉         | 1987/20600 [11:36:43<103:15:44, 19.97s/it] 10%|▉         | 1988/20600 [11:37:01<100:00:02, 19.34s/it] 10%|▉         | 1989/20600 [11:37:29<113:28:46, 21.95s/it] 10%|▉         | 1990/20600 [11:37:47<108:19:59, 20.96s/it]                                                           {'loss': 0.0, 'learning_rate': 4.9037954117937155e-05, 'epoch': 19.18}
 10%|▉         | 1990/20600 [11:37:47<108:19:59, 20.96s/it][INFO|trainer.py:3081] 2023-08-17 03:26:50,453 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:26:50,453 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:26:50,453 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0837, 'eval_samples_per_second': 0.988, 'eval_steps_per_second': 0.141, 'epoch': 19.18}
 10%|▉         | 1990/20600 [11:37:55<108:19:59, 20.96s/it]
100%|██████████| 1/1 [00:06<00:00,  6.22s/it][A
                                             [A 10%|▉         | 1991/20600 [11:38:14<117:35:22, 22.75s/it] 10%|▉         | 1992/20600 [11:38:32<110:07:26, 21.31s/it] 10%|▉         | 1993/20600 [11:38:51<106:32:07, 20.61s/it] 10%|▉         | 1994/20600 [11:39:12<106:31:06, 20.61s/it] 10%|▉         | 1995/20600 [11:39:36<112:04:48, 21.69s/it] 10%|▉         | 1996/20600 [11:39:54<106:33:34, 20.62s/it] 10%|▉         | 1997/20600 [11:40:12<102:33:01, 19.85s/it] 10%|▉         | 1998/20600 [11:40:31<100:07:40, 19.38s/it] 10%|▉         | 1999/20600 [11:40:48<96:40:13, 18.71s/it]  10%|▉         | 2000/20600 [11:41:07<97:29:22, 18.87s/it]                                                          {'loss': 0.0, 'learning_rate': 4.90274513451621e-05, 'epoch': 19.28}
 10%|▉         | 2000/20600 [11:41:07<97:29:22, 18.87s/it][INFO|trainer.py:3081] 2023-08-17 03:30:09,970 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:30:09,970 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:30:09,970 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.449, 'eval_samples_per_second': 0.94, 'eval_steps_per_second': 0.134, 'epoch': 19.28}
 10%|▉         | 2000/20600 [11:41:14<97:29:22, 18.87s/it]
100%|██████████| 1/1 [00:06<00:00,  6.57s/it][A
                                             [A 10%|▉         | 2001/20600 [11:41:32<107:09:27, 20.74s/it] 10%|▉         | 2002/20600 [11:41:56<111:35:37, 21.60s/it] 10%|▉         | 2003/20600 [11:42:12<103:39:05, 20.06s/it] 10%|▉         | 2004/20600 [11:42:30<100:35:16, 19.47s/it] 10%|▉         | 2005/20600 [11:42:53<106:16:36, 20.58s/it] 10%|▉         | 2006/20600 [11:43:15<107:54:22, 20.89s/it] 10%|▉         | 2007/20600 [11:43:34<104:57:04, 20.32s/it] 10%|▉         | 2008/20600 [11:43:52<101:31:10, 19.66s/it] 10%|▉         | 2009/20600 [11:44:21<115:12:18, 22.31s/it] 10%|▉         | 2010/20600 [11:44:45<117:52:11, 22.83s/it]                                                           {'loss': 0.0, 'learning_rate': 4.901689269026017e-05, 'epoch': 19.37}
 10%|▉         | 2010/20600 [11:44:45<117:52:11, 22.83s/it][INFO|trainer.py:3081] 2023-08-17 03:33:47,672 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:33:47,672 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:33:47,672 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5711, 'eval_samples_per_second': 1.96, 'eval_steps_per_second': 0.28, 'epoch': 19.37}
 10%|▉         | 2010/20600 [11:44:48<117:52:11, 22.83s/it]
100%|██████████| 1/1 [00:02<00:00,  2.69s/it][A
                                             [A 10%|▉         | 2011/20600 [11:45:05<113:33:44, 21.99s/it] 10%|▉         | 2012/20600 [11:45:28<114:55:38, 22.26s/it] 10%|▉         | 2013/20600 [11:45:43<103:40:34, 20.08s/it] 10%|▉         | 2014/20600 [11:46:07<111:02:31, 21.51s/it] 10%|▉         | 2015/20600 [11:46:26<105:53:15, 20.51s/it] 10%|▉         | 2016/20600 [11:46:42<99:46:32, 19.33s/it]  10%|▉         | 2017/20600 [11:47:09<111:39:16, 21.63s/it] 10%|▉         | 2018/20600 [11:47:24<101:28:30, 19.66s/it] 10%|▉         | 2019/20600 [11:47:42<99:10:11, 19.21s/it]  10%|▉         | 2020/20600 [11:48:08<109:21:32, 21.19s/it]                                                           {'loss': 0.0, 'learning_rate': 4.90062781777883e-05, 'epoch': 19.47}
 10%|▉         | 2020/20600 [11:48:08<109:21:32, 21.19s/it][INFO|trainer.py:3081] 2023-08-17 03:37:11,236 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:37:11,236 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:37:11,236 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3129, 'eval_samples_per_second': 0.957, 'eval_steps_per_second': 0.137, 'epoch': 19.47}
 10%|▉         | 2020/20600 [11:48:16<109:21:32, 21.19s/it]
100%|██████████| 1/1 [00:06<00:00,  6.46s/it][A
                                             [A 10%|▉         | 2021/20600 [11:48:31<111:15:58, 21.56s/it] 10%|▉         | 2022/20600 [11:48:52<110:56:10, 21.50s/it] 10%|▉         | 2023/20600 [11:49:16<114:48:16, 22.25s/it] 10%|▉         | 2024/20600 [11:49:43<121:38:14, 23.57s/it] 10%|▉         | 2025/20600 [11:49:57<107:19:05, 20.80s/it] 10%|▉         | 2026/20600 [11:50:23<114:45:24, 22.24s/it] 10%|▉         | 2027/20600 [11:50:44<114:11:22, 22.13s/it] 10%|▉         | 2028/20600 [11:51:05<112:20:12, 21.78s/it] 10%|▉         | 2029/20600 [11:51:30<116:48:21, 22.64s/it] 10%|▉         | 2030/20600 [11:51:48<110:07:15, 21.35s/it]                                                           {'loss': 0.0, 'learning_rate': 4.89956078324333e-05, 'epoch': 19.57}
 10%|▉         | 2030/20600 [11:51:48<110:07:15, 21.35s/it][INFO|trainer.py:3081] 2023-08-17 03:40:51,417 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:40:51,417 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:40:51,417 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9749, 'eval_samples_per_second': 1.761, 'eval_steps_per_second': 0.252, 'epoch': 19.57}
 10%|▉         | 2030/20600 [11:51:52<110:07:15, 21.35s/it]
100%|██████████| 1/1 [00:03<00:00,  3.06s/it][A
                                             [A 10%|▉         | 2031/20600 [11:52:10<110:22:28, 21.40s/it] 10%|▉         | 2032/20600 [11:52:29<107:11:17, 20.78s/it] 10%|▉         | 2033/20600 [11:52:52<110:56:49, 21.51s/it] 10%|▉         | 2034/20600 [11:53:13<109:20:10, 21.20s/it] 10%|▉         | 2035/20600 [11:53:29<101:34:54, 19.70s/it] 10%|▉         | 2036/20600 [11:53:53<108:27:36, 21.03s/it] 10%|▉         | 2037/20600 [11:54:12<104:11:34, 20.21s/it] 10%|▉         | 2038/20600 [11:54:27<97:00:48, 18.82s/it]  10%|▉         | 2039/20600 [11:54:44<94:14:32, 18.28s/it] 10%|▉         | 2040/20600 [11:55:10<105:30:26, 20.46s/it]                                                           {'loss': 0.0, 'learning_rate': 4.898488167901185e-05, 'epoch': 19.66}
 10%|▉         | 2040/20600 [11:55:10<105:30:26, 20.46s/it][INFO|trainer.py:3081] 2023-08-17 03:44:12,750 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:44:12,750 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:44:12,750 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3898, 'eval_samples_per_second': 2.065, 'eval_steps_per_second': 0.295, 'epoch': 19.66}
 10%|▉         | 2040/20600 [11:55:13<105:30:26, 20.46s/it]
100%|██████████| 1/1 [00:02<00:00,  2.53s/it][A
                                             [A 10%|▉         | 2041/20600 [11:55:29<103:46:35, 20.13s/it] 10%|▉         | 2042/20600 [11:55:45<96:48:01, 18.78s/it]  10%|▉         | 2043/20600 [11:56:09<105:19:19, 20.43s/it] 10%|▉         | 2044/20600 [11:56:27<101:50:17, 19.76s/it] 10%|▉         | 2045/20600 [11:56:44<97:22:24, 18.89s/it]  10%|▉         | 2046/20600 [11:57:01<94:13:01, 18.28s/it] 10%|▉         | 2047/20600 [11:57:21<96:54:48, 18.80s/it] 10%|▉         | 2048/20600 [11:57:41<99:14:42, 19.26s/it] 10%|▉         | 2049/20600 [11:58:02<100:57:33, 19.59s/it] 10%|▉         | 2050/20600 [11:58:24<104:51:53, 20.35s/it]                                                           {'loss': 0.0, 'learning_rate': 4.897409974247042e-05, 'epoch': 19.76}
 10%|▉         | 2050/20600 [11:58:24<104:51:53, 20.35s/it][INFO|trainer.py:3081] 2023-08-17 03:47:26,748 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:47:26,748 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:47:26,748 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.5215, 'eval_samples_per_second': 0.821, 'eval_steps_per_second': 0.117, 'epoch': 19.76}
 10%|▉         | 2050/20600 [11:58:32<104:51:53, 20.35s/it]
100%|██████████| 1/1 [00:07<00:00,  7.77s/it][A
                                             [A 10%|▉         | 2051/20600 [11:58:51<115:37:10, 22.44s/it] 10%|▉         | 2052/20600 [11:59:10<109:43:27, 21.30s/it] 10%|▉         | 2053/20600 [11:59:32<110:57:19, 21.54s/it] 10%|▉         | 2054/20600 [11:59:54<112:43:00, 21.88s/it] 10%|▉         | 2055/20600 [12:00:12<105:28:39, 20.48s/it] 10%|▉         | 2056/20600 [12:00:35<110:32:26, 21.46s/it] 10%|▉         | 2057/20600 [12:00:57<110:20:29, 21.42s/it] 10%|▉         | 2058/20600 [12:01:16<106:54:23, 20.76s/it] 10%|▉         | 2059/20600 [12:01:36<106:21:12, 20.65s/it] 10%|█         | 2060/20600 [12:02:02<114:17:15, 22.19s/it]                                                           {'loss': 0.0, 'learning_rate': 4.896326204788525e-05, 'epoch': 19.86}
 10%|█         | 2060/20600 [12:02:02<114:17:15, 22.19s/it][INFO|trainer.py:3081] 2023-08-17 03:51:05,155 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:51:05,155 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:51:05,155 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.2712, 'eval_samples_per_second': 0.846, 'eval_steps_per_second': 0.121, 'epoch': 19.86}
 10%|█         | 2060/20600 [12:02:10<114:17:15, 22.19s/it]
100%|██████████| 1/1 [00:07<00:00,  7.37s/it][A
                                             [A 10%|█         | 2061/20600 [12:02:31<125:08:22, 24.30s/it] 10%|█         | 2062/20600 [12:02:53<120:28:25, 23.40s/it] 10%|█         | 2063/20600 [12:03:20<126:33:06, 24.58s/it] 10%|█         | 2064/20600 [12:03:42<122:55:04, 23.87s/it] 10%|█         | 2065/20600 [12:04:08<126:30:04, 24.57s/it] 10%|█         | 2066/20600 [12:04:28<118:36:39, 23.04s/it] 10%|█         | 2067/20600 [12:04:50<117:05:09, 22.74s/it] 10%|█         | 2068/20600 [12:05:15<121:11:18, 23.54s/it] 10%|█         | 2069/20600 [12:05:33<111:56:53, 21.75s/it] 10%|█         | 2070/20600 [12:06:05<128:14:58, 24.92s/it]                                                           {'loss': 0.0, 'learning_rate': 4.895236862046223e-05, 'epoch': 19.95}
 10%|█         | 2070/20600 [12:06:05<128:14:58, 24.92s/it][INFO|trainer.py:3081] 2023-08-17 03:55:08,203 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:55:08,203 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:55:08,203 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.8073, 'eval_samples_per_second': 1.456, 'eval_steps_per_second': 0.208, 'epoch': 19.95}
 10%|█         | 2070/20600 [12:06:10<128:14:58, 24.92s/it]
100%|██████████| 1/1 [00:03<00:00,  3.97s/it][A
                                             [A 10%|█         | 2071/20600 [12:06:25<120:41:42, 23.45s/it] 10%|█         | 2072/20600 [12:06:49<121:41:51, 23.65s/it] 10%|█         | 2073/20600 [12:07:06<110:19:16, 21.44s/it] 10%|█         | 2074/20600 [12:07:28<112:16:35, 21.82s/it] 10%|█         | 2075/20600 [12:07:53<116:23:33, 22.62s/it] 10%|█         | 2076/20600 [12:08:10<107:59:43, 20.99s/it] 10%|█         | 2077/20600 [12:08:38<118:35:02, 23.05s/it] 10%|█         | 2078/20600 [12:09:02<120:23:35, 23.40s/it] 10%|█         | 2079/20600 [12:09:21<113:49:46, 22.13s/it] 10%|█         | 2080/20600 [12:09:49<121:44:30, 23.66s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8941419485536854e-05, 'epoch': 20.05}
 10%|█         | 2080/20600 [12:09:49<121:44:30, 23.66s/it][INFO|trainer.py:3081] 2023-08-17 03:58:51,517 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 03:58:51,517 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 03:58:51,517 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3802, 'eval_samples_per_second': 2.071, 'eval_steps_per_second': 0.296, 'epoch': 20.05}
 10%|█         | 2080/20600 [12:09:52<121:44:30, 23.66s/it]
100%|██████████| 1/1 [00:02<00:00,  2.52s/it][A
                                             [A 10%|█         | 2081/20600 [12:10:14<124:56:46, 24.29s/it] 10%|█         | 2082/20600 [12:10:32<115:32:55, 22.46s/it] 10%|█         | 2083/20600 [12:10:52<110:18:13, 21.44s/it] 10%|█         | 2084/20600 [12:11:14<111:44:34, 21.73s/it] 10%|█         | 2085/20600 [12:11:33<107:10:03, 20.84s/it] 10%|█         | 2086/20600 [12:11:51<103:32:02, 20.13s/it] 10%|█         | 2087/20600 [12:12:13<105:28:17, 20.51s/it] 10%|█         | 2088/20600 [12:12:35<108:31:11, 21.10s/it] 10%|█         | 2089/20600 [12:12:53<103:35:26, 20.15s/it] 10%|█         | 2090/20600 [12:13:09<96:33:37, 18.78s/it]                                                           {'loss': 0.0, 'learning_rate': 4.893041466857422e-05, 'epoch': 20.14}
 10%|█         | 2090/20600 [12:13:09<96:33:37, 18.78s/it][INFO|trainer.py:3081] 2023-08-17 04:02:11,529 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:02:11,529 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:02:11,529 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9305, 'eval_samples_per_second': 1.781, 'eval_steps_per_second': 0.254, 'epoch': 20.14}
 10%|█         | 2090/20600 [12:13:12<96:33:37, 18.78s/it]
100%|██████████| 1/1 [00:03<00:00,  3.00s/it][A
                                             [A 10%|█         | 2091/20600 [12:13:32<103:12:59, 20.08s/it] 10%|█         | 2092/20600 [12:13:56<109:26:00, 21.29s/it] 10%|█         | 2093/20600 [12:14:14<104:33:17, 20.34s/it] 10%|█         | 2094/20600 [12:14:33<103:02:24, 20.04s/it] 10%|█         | 2095/20600 [12:14:54<104:50:30, 20.40s/it] 10%|█         | 2096/20600 [12:15:09<96:21:51, 18.75s/it]  10%|█         | 2097/20600 [12:15:24<90:20:43, 17.58s/it] 10%|█         | 2098/20600 [12:15:54<108:37:55, 21.14s/it] 10%|█         | 2099/20600 [12:16:12<103:38:56, 20.17s/it] 10%|█         | 2100/20600 [12:16:29<99:35:57, 19.38s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8919354195168906e-05, 'epoch': 20.24}
 10%|█         | 2100/20600 [12:16:29<99:35:57, 19.38s/it][INFO|trainer.py:3081] 2023-08-17 04:05:32,086 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:05:32,087 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:05:32,087 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7254, 'eval_samples_per_second': 1.879, 'eval_steps_per_second': 0.268, 'epoch': 20.24}
 10%|█         | 2100/20600 [12:16:33<99:35:57, 19.38s/it]
100%|██████████| 1/1 [00:02<00:00,  2.87s/it][A
                                             [A 10%|█         | 2101/20600 [12:16:56<110:56:48, 21.59s/it] 10%|█         | 2102/20600 [12:17:15<107:34:07, 20.93s/it] 10%|█         | 2103/20600 [12:17:30<97:59:26, 19.07s/it]  10%|█         | 2104/20600 [12:17:46<93:56:15, 18.28s/it] 10%|█         | 2105/20600 [12:18:07<97:25:28, 18.96s/it] 10%|█         | 2106/20600 [12:18:24<94:41:11, 18.43s/it] 10%|█         | 2107/20600 [12:18:41<93:00:40, 18.11s/it] 10%|█         | 2108/20600 [12:19:09<107:51:27, 21.00s/it] 10%|█         | 2109/20600 [12:19:28<103:57:14, 20.24s/it] 10%|█         | 2110/20600 [12:19:52<110:31:20, 21.52s/it]                                                           {'loss': 0.0, 'learning_rate': 4.890823809104493e-05, 'epoch': 20.34}
 10%|█         | 2110/20600 [12:19:52<110:31:20, 21.52s/it][INFO|trainer.py:3081] 2023-08-17 04:08:55,209 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:08:55,210 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:08:55,210 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3183, 'eval_samples_per_second': 2.109, 'eval_steps_per_second': 0.301, 'epoch': 20.34}
 10%|█         | 2110/20600 [12:19:56<110:31:20, 21.52s/it]
100%|██████████| 1/1 [00:02<00:00,  2.43s/it][A
                                             [A 10%|█         | 2111/20600 [12:20:12<107:47:47, 20.99s/it] 10%|█         | 2112/20600 [12:20:38<114:55:37, 22.38s/it] 10%|█         | 2113/20600 [12:20:57<110:56:05, 21.60s/it] 10%|█         | 2114/20600 [12:21:14<103:58:15, 20.25s/it] 10%|█         | 2115/20600 [12:21:37<107:46:38, 20.99s/it] 10%|█         | 2116/20600 [12:21:57<106:24:55, 20.73s/it] 10%|█         | 2117/20600 [12:22:13<99:12:15, 19.32s/it]  10%|█         | 2118/20600 [12:22:30<95:29:42, 18.60s/it] 10%|█         | 2119/20600 [12:22:56<106:49:06, 20.81s/it] 10%|█         | 2120/20600 [12:23:17<106:34:55, 20.76s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8897066382055725e-05, 'epoch': 20.43}
 10%|█         | 2120/20600 [12:23:17<106:34:55, 20.76s/it][INFO|trainer.py:3081] 2023-08-17 04:12:19,886 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:12:19,886 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:12:19,886 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.991, 'eval_samples_per_second': 1.754, 'eval_steps_per_second': 0.251, 'epoch': 20.43}
 10%|█         | 2120/20600 [12:23:21<106:34:55, 20.76s/it]
100%|██████████| 1/1 [00:03<00:00,  3.10s/it][A
                                             [A 10%|█         | 2121/20600 [12:23:48<123:13:12, 24.01s/it] 10%|█         | 2122/20600 [12:24:07<114:32:21, 22.32s/it] 10%|█         | 2123/20600 [12:24:33<119:45:01, 23.33s/it] 10%|█         | 2124/20600 [12:24:55<117:54:20, 22.97s/it] 10%|█         | 2125/20600 [12:25:15<113:58:08, 22.21s/it] 10%|█         | 2126/20600 [12:25:33<108:06:52, 21.07s/it] 10%|█         | 2127/20600 [12:25:52<103:34:53, 20.19s/it] 10%|█         | 2128/20600 [12:26:10<100:13:01, 19.53s/it] 10%|█         | 2129/20600 [12:26:33<106:44:45, 20.80s/it] 10%|█         | 2130/20600 [12:26:56<109:44:44, 21.39s/it]                                                           {'loss': 0.0, 'learning_rate': 4.888583909418399e-05, 'epoch': 20.53}
 10%|█         | 2130/20600 [12:26:56<109:44:44, 21.39s/it][INFO|trainer.py:3081] 2023-08-17 04:15:59,146 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:15:59,147 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:15:59,147 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.1723, 'eval_samples_per_second': 0.976, 'eval_steps_per_second': 0.139, 'epoch': 20.53}
 10%|█         | 2130/20600 [12:27:03<109:44:44, 21.39s/it]
100%|██████████| 1/1 [00:06<00:00,  6.28s/it][A
                                             [A 10%|█         | 2131/20600 [12:27:21<115:30:56, 22.52s/it] 10%|█         | 2132/20600 [12:27:45<117:17:25, 22.86s/it] 10%|█         | 2133/20600 [12:28:00<105:38:24, 20.59s/it] 10%|█         | 2134/20600 [12:28:19<103:02:34, 20.09s/it] 10%|█         | 2135/20600 [12:28:46<113:52:42, 22.20s/it] 10%|█         | 2136/20600 [12:29:04<107:40:14, 20.99s/it] 10%|█         | 2137/20600 [12:29:24<105:58:30, 20.66s/it] 10%|█         | 2138/20600 [12:29:46<107:18:14, 20.92s/it] 10%|█         | 2139/20600 [12:30:07<107:56:03, 21.05s/it] 10%|█         | 2140/20600 [12:30:25<102:10:55, 19.93s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8874556253541756e-05, 'epoch': 20.63}
 10%|█         | 2140/20600 [12:30:25<102:10:55, 19.93s/it][INFO|trainer.py:3081] 2023-08-17 04:19:27,569 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:19:27,569 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:19:27,569 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.6979, 'eval_samples_per_second': 0.909, 'eval_steps_per_second': 0.13, 'epoch': 20.63}
 10%|█         | 2140/20600 [12:30:32<102:10:55, 19.93s/it]
100%|██████████| 1/1 [00:06<00:00,  6.75s/it][A
                                             [A 10%|█         | 2141/20600 [12:30:51<112:49:45, 22.00s/it] 10%|█         | 2142/20600 [12:31:09<106:11:32, 20.71s/it] 10%|█         | 2143/20600 [12:31:28<102:39:57, 20.02s/it] 10%|█         | 2144/20600 [12:31:51<107:16:13, 20.92s/it] 10%|█         | 2145/20600 [12:32:07<101:06:47, 19.72s/it] 10%|█         | 2146/20600 [12:32:25<98:14:40, 19.17s/it]  10%|█         | 2147/20600 [12:32:50<106:25:01, 20.76s/it] 10%|█         | 2148/20600 [12:33:07<100:51:05, 19.68s/it] 10%|█         | 2149/20600 [12:33:32<108:27:13, 21.16s/it] 10%|█         | 2150/20600 [12:33:51<106:07:50, 20.71s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8863217886370204e-05, 'epoch': 20.72}
 10%|█         | 2150/20600 [12:33:51<106:07:50, 20.71s/it][INFO|trainer.py:3081] 2023-08-17 04:22:54,246 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:22:54,246 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:22:54,246 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3863, 'eval_samples_per_second': 1.096, 'eval_steps_per_second': 0.157, 'epoch': 20.72}
 10%|█         | 2150/20600 [12:33:58<106:07:50, 20.71s/it]
100%|██████████| 1/1 [00:05<00:00,  5.50s/it][A
                                             [A 10%|█         | 2151/20600 [12:34:17<113:41:23, 22.18s/it] 10%|█         | 2152/20600 [12:34:36<108:51:11, 21.24s/it] 10%|█         | 2153/20600 [12:34:55<105:33:58, 20.60s/it] 10%|█         | 2154/20600 [12:35:22<115:52:04, 22.61s/it] 10%|█         | 2155/20600 [12:35:43<112:57:36, 22.05s/it] 10%|█         | 2156/20600 [12:36:03<109:04:09, 21.29s/it] 10%|█         | 2157/20600 [12:36:20<102:59:52, 20.10s/it] 10%|█         | 2158/20600 [12:36:37<98:22:14, 19.20s/it]  10%|█         | 2159/20600 [12:36:56<98:29:24, 19.23s/it] 10%|█         | 2160/20600 [12:37:13<94:28:51, 18.45s/it]                                                          {'loss': 0.0, 'learning_rate': 4.885182401903967e-05, 'epoch': 20.82}
 10%|█         | 2160/20600 [12:37:13<94:28:51, 18.45s/it][INFO|trainer.py:3081] 2023-08-17 04:26:15,922 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:26:15,922 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:26:15,922 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.6056, 'eval_samples_per_second': 1.249, 'eval_steps_per_second': 0.178, 'epoch': 20.82}
 10%|█         | 2160/20600 [12:37:19<94:28:51, 18.45s/it]
100%|██████████| 1/1 [00:04<00:00,  4.66s/it][A
                                             [A 10%|█         | 2161/20600 [12:37:35<100:08:40, 19.55s/it] 10%|█         | 2162/20600 [12:37:58<105:46:08, 20.65s/it] 10%|█         | 2163/20600 [12:38:18<104:23:15, 20.38s/it] 11%|█         | 2164/20600 [12:38:36<100:31:02, 19.63s/it] 11%|█         | 2165/20600 [12:38:56<101:52:16, 19.89s/it] 11%|█         | 2166/20600 [12:39:13<97:29:11, 19.04s/it]  11%|█         | 2167/20600 [12:39:40<109:06:59, 21.31s/it] 11%|█         | 2168/20600 [12:40:01<108:43:41, 21.24s/it] 11%|█         | 2169/20600 [12:40:21<106:00:22, 20.71s/it] 11%|█         | 2170/20600 [12:40:41<105:55:28, 20.69s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8840374678049586e-05, 'epoch': 20.92}
 11%|█         | 2170/20600 [12:40:41<105:55:28, 20.69s/it][INFO|trainer.py:3081] 2023-08-17 04:29:44,250 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:29:44,250 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:29:44,251 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.6639, 'eval_samples_per_second': 0.808, 'eval_steps_per_second': 0.115, 'epoch': 20.92}
 11%|█         | 2170/20600 [12:40:50<105:55:28, 20.69s/it]
100%|██████████| 1/1 [00:07<00:00,  7.75s/it][A
                                             [A 11%|█         | 2171/20600 [12:41:12<120:58:31, 23.63s/it] 11%|█         | 2172/20600 [12:41:31<114:35:57, 22.39s/it] 11%|█         | 2173/20600 [12:41:50<108:17:56, 21.16s/it] 11%|█         | 2174/20600 [12:42:09<106:23:28, 20.79s/it] 11%|█         | 2175/20600 [12:42:37<117:16:04, 22.91s/it] 11%|█         | 2176/20600 [12:43:05<124:46:36, 24.38s/it] 11%|█         | 2177/20600 [12:43:32<128:38:07, 25.14s/it] 11%|█         | 2178/20600 [12:43:53<122:00:34, 23.84s/it] 11%|█         | 2179/20600 [12:44:10<112:09:53, 21.92s/it] 11%|█         | 2180/20600 [12:44:36<117:49:46, 23.03s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8828869890028385e-05, 'epoch': 21.01}
 11%|█         | 2180/20600 [12:44:36<117:49:46, 23.03s/it][INFO|trainer.py:3081] 2023-08-17 04:33:38,894 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:33:38,894 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:33:38,894 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7817, 'eval_samples_per_second': 1.851, 'eval_steps_per_second': 0.264, 'epoch': 21.01}
 11%|█         | 2180/20600 [12:44:40<117:49:46, 23.03s/it]
100%|██████████| 1/1 [00:02<00:00,  2.91s/it][A
                                             [A 11%|█         | 2181/20600 [12:44:56<113:57:17, 22.27s/it] 11%|█         | 2182/20600 [12:45:20<116:16:14, 22.73s/it] 11%|█         | 2183/20600 [12:45:38<108:22:15, 21.18s/it] 11%|█         | 2184/20600 [12:45:59<108:13:55, 21.16s/it] 11%|█         | 2185/20600 [12:46:17<103:07:54, 20.16s/it] 11%|█         | 2186/20600 [12:46:46<117:33:56, 22.98s/it] 11%|█         | 2187/20600 [12:47:06<112:01:11, 21.90s/it] 11%|█         | 2188/20600 [12:47:23<105:23:27, 20.61s/it] 11%|█         | 2189/20600 [12:47:40<98:47:39, 19.32s/it]  11%|█         | 2190/20600 [12:48:04<106:05:59, 20.75s/it]                                                           {'loss': 0.0, 'learning_rate': 4.881730968173347e-05, 'epoch': 21.11}
 11%|█         | 2190/20600 [12:48:04<106:05:59, 20.75s/it][INFO|trainer.py:3081] 2023-08-17 04:37:06,626 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:37:06,626 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:37:06,626 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.7257, 'eval_samples_per_second': 1.041, 'eval_steps_per_second': 0.149, 'epoch': 21.11}
 11%|█         | 2190/20600 [12:48:10<106:05:59, 20.75s/it]
100%|██████████| 1/1 [00:05<00:00,  5.87s/it][A
                                             [A 11%|█         | 2191/20600 [12:48:25<106:48:08, 20.89s/it] 11%|█         | 2192/20600 [12:48:50<112:59:31, 22.10s/it] 11%|█         | 2193/20600 [12:49:08<106:27:28, 20.82s/it] 11%|█         | 2194/20600 [12:49:27<104:14:30, 20.39s/it] 11%|█         | 2195/20600 [12:49:52<111:35:03, 21.83s/it] 11%|█         | 2196/20600 [12:50:11<106:18:26, 20.79s/it] 11%|█         | 2197/20600 [12:50:31<105:41:19, 20.67s/it] 11%|█         | 2198/20600 [12:50:56<112:15:46, 21.96s/it] 11%|█         | 2199/20600 [12:51:14<106:33:29, 20.85s/it] 11%|█         | 2200/20600 [12:51:37<110:10:05, 21.55s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8805694080051115e-05, 'epoch': 21.2}
 11%|█         | 2200/20600 [12:51:37<110:10:05, 21.55s/it][INFO|trainer.py:3081] 2023-08-17 04:40:40,359 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:40:40,359 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:40:40,359 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.4242, 'eval_samples_per_second': 1.09, 'eval_steps_per_second': 0.156, 'epoch': 21.2}
 11%|█         | 2200/20600 [12:51:44<110:10:05, 21.55s/it]
100%|██████████| 1/1 [00:05<00:00,  5.53s/it][A
                                             [A 11%|█         | 2201/20600 [12:52:01<112:49:59, 22.08s/it] 11%|█         | 2202/20600 [12:52:26<117:34:46, 23.01s/it] 11%|█         | 2203/20600 [12:52:45<111:45:38, 21.87s/it] 11%|█         | 2204/20600 [12:53:03<105:12:00, 20.59s/it] 11%|█         | 2205/20600 [12:53:20<100:00:13, 19.57s/it] 11%|█         | 2206/20600 [12:53:41<101:41:26, 19.90s/it] 11%|█         | 2207/20600 [12:53:59<100:02:11, 19.58s/it] 11%|█         | 2208/20600 [12:54:17<96:49:30, 18.95s/it]  11%|█         | 2209/20600 [12:54:38<99:50:30, 19.54s/it] 11%|█         | 2210/20600 [12:54:55<96:31:26, 18.90s/it]                                                          {'loss': 0.0, 'learning_rate': 4.8794023111996455e-05, 'epoch': 21.3}
 11%|█         | 2210/20600 [12:54:55<96:31:26, 18.90s/it][INFO|trainer.py:3081] 2023-08-17 04:43:58,140 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:43:58,140 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:43:58,140 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.6215, 'eval_samples_per_second': 1.245, 'eval_steps_per_second': 0.178, 'epoch': 21.3}
 11%|█         | 2210/20600 [12:55:01<96:31:26, 18.90s/it]
100%|██████████| 1/1 [00:04<00:00,  4.74s/it][A
                                             [A 11%|█         | 2211/20600 [12:55:25<113:23:04, 22.20s/it] 11%|█         | 2212/20600 [12:55:46<111:26:56, 21.82s/it] 11%|█         | 2213/20600 [12:56:06<108:25:47, 21.23s/it] 11%|█         | 2214/20600 [12:56:24<103:24:51, 20.25s/it] 11%|█         | 2215/20600 [12:56:44<104:02:07, 20.37s/it] 11%|█         | 2216/20600 [12:57:02<98:57:03, 19.38s/it]  11%|█         | 2217/20600 [12:57:31<115:05:38, 22.54s/it] 11%|█         | 2218/20600 [12:57:48<106:36:04, 20.88s/it] 11%|█         | 2219/20600 [12:58:11<109:20:16, 21.41s/it] 11%|█         | 2220/20600 [12:58:38<118:21:41, 23.18s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8782296804713377e-05, 'epoch': 21.4}
 11%|█         | 2220/20600 [12:58:38<118:21:41, 23.18s/it][INFO|trainer.py:3081] 2023-08-17 04:47:41,404 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:47:41,405 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:47:41,405 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 9.1454, 'eval_samples_per_second': 0.765, 'eval_steps_per_second': 0.109, 'epoch': 21.4}
 11%|█         | 2220/20600 [12:58:48<118:21:41, 23.18s/it]
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A
                                             [A 11%|█         | 2221/20600 [12:59:05<123:24:24, 24.17s/it] 11%|█         | 2222/20600 [12:59:28<121:42:46, 23.84s/it] 11%|█         | 2223/20600 [12:59:47<115:06:27, 22.55s/it] 11%|█         | 2224/20600 [13:00:06<108:13:43, 21.20s/it] 11%|█         | 2225/20600 [13:00:29<111:43:36, 21.89s/it] 11%|█         | 2226/20600 [13:00:47<105:01:02, 20.58s/it] 11%|█         | 2227/20600 [13:01:13<113:21:50, 22.21s/it] 11%|█         | 2228/20600 [13:01:35<113:10:31, 22.18s/it] 11%|█         | 2229/20600 [13:02:01<119:31:32, 23.42s/it] 11%|█         | 2230/20600 [13:02:31<128:56:31, 25.27s/it]                                                           {'loss': 0.0, 'learning_rate': 4.877051518547448e-05, 'epoch': 21.49}
 11%|█         | 2230/20600 [13:02:31<128:56:31, 25.27s/it][INFO|trainer.py:3081] 2023-08-17 04:51:33,586 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:51:33,586 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:51:33,586 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.3835, 'eval_samples_per_second': 1.597, 'eval_steps_per_second': 0.228, 'epoch': 21.49}
 11%|█         | 2230/20600 [13:02:35<128:56:31, 25.27s/it]
100%|██████████| 1/1 [00:03<00:00,  3.53s/it][A
                                             [A 11%|█         | 2231/20600 [13:02:49<119:09:47, 23.35s/it] 11%|█         | 2232/20600 [13:03:12<117:50:30, 23.10s/it] 11%|█         | 2233/20600 [13:03:31<111:54:01, 21.93s/it] 11%|█         | 2234/20600 [13:03:49<106:08:07, 20.80s/it] 11%|█         | 2235/20600 [13:04:10<106:16:36, 20.83s/it] 11%|█         | 2236/20600 [13:04:34<110:13:07, 21.61s/it] 11%|█         | 2237/20600 [13:04:52<104:50:00, 20.55s/it] 11%|█         | 2238/20600 [13:05:15<109:32:09, 21.48s/it] 11%|█         | 2239/20600 [13:05:33<103:28:10, 20.29s/it] 11%|█         | 2240/20600 [13:05:53<103:43:08, 20.34s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8758678281681e-05, 'epoch': 21.59}
 11%|█         | 2240/20600 [13:05:53<103:43:08, 20.34s/it][INFO|trainer.py:3081] 2023-08-17 04:54:56,352 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:54:56,352 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:54:56,352 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9341, 'eval_samples_per_second': 1.779, 'eval_steps_per_second': 0.254, 'epoch': 21.59}
 11%|█         | 2240/20600 [13:05:57<103:43:08, 20.34s/it]
100%|██████████| 1/1 [00:03<00:00,  3.03s/it][A
                                             [A 11%|█         | 2241/20600 [13:06:12<101:10:55, 19.84s/it] 11%|█         | 2242/20600 [13:06:36<107:21:25, 21.05s/it] 11%|█         | 2243/20600 [13:06:55<103:58:34, 20.39s/it] 11%|█         | 2244/20600 [13:07:11<98:03:09, 19.23s/it]  11%|█         | 2245/20600 [13:07:35<104:31:50, 20.50s/it] 11%|█         | 2246/20600 [13:07:52<99:46:32, 19.57s/it]  11%|█         | 2247/20600 [13:08:09<94:56:02, 18.62s/it] 11%|█         | 2248/20600 [13:08:28<96:28:03, 18.92s/it] 11%|█         | 2249/20600 [13:08:49<100:04:59, 19.63s/it] 11%|█         | 2250/20600 [13:09:11<103:32:02, 20.31s/it]                                                           {'loss': 0.0, 'learning_rate': 4.874678612086276e-05, 'epoch': 21.69}
 11%|█         | 2250/20600 [13:09:11<103:32:02, 20.31s/it][INFO|trainer.py:3081] 2023-08-17 04:58:14,379 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 04:58:14,379 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 04:58:14,379 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0635, 'eval_samples_per_second': 0.991, 'eval_steps_per_second': 0.142, 'epoch': 21.69}
 11%|█         | 2250/20600 [13:09:18<103:32:02, 20.31s/it]
100%|██████████| 1/1 [00:06<00:00,  6.20s/it][A
                                             [A 11%|█         | 2251/20600 [13:09:38<113:04:43, 22.19s/it] 11%|█         | 2252/20600 [13:09:56<106:58:53, 20.99s/it] 11%|█         | 2253/20600 [13:10:14<102:47:48, 20.17s/it] 11%|█         | 2254/20600 [13:10:32<98:38:31, 19.36s/it]  11%|█         | 2255/20600 [13:10:52<100:27:16, 19.71s/it] 11%|█         | 2256/20600 [13:11:15<105:21:13, 20.68s/it] 11%|█         | 2257/20600 [13:11:34<101:47:02, 19.98s/it] 11%|█         | 2258/20600 [13:11:53<101:16:15, 19.88s/it] 11%|█         | 2259/20600 [13:12:11<97:52:37, 19.21s/it]  11%|█         | 2260/20600 [13:12:30<97:44:02, 19.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.873483873067809e-05, 'epoch': 21.78}
 11%|█         | 2260/20600 [13:12:30<97:44:02, 19.18s/it][INFO|trainer.py:3081] 2023-08-17 05:01:33,091 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:01:33,091 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:01:33,091 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.8099, 'eval_samples_per_second': 0.795, 'eval_steps_per_second': 0.114, 'epoch': 21.78}
 11%|█         | 2260/20600 [13:12:39<97:44:02, 19.18s/it]
100%|██████████| 1/1 [00:07<00:00,  7.87s/it][A
                                             [A 11%|█         | 2261/20600 [13:12:56<108:36:18, 21.32s/it] 11%|█         | 2262/20600 [13:13:22<114:37:19, 22.50s/it] 11%|█         | 2263/20600 [13:13:50<124:17:41, 24.40s/it] 11%|█         | 2264/20600 [13:14:07<112:31:34, 22.09s/it] 11%|█         | 2265/20600 [13:14:29<112:02:25, 22.00s/it] 11%|█         | 2266/20600 [13:14:54<116:21:58, 22.85s/it] 11%|█         | 2267/20600 [13:15:10<105:43:01, 20.76s/it] 11%|█         | 2268/20600 [13:15:31<106:39:09, 20.94s/it] 11%|█         | 2269/20600 [13:15:47<99:19:18, 19.51s/it]  11%|█         | 2270/20600 [13:16:11<106:24:33, 20.90s/it]                                                           {'loss': 0.0, 'learning_rate': 4.872283613891376e-05, 'epoch': 21.88}
 11%|█         | 2270/20600 [13:16:11<106:24:33, 20.90s/it][INFO|trainer.py:3081] 2023-08-17 05:05:14,351 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:05:14,351 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:05:14,352 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.0279, 'eval_samples_per_second': 1.392, 'eval_steps_per_second': 0.199, 'epoch': 21.88}
 11%|█         | 2270/20600 [13:16:16<106:24:33, 20.90s/it]
100%|██████████| 1/1 [00:04<00:00,  4.20s/it][A
                                             [A 11%|█         | 2271/20600 [13:16:31<104:58:18, 20.62s/it] 11%|█         | 2272/20600 [13:16:53<106:56:21, 21.01s/it] 11%|█         | 2273/20600 [13:17:26<124:10:14, 24.39s/it] 11%|█         | 2274/20600 [13:17:41<110:56:58, 21.80s/it] 11%|█         | 2275/20600 [13:18:15<129:22:26, 25.42s/it] 11%|█         | 2276/20600 [13:18:42<131:49:17, 25.90s/it] 11%|█         | 2277/20600 [13:18:59<118:40:13, 23.32s/it] 11%|█         | 2278/20600 [13:19:16<108:47:18, 21.38s/it] 11%|█         | 2279/20600 [13:19:40<112:38:17, 22.13s/it] 11%|█         | 2280/20600 [13:20:04<115:06:55, 22.62s/it]                                                           {'loss': 0.0, 'learning_rate': 4.871077837348497e-05, 'epoch': 21.98}
 11%|█         | 2280/20600 [13:20:04<115:06:55, 22.62s/it][INFO|trainer.py:3081] 2023-08-17 05:09:06,941 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:09:06,941 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:09:06,941 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1458, 'eval_samples_per_second': 1.688, 'eval_steps_per_second': 0.241, 'epoch': 21.98}
 11%|█         | 2280/20600 [13:20:08<115:06:55, 22.62s/it]
100%|██████████| 1/1 [00:03<00:00,  3.29s/it][A
                                             [A 11%|█         | 2281/20600 [13:20:35<127:22:36, 25.03s/it] 11%|█         | 2282/20600 [13:20:54<118:35:09, 23.31s/it] 11%|█         | 2283/20600 [13:21:16<116:49:23, 22.96s/it] 11%|█         | 2284/20600 [13:21:31<104:56:03, 20.62s/it] 11%|█         | 2285/20600 [13:21:56<111:37:56, 21.94s/it] 11%|█         | 2286/20600 [13:22:12<102:31:00, 20.15s/it] 11%|█         | 2287/20600 [13:22:39<113:14:08, 22.26s/it] 11%|█         | 2288/20600 [13:23:01<112:25:02, 22.10s/it] 11%|█         | 2289/20600 [13:23:21<109:02:18, 21.44s/it] 11%|█         | 2290/20600 [13:23:39<103:13:12, 20.29s/it]                                                           {'loss': 0.0, 'learning_rate': 4.869866546243518e-05, 'epoch': 22.07}
 11%|█         | 2290/20600 [13:23:39<103:13:12, 20.29s/it][INFO|trainer.py:3081] 2023-08-17 05:12:41,620 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:12:41,620 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:12:41,620 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0417, 'eval_samples_per_second': 1.732, 'eval_steps_per_second': 0.247, 'epoch': 22.07}
 11%|█         | 2290/20600 [13:23:43<103:13:12, 20.29s/it]
100%|██████████| 1/1 [00:03<00:00,  3.22s/it][A
                                             [A 11%|█         | 2291/20600 [13:24:02<108:14:32, 21.28s/it] 11%|█         | 2292/20600 [13:24:19<101:53:32, 20.04s/it] 11%|█         | 2293/20600 [13:24:42<106:04:13, 20.86s/it] 11%|█         | 2294/20600 [13:25:03<105:24:01, 20.73s/it] 11%|█         | 2295/20600 [13:25:21<101:51:38, 20.03s/it] 11%|█         | 2296/20600 [13:25:38<97:16:59, 19.13s/it]  11%|█         | 2297/20600 [13:26:01<102:44:03, 20.21s/it] 11%|█         | 2298/20600 [13:26:24<106:46:21, 21.00s/it] 11%|█         | 2299/20600 [13:26:42<102:46:54, 20.22s/it] 11%|█         | 2300/20600 [13:26:58<96:56:12, 19.07s/it]                                                           {'loss': 0.0, 'learning_rate': 4.868649743393614e-05, 'epoch': 22.17}
 11%|█         | 2300/20600 [13:26:58<96:56:12, 19.07s/it][INFO|trainer.py:3081] 2023-08-17 05:16:01,329 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:16:01,329 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:16:01,329 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7126, 'eval_samples_per_second': 1.885, 'eval_steps_per_second': 0.269, 'epoch': 22.17}
 11%|█         | 2300/20600 [13:27:02<96:56:12, 19.07s/it]
100%|██████████| 1/1 [00:02<00:00,  2.87s/it][A
                                             [A 11%|█         | 2301/20600 [13:27:18<98:03:14, 19.29s/it] 11%|█         | 2302/20600 [13:27:45<109:10:09, 21.48s/it] 11%|█         | 2303/20600 [13:28:00<99:58:46, 19.67s/it]  11%|█         | 2304/20600 [13:28:21<102:04:04, 20.08s/it] 11%|█         | 2305/20600 [13:28:39<98:02:04, 19.29s/it]  11%|█         | 2306/20600 [13:28:59<99:39:42, 19.61s/it] 11%|█         | 2307/20600 [13:29:16<95:18:40, 18.76s/it] 11%|█         | 2308/20600 [13:29:38<100:49:41, 19.84s/it] 11%|█         | 2309/20600 [13:29:53<92:49:31, 18.27s/it]  11%|█         | 2310/20600 [13:30:13<95:51:30, 18.87s/it]                                                          {'loss': 0.0, 'learning_rate': 4.867427431628779e-05, 'epoch': 22.27}
 11%|█         | 2310/20600 [13:30:13<95:51:30, 18.87s/it][INFO|trainer.py:3081] 2023-08-17 05:19:16,024 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:19:16,025 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:19:16,025 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.2256, 'eval_samples_per_second': 0.759, 'eval_steps_per_second': 0.108, 'epoch': 22.27}
 11%|█         | 2310/20600 [13:30:22<95:51:30, 18.87s/it]
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A
                                             [A 11%|█         | 2311/20600 [13:30:45<116:18:32, 22.89s/it] 11%|█         | 2312/20600 [13:31:02<106:14:44, 20.91s/it] 11%|█         | 2313/20600 [13:31:20<101:49:06, 20.04s/it] 11%|█         | 2314/20600 [13:31:43<107:05:42, 21.08s/it] 11%|█         | 2315/20600 [13:32:00<101:21:21, 19.96s/it] 11%|█         | 2316/20600 [13:32:23<105:58:14, 20.86s/it] 11%|█         | 2317/20600 [13:32:44<105:04:43, 20.69s/it] 11%|█▏        | 2318/20600 [13:33:08<110:11:14, 21.70s/it] 11%|█▏        | 2319/20600 [13:33:30<110:19:25, 21.73s/it] 11%|█▏        | 2320/20600 [13:33:49<106:04:42, 20.89s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8661996137918206e-05, 'epoch': 22.36}
 11%|█▏        | 2320/20600 [13:33:49<106:04:42, 20.89s/it][INFO|trainer.py:3081] 2023-08-17 05:22:51,540 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:22:51,540 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:22:51,540 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.1008, 'eval_samples_per_second': 0.864, 'eval_steps_per_second': 0.123, 'epoch': 22.36}
 11%|█▏        | 2320/20600 [13:33:57<106:04:42, 20.89s/it]
100%|██████████| 1/1 [00:07<00:00,  7.21s/it][A
                                             [A 11%|█▏        | 2321/20600 [13:34:13<111:08:51, 21.89s/it] 11%|█▏        | 2322/20600 [13:34:34<110:01:44, 21.67s/it] 11%|█▏        | 2323/20600 [13:34:50<101:41:33, 20.03s/it] 11%|█▏        | 2324/20600 [13:35:16<110:59:26, 21.86s/it] 11%|█▏        | 2325/20600 [13:35:38<111:32:27, 21.97s/it] 11%|█▏        | 2326/20600 [13:36:00<110:19:57, 21.74s/it] 11%|█▏        | 2327/20600 [13:36:17<102:57:48, 20.29s/it] 11%|█▏        | 2328/20600 [13:36:34<99:23:35, 19.58s/it]  11%|█▏        | 2329/20600 [13:36:59<107:29:15, 21.18s/it] 11%|█▏        | 2330/20600 [13:37:16<100:59:04, 19.90s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8649662927383474e-05, 'epoch': 22.46}
 11%|█▏        | 2330/20600 [13:37:16<100:59:04, 19.90s/it][INFO|trainer.py:3081] 2023-08-17 05:26:19,294 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:26:19,295 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:26:19,295 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7837, 'eval_samples_per_second': 1.85, 'eval_steps_per_second': 0.264, 'epoch': 22.46}
 11%|█▏        | 2330/20600 [13:37:20<100:59:04, 19.90s/it]
100%|██████████| 1/1 [00:02<00:00,  2.87s/it][A
                                             [A 11%|█▏        | 2331/20600 [13:37:44<112:05:58, 22.09s/it] 11%|█▏        | 2332/20600 [13:37:57<99:03:54, 19.52s/it]  11%|█▏        | 2333/20600 [13:38:18<101:11:42, 19.94s/it] 11%|█▏        | 2334/20600 [13:38:33<93:31:30, 18.43s/it]  11%|█▏        | 2335/20600 [13:38:54<98:18:58, 19.38s/it] 11%|█▏        | 2336/20600 [13:39:11<94:03:11, 18.54s/it] 11%|█▏        | 2337/20600 [13:39:28<91:17:08, 17.99s/it] 11%|█▏        | 2338/20600 [13:39:47<93:53:42, 18.51s/it] 11%|█▏        | 2339/20600 [13:40:10<99:22:01, 19.59s/it] 11%|█▏        | 2340/20600 [13:40:30<101:04:46, 19.93s/it]                                                           {'loss': 0.0, 'learning_rate': 4.863727471336772e-05, 'epoch': 22.55}
 11%|█▏        | 2340/20600 [13:40:30<101:04:46, 19.93s/it][INFO|trainer.py:3081] 2023-08-17 05:29:33,301 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:29:33,301 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:29:33,301 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3194, 'eval_samples_per_second': 1.108, 'eval_steps_per_second': 0.158, 'epoch': 22.55}
 11%|█▏        | 2340/20600 [13:40:37<101:04:46, 19.93s/it]
100%|██████████| 1/1 [00:05<00:00,  5.41s/it][A
                                             [A 11%|█▏        | 2341/20600 [13:40:55<107:44:40, 21.24s/it] 11%|█▏        | 2342/20600 [13:41:17<108:55:16, 21.48s/it] 11%|█▏        | 2343/20600 [13:41:37<107:01:58, 21.11s/it] 11%|█▏        | 2344/20600 [13:41:58<106:21:43, 20.97s/it] 11%|█▏        | 2345/20600 [13:42:15<101:28:13, 20.01s/it] 11%|█▏        | 2346/20600 [13:42:44<115:14:47, 22.73s/it] 11%|█▏        | 2347/20600 [13:43:08<117:21:36, 23.15s/it] 11%|█▏        | 2348/20600 [13:43:27<109:52:28, 21.67s/it] 11%|█▏        | 2349/20600 [13:43:53<116:30:02, 22.98s/it] 11%|█▏        | 2350/20600 [13:44:20<123:18:14, 24.32s/it]                                                           {'loss': 0.0, 'learning_rate': 4.862483152468298e-05, 'epoch': 22.65}
 11%|█▏        | 2350/20600 [13:44:20<123:18:14, 24.32s/it][INFO|trainer.py:3081] 2023-08-17 05:33:23,197 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:33:23,197 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:33:23,197 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3673, 'eval_samples_per_second': 2.079, 'eval_steps_per_second': 0.297, 'epoch': 22.65}
 11%|█▏        | 2350/20600 [13:44:24<123:18:14, 24.32s/it]
100%|██████████| 1/1 [00:02<00:00,  2.55s/it][A
                                             [A 11%|█▏        | 2351/20600 [13:44:47<127:29:53, 25.15s/it] 11%|█▏        | 2352/20600 [13:45:02<112:06:36, 22.12s/it] 11%|█▏        | 2353/20600 [13:45:26<114:20:18, 22.56s/it] 11%|█▏        | 2354/20600 [13:45:47<111:50:55, 22.07s/it] 11%|█▏        | 2355/20600 [13:46:05<106:12:41, 20.96s/it] 11%|█▏        | 2356/20600 [13:46:23<101:14:36, 19.98s/it] 11%|█▏        | 2357/20600 [13:46:50<112:06:01, 22.12s/it] 11%|█▏        | 2358/20600 [13:47:06<103:18:42, 20.39s/it] 11%|█▏        | 2359/20600 [13:47:27<104:24:44, 20.61s/it] 11%|█▏        | 2360/20600 [13:47:48<103:43:25, 20.47s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8612333390269135e-05, 'epoch': 22.75}
 11%|█▏        | 2360/20600 [13:47:48<103:43:25, 20.47s/it][INFO|trainer.py:3081] 2023-08-17 05:36:50,630 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:36:50,631 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:36:50,631 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.1586, 'eval_samples_per_second': 0.978, 'eval_steps_per_second': 0.14, 'epoch': 22.75}
 11%|█▏        | 2360/20600 [13:47:55<103:43:25, 20.47s/it]
100%|██████████| 1/1 [00:06<00:00,  6.28s/it][A
                                             [A 11%|█▏        | 2361/20600 [13:48:19<119:54:01, 23.67s/it] 11%|█▏        | 2362/20600 [13:48:37<111:28:33, 22.00s/it] 11%|█▏        | 2363/20600 [13:48:55<105:04:09, 20.74s/it] 11%|█▏        | 2364/20600 [13:49:17<108:04:00, 21.33s/it] 11%|█▏        | 2365/20600 [13:49:38<106:24:58, 21.01s/it] 11%|█▏        | 2366/20600 [13:50:00<107:51:54, 21.30s/it] 11%|█▏        | 2367/20600 [13:50:26<116:04:22, 22.92s/it] 11%|█▏        | 2368/20600 [13:50:44<108:36:49, 21.45s/it] 12%|█▏        | 2369/20600 [13:51:06<108:17:51, 21.39s/it] 12%|█▏        | 2370/20600 [13:51:31<114:19:39, 22.58s/it]                                                           {'loss': 0.0, 'learning_rate': 4.859978033919388e-05, 'epoch': 22.84}
 12%|█▏        | 2370/20600 [13:51:31<114:19:39, 22.58s/it][INFO|trainer.py:3081] 2023-08-17 05:40:33,955 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:40:33,955 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:40:33,955 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.7137, 'eval_samples_per_second': 0.803, 'eval_steps_per_second': 0.115, 'epoch': 22.84}
 12%|█▏        | 2370/20600 [13:51:40<114:19:39, 22.58s/it]
100%|██████████| 1/1 [00:07<00:00,  7.82s/it][A
                                             [A 12%|█▏        | 2371/20600 [13:52:09<138:01:24, 27.26s/it] 12%|█▏        | 2372/20600 [13:52:26<121:37:01, 24.02s/it] 12%|█▏        | 2373/20600 [13:52:42<110:14:23, 21.77s/it] 12%|█▏        | 2374/20600 [13:53:08<117:06:53, 23.13s/it] 12%|█▏        | 2375/20600 [13:53:30<114:05:35, 22.54s/it] 12%|█▏        | 2376/20600 [13:53:47<107:00:47, 21.14s/it] 12%|█▏        | 2377/20600 [13:54:05<101:44:39, 20.10s/it] 12%|█▏        | 2378/20600 [13:54:25<101:02:55, 19.96s/it] 12%|█▏        | 2379/20600 [13:54:46<102:44:31, 20.30s/it] 12%|█▏        | 2380/20600 [13:55:08<106:02:14, 20.95s/it]                                                           {'loss': 0.0, 'learning_rate': 4.858717240065262e-05, 'epoch': 22.94}
 12%|█▏        | 2380/20600 [13:55:08<106:02:14, 20.95s/it][INFO|trainer.py:3081] 2023-08-17 05:44:11,306 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:44:11,307 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:44:11,307 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 9.1618, 'eval_samples_per_second': 0.764, 'eval_steps_per_second': 0.109, 'epoch': 22.94}
 12%|█▏        | 2380/20600 [13:55:18<106:02:14, 20.95s/it]
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A
                                             [A 12%|█▏        | 2381/20600 [13:55:37<117:32:04, 23.22s/it] 12%|█▏        | 2382/20600 [13:55:55<109:50:36, 21.71s/it] 12%|█▏        | 2383/20600 [13:56:13<103:57:17, 20.54s/it] 12%|█▏        | 2384/20600 [13:56:33<103:30:47, 20.46s/it] 12%|█▏        | 2385/20600 [13:56:55<105:51:52, 20.92s/it] 12%|█▏        | 2386/20600 [13:57:13<101:51:50, 20.13s/it] 12%|█▏        | 2387/20600 [13:57:40<111:21:42, 22.01s/it] 12%|█▏        | 2388/20600 [13:57:57<104:13:30, 20.60s/it] 12%|█▏        | 2389/20600 [13:58:19<105:45:06, 20.91s/it] 12%|█▏        | 2390/20600 [13:58:41<107:07:10, 21.18s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8574509603968405e-05, 'epoch': 23.04}
 12%|█▏        | 2390/20600 [13:58:41<107:07:10, 21.18s/it][INFO|trainer.py:3081] 2023-08-17 05:47:43,730 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:47:43,730 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:47:43,730 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3678, 'eval_samples_per_second': 0.95, 'eval_steps_per_second': 0.136, 'epoch': 23.04}
 12%|█▏        | 2390/20600 [13:58:48<107:07:10, 21.18s/it]
100%|██████████| 1/1 [00:06<00:00,  6.54s/it][A
                                             [A 12%|█▏        | 2391/20600 [13:59:03<109:16:13, 21.60s/it] 12%|█▏        | 2392/20600 [13:59:25<109:29:29, 21.65s/it] 12%|█▏        | 2393/20600 [13:59:43<104:39:41, 20.69s/it] 12%|█▏        | 2394/20600 [14:00:04<104:59:36, 20.76s/it] 12%|█▏        | 2395/20600 [14:00:26<105:55:35, 20.95s/it] 12%|█▏        | 2396/20600 [14:00:44<102:08:22, 20.20s/it] 12%|█▏        | 2397/20600 [14:01:03<100:24:58, 19.86s/it] 12%|█▏        | 2398/20600 [14:01:26<105:31:10, 20.87s/it] 12%|█▏        | 2399/20600 [14:01:41<96:14:18, 19.04s/it]  12%|█▏        | 2400/20600 [14:02:03<100:40:59, 19.92s/it]                                                           {'loss': 0.0, 'learning_rate': 4.856179197859189e-05, 'epoch': 23.13}
 12%|█▏        | 2400/20600 [14:02:03<100:40:59, 19.92s/it][INFO|trainer.py:3081] 2023-08-17 05:51:06,089 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:51:06,089 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:51:06,089 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.7375, 'eval_samples_per_second': 0.905, 'eval_steps_per_second': 0.129, 'epoch': 23.13}
 12%|█▏        | 2400/20600 [14:02:11<100:40:59, 19.92s/it]
100%|██████████| 1/1 [00:06<00:00,  6.88s/it][A
                                             [A08/17/2023 05:51:13 - INFO - llmtuner.tuner.core.trainer - Saving model checkpoint to ../outputs/Ihin/Ihin-sft-llama2/checkpoint-2400
 12%|█▏        | 2401/20600 [14:02:28<108:11:58, 21.40s/it] 12%|█▏        | 2402/20600 [14:02:43<98:28:18, 19.48s/it]  12%|█▏        | 2403/20600 [14:03:05<102:22:00, 20.25s/it] 12%|█▏        | 2404/20600 [14:03:21<96:00:15, 18.99s/it]  12%|█▏        | 2405/20600 [14:03:38<92:42:41, 18.34s/it] 12%|█▏        | 2406/20600 [14:04:12<117:01:53, 23.16s/it] 12%|█▏        | 2407/20600 [14:04:32<111:38:43, 22.09s/it] 12%|█▏        | 2408/20600 [14:04:52<109:21:47, 21.64s/it] 12%|█▏        | 2409/20600 [14:05:09<102:13:55, 20.23s/it] 12%|█▏        | 2410/20600 [14:05:32<105:37:42, 20.91s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8549019554101243e-05, 'epoch': 23.23}
 12%|█▏        | 2410/20600 [14:05:32<105:37:42, 20.91s/it][INFO|trainer.py:3081] 2023-08-17 05:54:34,922 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:54:34,922 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:54:34,922 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.6562, 'eval_samples_per_second': 0.809, 'eval_steps_per_second': 0.116, 'epoch': 23.23}
 12%|█▏        | 2410/20600 [14:05:41<105:37:42, 20.91s/it]
100%|██████████| 1/1 [00:07<00:00,  7.77s/it][A
                                             [A 12%|█▏        | 2411/20600 [14:05:57<112:39:54, 22.30s/it] 12%|█▏        | 2412/20600 [14:06:17<108:11:51, 21.42s/it] 12%|█▏        | 2413/20600 [14:06:38<107:05:47, 21.20s/it] 12%|█▏        | 2414/20600 [14:07:09<123:21:59, 24.42s/it] 12%|█▏        | 2415/20600 [14:07:31<118:29:35, 23.46s/it] 12%|█▏        | 2416/20600 [14:07:53<116:35:18, 23.08s/it] 12%|█▏        | 2417/20600 [14:08:11<109:43:54, 21.73s/it] 12%|█▏        | 2418/20600 [14:08:29<102:47:01, 20.35s/it] 12%|█▏        | 2419/20600 [14:09:01<120:39:02, 23.89s/it] 12%|█▏        | 2420/20600 [14:09:28<125:26:30, 24.84s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8536192360202085e-05, 'epoch': 23.33}
 12%|█▏        | 2420/20600 [14:09:28<125:26:30, 24.84s/it][INFO|trainer.py:3081] 2023-08-17 05:58:30,914 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 05:58:30,914 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 05:58:30,914 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3512, 'eval_samples_per_second': 0.838, 'eval_steps_per_second': 0.12, 'epoch': 23.33}
 12%|█▏        | 2420/20600 [14:09:36<125:26:30, 24.84s/it]
100%|██████████| 1/1 [00:07<00:00,  7.51s/it][A
                                             [A 12%|█▏        | 2421/20600 [14:09:50<121:45:49, 24.11s/it] 12%|█▏        | 2422/20600 [14:10:10<115:22:42, 22.85s/it] 12%|█▏        | 2423/20600 [14:10:35<117:52:06, 23.34s/it] 12%|█▏        | 2424/20600 [14:10:51<106:58:33, 21.19s/it] 12%|█▏        | 2425/20600 [14:11:09<102:03:50, 20.22s/it] 12%|█▏        | 2426/20600 [14:11:32<106:36:36, 21.12s/it] 12%|█▏        | 2427/20600 [14:11:50<101:53:23, 20.18s/it] 12%|█▏        | 2428/20600 [14:12:07<97:15:25, 19.27s/it]  12%|█▏        | 2429/20600 [14:12:28<100:06:25, 19.83s/it] 12%|█▏        | 2430/20600 [14:12:54<109:02:12, 21.60s/it]                                                           {'loss': 0.0, 'learning_rate': 4.852331042672739e-05, 'epoch': 23.42}
 12%|█▏        | 2430/20600 [14:12:54<109:02:12, 21.60s/it][INFO|trainer.py:3081] 2023-08-17 06:01:56,941 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:01:56,941 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:01:56,941 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.9536, 'eval_samples_per_second': 0.782, 'eval_steps_per_second': 0.112, 'epoch': 23.42}
 12%|█▏        | 2430/20600 [14:13:03<109:02:12, 21.60s/it]
100%|██████████| 1/1 [00:08<00:00,  8.07s/it][A
                                             [A 12%|█▏        | 2431/20600 [14:13:17<111:33:03, 22.10s/it] 12%|█▏        | 2432/20600 [14:13:38<109:59:37, 21.80s/it] 12%|█▏        | 2433/20600 [14:13:59<108:28:35, 21.50s/it] 12%|█▏        | 2434/20600 [14:14:23<112:38:34, 22.32s/it] 12%|█▏        | 2435/20600 [14:14:50<119:40:44, 23.72s/it] 12%|█▏        | 2436/20600 [14:15:08<110:21:44, 21.87s/it] 12%|█▏        | 2437/20600 [14:15:32<113:47:24, 22.55s/it] 12%|█▏        | 2438/20600 [14:15:49<104:44:52, 20.76s/it] 12%|█▏        | 2439/20600 [14:16:06<100:14:53, 19.87s/it] 12%|█▏        | 2440/20600 [14:16:26<100:06:45, 19.85s/it]                                                           {'loss': 0.0, 'learning_rate': 4.851037378363749e-05, 'epoch': 23.52}
 12%|█▏        | 2440/20600 [14:16:26<100:06:45, 19.85s/it][INFO|trainer.py:3081] 2023-08-17 06:05:29,188 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:05:29,189 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:05:29,189 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.1403, 'eval_samples_per_second': 1.14, 'eval_steps_per_second': 0.163, 'epoch': 23.52}
 12%|█▏        | 2440/20600 [14:16:32<100:06:45, 19.85s/it]
100%|██████████| 1/1 [00:05<00:00,  5.21s/it][A
                                             [A 12%|█▏        | 2441/20600 [14:16:48<103:36:47, 20.54s/it] 12%|█▏        | 2442/20600 [14:17:03<95:25:06, 18.92s/it]  12%|█▏        | 2443/20600 [14:17:25<99:25:40, 19.71s/it] 12%|█▏        | 2444/20600 [14:17:40<92:40:51, 18.38s/it] 12%|█▏        | 2445/20600 [14:17:58<92:18:24, 18.30s/it] 12%|█▏        | 2446/20600 [14:18:17<92:17:19, 18.30s/it] 12%|█▏        | 2447/20600 [14:18:37<94:55:29, 18.82s/it] 12%|█▏        | 2448/20600 [14:18:54<92:43:08, 18.39s/it] 12%|█▏        | 2449/20600 [14:19:12<92:03:49, 18.26s/it] 12%|█▏        | 2450/20600 [14:19:33<95:37:58, 18.97s/it]                                                          {'loss': 0.0, 'learning_rate': 4.8497382461019926e-05, 'epoch': 23.61}
 12%|█▏        | 2450/20600 [14:19:33<95:37:58, 18.97s/it][INFO|trainer.py:3081] 2023-08-17 06:08:35,736 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:08:35,736 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:08:35,736 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.5813, 'eval_samples_per_second': 0.923, 'eval_steps_per_second': 0.132, 'epoch': 23.61}
 12%|█▏        | 2450/20600 [14:19:40<95:37:58, 18.97s/it]
100%|██████████| 1/1 [00:06<00:00,  6.69s/it][A
                                             [A 12%|█▏        | 2451/20600 [14:19:57<104:22:31, 20.70s/it] 12%|█▏        | 2452/20600 [14:20:23<112:13:47, 22.26s/it] 12%|█▏        | 2453/20600 [14:20:40<103:45:34, 20.58s/it] 12%|█▏        | 2454/20600 [14:21:00<102:06:53, 20.26s/it] 12%|█▏        | 2455/20600 [14:21:20<102:21:26, 20.31s/it] 12%|█▏        | 2456/20600 [14:21:44<108:25:16, 21.51s/it] 12%|█▏        | 2457/20600 [14:21:59<97:32:53, 19.36s/it]  12%|█▏        | 2458/20600 [14:22:14<90:48:49, 18.02s/it] 12%|█▏        | 2459/20600 [14:22:39<101:40:51, 20.18s/it] 12%|█▏        | 2460/20600 [14:22:56<97:44:07, 19.40s/it]                                                           {'loss': 0.0, 'learning_rate': 4.848433648908942e-05, 'epoch': 23.71}
 12%|█▏        | 2460/20600 [14:22:56<97:44:07, 19.40s/it][INFO|trainer.py:3081] 2023-08-17 06:11:59,334 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:11:59,334 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:11:59,334 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2784, 'eval_samples_per_second': 0.962, 'eval_steps_per_second': 0.137, 'epoch': 23.71}
 12%|█▏        | 2460/20600 [14:23:04<97:44:07, 19.40s/it]
100%|██████████| 1/1 [00:06<00:00,  6.36s/it][A
                                             [A 12%|█▏        | 2461/20600 [14:23:18<100:30:58, 19.95s/it] 12%|█▏        | 2462/20600 [14:23:40<104:27:33, 20.73s/it] 12%|█▏        | 2463/20600 [14:23:57<98:49:38, 19.62s/it]  12%|█▏        | 2464/20600 [14:24:22<106:36:29, 21.16s/it] 12%|█▏        | 2465/20600 [14:24:40<101:15:00, 20.10s/it] 12%|█▏        | 2466/20600 [14:25:05<109:19:51, 21.70s/it] 12%|█▏        | 2467/20600 [14:25:25<106:20:21, 21.11s/it] 12%|█▏        | 2468/20600 [14:25:43<102:04:40, 20.27s/it] 12%|█▏        | 2469/20600 [14:26:08<109:37:22, 21.77s/it] 12%|█▏        | 2470/20600 [14:26:29<108:04:29, 21.46s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8471235898187795e-05, 'epoch': 23.81}
 12%|█▏        | 2470/20600 [14:26:29<108:04:29, 21.46s/it][INFO|trainer.py:3081] 2023-08-17 06:15:31,998 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:15:31,998 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:15:31,998 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.8328, 'eval_samples_per_second': 0.793, 'eval_steps_per_second': 0.113, 'epoch': 23.81}
 12%|█▏        | 2470/20600 [14:26:38<108:04:29, 21.46s/it]
100%|██████████| 1/1 [00:07<00:00,  7.94s/it][A
                                             [A 12%|█▏        | 2471/20600 [14:26:57<117:26:34, 23.32s/it] 12%|█▏        | 2472/20600 [14:27:13<107:36:58, 21.37s/it] 12%|█▏        | 2473/20600 [14:27:35<107:44:15, 21.40s/it] 12%|█▏        | 2474/20600 [14:28:05<120:09:40, 23.87s/it] 12%|█▏        | 2475/20600 [14:28:26<116:23:13, 23.12s/it] 12%|█▏        | 2476/20600 [14:28:44<108:20:33, 21.52s/it] 12%|█▏        | 2477/20600 [14:29:01<102:16:26, 20.32s/it] 12%|█▏        | 2478/20600 [14:29:19<98:32:29, 19.58s/it]  12%|█▏        | 2479/20600 [14:29:39<99:06:57, 19.69s/it] 12%|█▏        | 2480/20600 [14:30:04<107:15:16, 21.31s/it]                                                           {'loss': 0.0, 'learning_rate': 4.845808071878391e-05, 'epoch': 23.9}
 12%|█▏        | 2480/20600 [14:30:04<107:15:16, 21.31s/it][INFO|trainer.py:3081] 2023-08-17 06:19:07,105 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:19:07,105 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:19:07,105 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7608, 'eval_samples_per_second': 1.861, 'eval_steps_per_second': 0.266, 'epoch': 23.9}
 12%|█▏        | 2480/20600 [14:30:08<107:15:16, 21.31s/it]
100%|██████████| 1/1 [00:02<00:00,  2.87s/it][A
                                             [A 12%|█▏        | 2481/20600 [14:30:24<105:46:04, 21.01s/it] 12%|█▏        | 2482/20600 [14:30:54<119:01:21, 23.65s/it] 12%|█▏        | 2483/20600 [14:31:12<110:00:44, 21.86s/it] 12%|█▏        | 2484/20600 [14:31:29<103:19:23, 20.53s/it] 12%|█▏        | 2485/20600 [14:31:55<111:31:30, 22.16s/it] 12%|█▏        | 2486/20600 [14:32:21<117:28:05, 23.35s/it] 12%|█▏        | 2487/20600 [14:32:43<114:13:13, 22.70s/it] 12%|█▏        | 2488/20600 [14:33:02<109:45:13, 21.82s/it] 12%|█▏        | 2489/20600 [14:33:22<105:44:01, 21.02s/it] 12%|█▏        | 2490/20600 [14:33:40<102:08:35, 20.30s/it]                                                           {'loss': 0.0, 'learning_rate': 4.844487098147355e-05, 'epoch': 24.0}
 12%|█▏        | 2490/20600 [14:33:40<102:08:35, 20.30s/it][INFO|trainer.py:3081] 2023-08-17 06:22:43,190 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:22:43,190 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:22:43,190 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0698, 'eval_samples_per_second': 0.99, 'eval_steps_per_second': 0.141, 'epoch': 24.0}
 12%|█▏        | 2490/20600 [14:33:47<102:08:35, 20.30s/it]
100%|██████████| 1/1 [00:06<00:00,  6.03s/it][A
                                             [A 12%|█▏        | 2491/20600 [14:34:05<108:55:59, 21.66s/it] 12%|█▏        | 2492/20600 [14:34:23<102:57:25, 20.47s/it] 12%|█▏        | 2493/20600 [14:34:43<103:08:16, 20.51s/it] 12%|█▏        | 2494/20600 [14:35:02<99:46:21, 19.84s/it]  12%|█▏        | 2495/20600 [14:35:19<96:52:25, 19.26s/it] 12%|█▏        | 2496/20600 [14:35:41<100:05:27, 19.90s/it] 12%|█▏        | 2497/20600 [14:36:03<103:01:12, 20.49s/it] 12%|█▏        | 2498/20600 [14:36:25<104:57:46, 20.87s/it] 12%|█▏        | 2499/20600 [14:36:43<101:03:13, 20.10s/it] 12%|█▏        | 2500/20600 [14:37:03<100:33:51, 20.00s/it]                                                           {'loss': 0.0, 'learning_rate': 4.843160671697945e-05, 'epoch': 24.1}
 12%|█▏        | 2500/20600 [14:37:03<100:33:51, 20.00s/it][INFO|trainer.py:3081] 2023-08-17 06:26:05,572 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:26:05,572 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:26:05,572 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4447, 'eval_samples_per_second': 2.032, 'eval_steps_per_second': 0.29, 'epoch': 24.1}
 12%|█▏        | 2500/20600 [14:37:06<100:33:51, 20.00s/it]
100%|██████████| 1/1 [00:02<00:00,  2.56s/it][A
                                             [A 12%|█▏        | 2501/20600 [14:37:23<101:24:49, 20.17s/it] 12%|█▏        | 2502/20600 [14:37:52<114:33:43, 22.79s/it] 12%|█▏        | 2503/20600 [14:38:07<102:38:23, 20.42s/it] 12%|█▏        | 2504/20600 [14:38:36<115:29:54, 22.98s/it] 12%|█▏        | 2505/20600 [14:38:53<106:33:54, 21.20s/it] 12%|█▏        | 2506/20600 [14:39:10<101:02:27, 20.10s/it] 12%|█▏        | 2507/20600 [14:39:30<99:44:39, 19.85s/it]  12%|█▏        | 2508/20600 [14:40:02<119:01:10, 23.68s/it] 12%|█▏        | 2509/20600 [14:40:25<118:05:34, 23.50s/it] 12%|█▏        | 2510/20600 [14:40:42<107:28:05, 21.39s/it]                                                           {'loss': 0.0, 'learning_rate': 4.841828795615111e-05, 'epoch': 24.19}
 12%|█▏        | 2510/20600 [14:40:42<107:28:05, 21.39s/it][INFO|trainer.py:3081] 2023-08-17 06:29:44,867 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:29:44,868 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:29:44,868 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0452, 'eval_samples_per_second': 1.73, 'eval_steps_per_second': 0.247, 'epoch': 24.19}
 12%|█▏        | 2510/20600 [14:40:46<107:28:05, 21.39s/it]
100%|██████████| 1/1 [00:03<00:00,  3.15s/it][A
                                             [A 12%|█▏        | 2511/20600 [14:41:07<112:20:06, 22.36s/it] 12%|█▏        | 2512/20600 [14:41:33<119:10:56, 23.72s/it] 12%|█▏        | 2513/20600 [14:41:50<109:05:18, 21.71s/it] 12%|█▏        | 2514/20600 [14:42:17<115:46:25, 23.04s/it] 12%|█▏        | 2515/20600 [14:42:33<105:45:40, 21.05s/it] 12%|█▏        | 2516/20600 [14:42:56<109:15:27, 21.75s/it] 12%|█▏        | 2517/20600 [14:43:16<106:23:15, 21.18s/it] 12%|█▏        | 2518/20600 [14:43:33<99:54:26, 19.89s/it]  12%|█▏        | 2519/20600 [14:43:54<101:24:33, 20.19s/it] 12%|█▏        | 2520/20600 [14:44:18<106:35:59, 21.23s/it]                                                           {'loss': 0.0, 'learning_rate': 4.840491472996481e-05, 'epoch': 24.29}
 12%|█▏        | 2520/20600 [14:44:18<106:35:59, 21.23s/it][INFO|trainer.py:3081] 2023-08-17 06:33:20,631 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:33:20,631 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:33:20,631 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.9944, 'eval_samples_per_second': 0.778, 'eval_steps_per_second': 0.111, 'epoch': 24.29}
 12%|█▏        | 2520/20600 [14:44:27<106:35:59, 21.23s/it]
100%|██████████| 1/1 [00:08<00:00,  8.09s/it][A
                                             [A 12%|█▏        | 2521/20600 [14:44:48<119:40:07, 23.83s/it] 12%|█▏        | 2522/20600 [14:45:05<109:28:39, 21.80s/it] 12%|█▏        | 2523/20600 [14:45:22<102:58:39, 20.51s/it] 12%|█▏        | 2524/20600 [14:45:45<106:49:12, 21.27s/it] 12%|█▏        | 2525/20600 [14:46:10<111:51:13, 22.28s/it] 12%|█▏        | 2526/20600 [14:46:36<117:17:28, 23.36s/it] 12%|█▏        | 2527/20600 [14:46:53<107:56:39, 21.50s/it] 12%|█▏        | 2528/20600 [14:47:14<107:11:23, 21.35s/it] 12%|█▏        | 2529/20600 [14:47:41<116:12:30, 23.15s/it] 12%|█▏        | 2530/20600 [14:47:59<107:28:58, 21.41s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8391487069523465e-05, 'epoch': 24.39}
 12%|█▏        | 2530/20600 [14:47:59<107:28:58, 21.41s/it][INFO|trainer.py:3081] 2023-08-17 06:37:01,535 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:37:01,535 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:37:01,535 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8491, 'eval_samples_per_second': 1.819, 'eval_steps_per_second': 0.26, 'epoch': 24.39}
 12%|█▏        | 2530/20600 [14:48:02<107:28:58, 21.41s/it]
100%|██████████| 1/1 [00:02<00:00,  2.93s/it][A
                                             [A 12%|█▏        | 2531/20600 [14:48:21<108:24:24, 21.60s/it] 12%|█▏        | 2532/20600 [14:48:36<99:29:57, 19.82s/it]  12%|█▏        | 2533/20600 [14:48:55<98:09:32, 19.56s/it] 12%|█▏        | 2534/20600 [14:49:17<100:59:59, 20.13s/it] 12%|█▏        | 2535/20600 [14:49:35<97:56:25, 19.52s/it]  12%|█▏        | 2536/20600 [14:50:04<113:06:12, 22.54s/it] 12%|█▏        | 2537/20600 [14:50:24<108:21:58, 21.60s/it] 12%|█▏        | 2538/20600 [14:50:42<103:21:09, 20.60s/it] 12%|█▏        | 2539/20600 [14:51:04<105:10:49, 20.97s/it] 12%|█▏        | 2540/20600 [14:51:22<101:03:00, 20.14s/it]                                                           {'loss': 0.0, 'learning_rate': 4.837800500605663e-05, 'epoch': 24.48}
 12%|█▏        | 2540/20600 [14:51:22<101:03:00, 20.14s/it][INFO|trainer.py:3081] 2023-08-17 06:40:25,043 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:40:25,043 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:40:25,043 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4665, 'eval_samples_per_second': 0.938, 'eval_steps_per_second': 0.134, 'epoch': 24.48}
 12%|█▏        | 2540/20600 [14:51:30<101:03:00, 20.14s/it]
100%|██████████| 1/1 [00:06<00:00,  6.57s/it][A
                                             [A 12%|█▏        | 2541/20600 [14:51:49<110:54:15, 22.11s/it] 12%|█▏        | 2542/20600 [14:52:06<102:52:24, 20.51s/it] 12%|█▏        | 2543/20600 [14:52:27<103:45:08, 20.68s/it] 12%|█▏        | 2544/20600 [14:52:48<105:30:45, 21.04s/it] 12%|█▏        | 2545/20600 [14:53:03<95:45:51, 19.09s/it]  12%|█▏        | 2546/20600 [14:53:24<98:42:41, 19.68s/it] 12%|█▏        | 2547/20600 [14:53:41<95:01:31, 18.95s/it] 12%|█▏        | 2548/20600 [14:54:03<99:51:52, 19.92s/it] 12%|█▏        | 2549/20600 [14:54:25<101:39:45, 20.28s/it] 12%|█▏        | 2550/20600 [14:54:44<100:03:27, 19.96s/it]                                                           {'loss': 0.0, 'learning_rate': 4.836446857092037e-05, 'epoch': 24.58}
 12%|█▏        | 2550/20600 [14:54:44<100:03:27, 19.96s/it][INFO|trainer.py:3081] 2023-08-17 06:43:46,844 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:43:46,845 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:43:46,845 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0635, 'eval_samples_per_second': 1.723, 'eval_steps_per_second': 0.246, 'epoch': 24.58}
 12%|█▏        | 2550/20600 [14:54:48<100:03:27, 19.96s/it]
100%|██████████| 1/1 [00:03<00:00,  3.18s/it][A
                                             [A 12%|█▏        | 2551/20600 [14:55:05<101:37:17, 20.27s/it] 12%|█▏        | 2552/20600 [14:55:22<96:29:26, 19.25s/it]  12%|█▏        | 2553/20600 [14:55:45<102:59:01, 20.54s/it] 12%|█▏        | 2554/20600 [14:56:02<97:55:51, 19.54s/it]  12%|█▏        | 2555/20600 [14:56:21<96:47:03, 19.31s/it] 12%|█▏        | 2556/20600 [14:56:44<102:04:16, 20.36s/it] 12%|█▏        | 2557/20600 [14:57:00<96:09:43, 19.19s/it]  12%|█▏        | 2558/20600 [14:57:27<107:31:23, 21.45s/it] 12%|█▏        | 2559/20600 [14:57:46<102:52:04, 20.53s/it] 12%|█▏        | 2560/20600 [14:58:01<95:22:10, 19.03s/it]                                                           {'loss': 0.0, 'learning_rate': 4.835087779559721e-05, 'epoch': 24.67}
 12%|█▏        | 2560/20600 [14:58:01<95:22:10, 19.03s/it][INFO|trainer.py:3081] 2023-08-17 06:47:04,110 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:47:04,110 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:47:04,110 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3811, 'eval_samples_per_second': 0.948, 'eval_steps_per_second': 0.135, 'epoch': 24.67}
 12%|█▏        | 2560/20600 [14:58:09<95:22:10, 19.03s/it]
100%|██████████| 1/1 [00:06<00:00,  6.49s/it][A
                                             [A 12%|█▏        | 2561/20600 [14:58:35<117:20:39, 23.42s/it] 12%|█▏        | 2562/20600 [14:58:57<115:37:12, 23.08s/it] 12%|█▏        | 2563/20600 [14:59:13<105:12:44, 21.00s/it] 12%|█▏        | 2564/20600 [14:59:29<97:46:29, 19.52s/it]  12%|█▏        | 2565/20600 [14:59:54<105:44:56, 21.11s/it] 12%|█▏        | 2566/20600 [15:00:22<116:03:07, 23.17s/it] 12%|█▏        | 2567/20600 [15:00:47<118:50:06, 23.72s/it] 12%|█▏        | 2568/20600 [15:01:11<119:45:06, 23.91s/it] 12%|█▏        | 2569/20600 [15:01:29<110:11:55, 22.00s/it] 12%|█▏        | 2570/20600 [15:01:55<116:15:46, 23.21s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8337232711696045e-05, 'epoch': 24.77}
 12%|█▏        | 2570/20600 [15:01:55<116:15:46, 23.21s/it][INFO|trainer.py:3081] 2023-08-17 06:50:58,022 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:50:58,022 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:50:58,022 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.4778, 'eval_samples_per_second': 1.563, 'eval_steps_per_second': 0.223, 'epoch': 24.77}
 12%|█▏        | 2570/20600 [15:02:00<116:15:46, 23.21s/it]
100%|██████████| 1/1 [00:03<00:00,  3.67s/it][A
                                             [A 12%|█▏        | 2571/20600 [15:02:13<109:03:40, 21.78s/it] 12%|█▏        | 2572/20600 [15:02:38<113:50:37, 22.73s/it] 12%|█▏        | 2573/20600 [15:02:58<108:43:04, 21.71s/it] 12%|█▏        | 2574/20600 [15:03:21<110:46:54, 22.12s/it] 12%|█▎        | 2575/20600 [15:03:48<118:26:05, 23.65s/it] 13%|█▎        | 2576/20600 [15:04:11<117:14:25, 23.42s/it] 13%|█▎        | 2577/20600 [15:04:28<108:06:06, 21.59s/it] 13%|█▎        | 2578/20600 [15:04:47<104:06:19, 20.80s/it] 13%|█▎        | 2579/20600 [15:05:15<114:12:56, 22.82s/it] 13%|█▎        | 2580/20600 [15:05:34<108:25:45, 21.66s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8323533350952106e-05, 'epoch': 24.87}
 13%|█▎        | 2580/20600 [15:05:34<108:25:45, 21.66s/it][INFO|trainer.py:3081] 2023-08-17 06:54:36,684 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:54:36,684 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:54:36,684 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6306, 'eval_samples_per_second': 1.928, 'eval_steps_per_second': 0.275, 'epoch': 24.87}
 13%|█▎        | 2580/20600 [15:05:37<108:25:45, 21.66s/it]
100%|██████████| 1/1 [00:02<00:00,  2.74s/it][A
                                             [A 13%|█▎        | 2581/20600 [15:06:01<116:16:11, 23.23s/it] 13%|█▎        | 2582/20600 [15:06:17<105:56:37, 21.17s/it] 13%|█▎        | 2583/20600 [15:06:38<105:12:25, 21.02s/it] 13%|█▎        | 2584/20600 [15:07:00<107:59:44, 21.58s/it] 13%|█▎        | 2585/20600 [15:07:18<101:34:25, 20.30s/it] 13%|█▎        | 2586/20600 [15:07:34<94:59:15, 18.98s/it]  13%|█▎        | 2587/20600 [15:07:51<92:11:52, 18.43s/it] 13%|█▎        | 2588/20600 [15:08:18<104:48:14, 20.95s/it] 13%|█▎        | 2589/20600 [15:08:38<103:27:58, 20.68s/it] 13%|█▎        | 2590/20600 [15:09:00<105:06:23, 21.01s/it]                                                           {'loss': 0.0, 'learning_rate': 4.830977974522682e-05, 'epoch': 24.96}
 13%|█▎        | 2590/20600 [15:09:00<105:06:23, 21.01s/it][INFO|trainer.py:3081] 2023-08-17 06:58:02,526 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 06:58:02,526 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 06:58:02,526 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.4957, 'eval_samples_per_second': 1.078, 'eval_steps_per_second': 0.154, 'epoch': 24.96}
 13%|█▎        | 2590/20600 [15:09:06<105:06:23, 21.01s/it]
100%|██████████| 1/1 [00:05<00:00,  5.66s/it][A
                                             [A 13%|█▎        | 2591/20600 [15:09:21<105:52:57, 21.17s/it] 13%|█▎        | 2592/20600 [15:09:38<99:48:13, 19.95s/it]  13%|█▎        | 2593/20600 [15:09:56<96:30:42, 19.29s/it] 13%|█▎        | 2594/20600 [15:10:17<98:41:14, 19.73s/it] 13%|█▎        | 2595/20600 [15:10:34<95:27:45, 19.09s/it] 13%|█▎        | 2596/20600 [15:10:59<104:16:45, 20.85s/it] 13%|█▎        | 2597/20600 [15:11:17<98:57:00, 19.79s/it]  13%|█▎        | 2598/20600 [15:11:38<102:05:34, 20.42s/it] 13%|█▎        | 2599/20600 [15:11:58<100:16:10, 20.05s/it] 13%|█▎        | 2600/20600 [15:12:15<95:49:58, 19.17s/it]                                                           {'loss': 0.0, 'learning_rate': 4.829597192650781e-05, 'epoch': 25.06}
 13%|█▎        | 2600/20600 [15:12:15<95:49:58, 19.17s/it][INFO|trainer.py:3081] 2023-08-17 07:01:17,712 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:01:17,712 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:01:17,712 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.1781, 'eval_samples_per_second': 0.975, 'eval_steps_per_second': 0.139, 'epoch': 25.06}
 13%|█▎        | 2600/20600 [15:12:22<95:49:58, 19.17s/it]
100%|██████████| 1/1 [00:06<00:00,  6.31s/it][A
                                             [A 13%|█▎        | 2601/20600 [15:12:38<102:22:13, 20.48s/it] 13%|█▎        | 2602/20600 [15:12:56<97:33:35, 19.51s/it]  13%|█▎        | 2603/20600 [15:13:12<93:02:09, 18.61s/it] 13%|█▎        | 2604/20600 [15:13:28<89:09:45, 17.84s/it] 13%|█▎        | 2605/20600 [15:13:53<100:12:40, 20.05s/it] 13%|█▎        | 2606/20600 [15:14:17<105:55:25, 21.19s/it] 13%|█▎        | 2607/20600 [15:14:40<107:43:24, 21.55s/it] 13%|█▎        | 2608/20600 [15:14:56<100:36:35, 20.13s/it] 13%|█▎        | 2609/20600 [15:15:13<95:56:54, 19.20s/it]  13%|█▎        | 2610/20600 [15:15:32<95:48:20, 19.17s/it]                                                          {'loss': 0.0, 'learning_rate': 4.828210992690878e-05, 'epoch': 25.16}
 13%|█▎        | 2610/20600 [15:15:32<95:48:20, 19.17s/it][INFO|trainer.py:3081] 2023-08-17 07:04:35,457 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:04:35,457 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:04:35,457 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1956, 'eval_samples_per_second': 1.668, 'eval_steps_per_second': 0.238, 'epoch': 25.16}
 13%|█▎        | 2610/20600 [15:15:37<95:48:20, 19.17s/it]
100%|██████████| 1/1 [00:03<00:00,  3.28s/it][A
                                             [A 13%|█▎        | 2611/20600 [15:15:55<100:45:23, 20.16s/it] 13%|█▎        | 2612/20600 [15:16:18<105:20:01, 21.08s/it] 13%|█▎        | 2613/20600 [15:16:36<100:54:37, 20.20s/it] 13%|█▎        | 2614/20600 [15:16:53<95:52:24, 19.19s/it]  13%|█▎        | 2615/20600 [15:17:09<91:06:39, 18.24s/it] 13%|█▎        | 2616/20600 [15:17:30<95:17:07, 19.07s/it] 13%|█▎        | 2617/20600 [15:17:49<94:29:11, 18.92s/it] 13%|█▎        | 2618/20600 [15:18:08<95:34:06, 19.13s/it] 13%|█▎        | 2619/20600 [15:18:33<104:15:51, 20.87s/it] 13%|█▎        | 2620/20600 [15:18:51<99:36:49, 19.94s/it]                                                           {'loss': 0.0, 'learning_rate': 4.826819377866943e-05, 'epoch': 25.25}
 13%|█▎        | 2620/20600 [15:18:51<99:36:49, 19.94s/it][INFO|trainer.py:3081] 2023-08-17 07:07:54,064 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:07:54,064 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:07:54,064 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5321, 'eval_samples_per_second': 1.982, 'eval_steps_per_second': 0.283, 'epoch': 25.25}
 13%|█▎        | 2620/20600 [15:18:55<99:36:49, 19.94s/it]
100%|██████████| 1/1 [00:02<00:00,  2.65s/it][A
                                             [A 13%|█▎        | 2621/20600 [15:19:23<117:24:59, 23.51s/it] 13%|█▎        | 2622/20600 [15:19:40<108:28:45, 21.72s/it] 13%|█▎        | 2623/20600 [15:20:00<104:44:38, 20.98s/it] 13%|█▎        | 2624/20600 [15:20:25<110:32:26, 22.14s/it] 13%|█▎        | 2625/20600 [15:20:48<111:48:59, 22.39s/it] 13%|█▎        | 2626/20600 [15:21:09<110:39:38, 22.16s/it] 13%|█▎        | 2627/20600 [15:21:35<115:41:15, 23.17s/it] 13%|█▎        | 2628/20600 [15:21:50<103:59:57, 20.83s/it] 13%|█▎        | 2629/20600 [15:22:06<96:45:23, 19.38s/it]  13%|█▎        | 2630/20600 [15:22:35<111:23:50, 22.32s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8254223514155395e-05, 'epoch': 25.35}
 13%|█▎        | 2630/20600 [15:22:35<111:23:50, 22.32s/it][INFO|trainer.py:3081] 2023-08-17 07:11:38,220 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:11:38,234 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:11:38,234 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.5815, 'eval_samples_per_second': 1.528, 'eval_steps_per_second': 0.218, 'epoch': 25.35}
 13%|█▎        | 2630/20600 [15:22:40<111:23:50, 22.32s/it]
100%|██████████| 1/1 [00:03<00:00,  3.74s/it][A
                                             [A 13%|█▎        | 2631/20600 [15:22:57<110:53:43, 22.22s/it] 13%|█▎        | 2632/20600 [15:23:27<122:10:51, 24.48s/it] 13%|█▎        | 2633/20600 [15:23:51<122:15:21, 24.50s/it] 13%|█▎        | 2634/20600 [15:24:18<124:35:47, 24.97s/it] 13%|█▎        | 2635/20600 [15:24:36<114:29:24, 22.94s/it] 13%|█▎        | 2636/20600 [15:24:53<106:29:41, 21.34s/it] 13%|█▎        | 2637/20600 [15:25:11<101:13:00, 20.29s/it] 13%|█▎        | 2638/20600 [15:25:29<97:48:58, 19.60s/it]  13%|█▎        | 2639/20600 [15:25:51<101:27:40, 20.34s/it] 13%|█▎        | 2640/20600 [15:26:12<102:01:36, 20.45s/it]                                                           {'loss': 0.0, 'learning_rate': 4.824019916585819e-05, 'epoch': 25.45}
 13%|█▎        | 2640/20600 [15:26:12<102:01:36, 20.45s/it][INFO|trainer.py:3081] 2023-08-17 07:15:14,969 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:15:14,970 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:15:14,970 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3615, 'eval_samples_per_second': 1.1, 'eval_steps_per_second': 0.157, 'epoch': 25.45}
 13%|█▎        | 2640/20600 [15:26:18<102:01:36, 20.45s/it]
100%|██████████| 1/1 [00:05<00:00,  5.44s/it][A
                                             [A 13%|█▎        | 2641/20600 [15:26:36<107:47:13, 21.61s/it] 13%|█▎        | 2642/20600 [15:26:58<108:18:14, 21.71s/it] 13%|█▎        | 2643/20600 [15:27:15<100:16:14, 20.10s/it] 13%|█▎        | 2644/20600 [15:27:39<106:52:20, 21.43s/it] 13%|█▎        | 2645/20600 [15:27:55<98:25:48, 19.74s/it]  13%|█▎        | 2646/20600 [15:28:15<98:55:31, 19.84s/it] 13%|█▎        | 2647/20600 [15:28:34<97:52:58, 19.63s/it] 13%|█▎        | 2648/20600 [15:28:53<96:47:16, 19.41s/it] 13%|█▎        | 2649/20600 [15:29:12<95:26:39, 19.14s/it] 13%|█▎        | 2650/20600 [15:29:36<104:06:22, 20.88s/it]                                                           {'loss': 0.0, 'learning_rate': 4.822612076639511e-05, 'epoch': 25.54}
 13%|█▎        | 2650/20600 [15:29:36<104:06:22, 20.88s/it][INFO|trainer.py:3081] 2023-08-17 07:18:39,443 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:18:39,443 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:18:39,443 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6624, 'eval_samples_per_second': 1.501, 'eval_steps_per_second': 0.214, 'epoch': 25.54}
 13%|█▎        | 2650/20600 [15:29:41<104:06:22, 20.88s/it]
100%|██████████| 1/1 [00:03<00:00,  3.81s/it][A
                                             [A 13%|█▎        | 2651/20600 [15:29:57<103:52:40, 20.83s/it] 13%|█▎        | 2652/20600 [15:30:20<106:54:00, 21.44s/it] 13%|█▎        | 2653/20600 [15:30:35<96:44:00, 19.40s/it]  13%|█▎        | 2654/20600 [15:30:50<90:40:44, 18.19s/it] 13%|█▎        | 2655/20600 [15:31:14<98:37:40, 19.79s/it] 13%|█▎        | 2656/20600 [15:31:32<96:01:38, 19.27s/it] 13%|█▎        | 2657/20600 [15:31:53<99:48:03, 20.02s/it] 13%|█▎        | 2658/20600 [15:32:14<100:45:57, 20.22s/it] 13%|█▎        | 2659/20600 [15:32:31<96:03:25, 19.27s/it]  13%|█▎        | 2660/20600 [15:32:51<96:50:15, 19.43s/it]                                                          {'loss': 0.0, 'learning_rate': 4.8211988348509164e-05, 'epoch': 25.64}
 13%|█▎        | 2660/20600 [15:32:58<96:50:15, 19.43s/it][INFO|trainer.py:3081] 2023-08-17 07:22:01,013 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:22:01,013 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:22:01,013 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 1.5234, 'eval_samples_per_second': 4.595, 'eval_steps_per_second': 0.656, 'epoch': 25.64}
 13%|█▎        | 2660/20600 [15:33:00<96:50:15, 19.43s/it]
100%|██████████| 1/1 [00:00<00:00,  1.51it/s][A
                                             [A 13%|█▎        | 2661/20600 [15:33:13<100:57:25, 20.26s/it] 13%|█▎        | 2662/20600 [15:33:32<99:03:00, 19.88s/it]  13%|█▎        | 2663/20600 [15:33:51<97:04:10, 19.48s/it] 13%|█▎        | 2664/20600 [15:34:10<97:11:20, 19.51s/it] 13%|█▎        | 2665/20600 [15:34:28<94:34:04, 18.98s/it] 13%|█▎        | 2666/20600 [15:34:47<94:25:22, 18.95s/it] 13%|█▎        | 2667/20600 [15:35:03<90:44:19, 18.22s/it] 13%|█▎        | 2668/20600 [15:35:22<90:49:29, 18.23s/it] 13%|█▎        | 2669/20600 [15:35:39<89:31:20, 17.97s/it] 13%|█▎        | 2670/20600 [15:36:00<93:49:55, 18.84s/it]                                                          {'loss': 0.0, 'learning_rate': 4.819780194506897e-05, 'epoch': 25.73}
 13%|█▎        | 2670/20600 [15:36:00<93:49:55, 18.84s/it][INFO|trainer.py:3081] 2023-08-17 07:25:02,880 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:25:02,880 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:25:02,880 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.6971, 'eval_samples_per_second': 0.805, 'eval_steps_per_second': 0.115, 'epoch': 25.73}
 13%|█▎        | 2670/20600 [15:36:09<93:49:55, 18.84s/it]
100%|██████████| 1/1 [00:07<00:00,  7.85s/it][A
                                             [A 13%|█▎        | 2671/20600 [15:36:31<111:30:57, 22.39s/it] 13%|█▎        | 2672/20600 [15:36:54<112:33:42, 22.60s/it] 13%|█▎        | 2673/20600 [15:37:14<109:11:19, 21.93s/it] 13%|█▎        | 2674/20600 [15:37:32<103:23:25, 20.76s/it] 13%|█▎        | 2675/20600 [15:37:54<105:50:56, 21.26s/it] 13%|█▎        | 2676/20600 [15:38:09<95:52:02, 19.25s/it]  13%|█▎        | 2677/20600 [15:38:25<91:13:50, 18.32s/it] 13%|█▎        | 2678/20600 [15:38:48<97:35:38, 19.60s/it] 13%|█▎        | 2679/20600 [15:39:07<97:34:35, 19.60s/it] 13%|█▎        | 2680/20600 [15:39:23<90:57:19, 18.27s/it]                                                          {'loss': 0.0, 'learning_rate': 4.8183561589068735e-05, 'epoch': 25.83}
 13%|█▎        | 2680/20600 [15:39:23<90:57:19, 18.27s/it][INFO|trainer.py:3081] 2023-08-17 07:28:25,565 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:28:25,565 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:28:25,565 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.8835, 'eval_samples_per_second': 0.888, 'eval_steps_per_second': 0.127, 'epoch': 25.83}
 13%|█▎        | 2680/20600 [15:39:30<90:57:19, 18.27s/it]
100%|██████████| 1/1 [00:06<00:00,  6.99s/it][A
                                             [A 13%|█▎        | 2681/20600 [15:39:48<101:14:28, 20.34s/it] 13%|█▎        | 2682/20600 [15:40:09<102:51:22, 20.67s/it] 13%|█▎        | 2683/20600 [15:40:27<98:16:31, 19.75s/it]  13%|█▎        | 2684/20600 [15:40:47<98:50:05, 19.86s/it] 13%|█▎        | 2685/20600 [15:41:16<112:26:59, 22.60s/it] 13%|█▎        | 2686/20600 [15:41:40<115:15:37, 23.16s/it] 13%|█▎        | 2687/20600 [15:42:06<118:38:33, 23.84s/it] 13%|█▎        | 2688/20600 [15:42:25<111:56:22, 22.50s/it] 13%|█▎        | 2689/20600 [15:42:48<112:54:19, 22.69s/it] 13%|█▎        | 2690/20600 [15:43:07<106:13:03, 21.35s/it]                                                           {'loss': 0.0, 'learning_rate': 4.816926731362814e-05, 'epoch': 25.93}
 13%|█▎        | 2690/20600 [15:43:07<106:13:03, 21.35s/it][INFO|trainer.py:3081] 2023-08-17 07:32:09,503 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:32:09,503 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:32:09,503 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.1756, 'eval_samples_per_second': 0.856, 'eval_steps_per_second': 0.122, 'epoch': 25.93}
 13%|█▎        | 2690/20600 [15:43:15<106:13:03, 21.35s/it]
100%|██████████| 1/1 [00:07<00:00,  7.29s/it][A
                                             [A 13%|█▎        | 2691/20600 [15:43:31<111:11:03, 22.35s/it] 13%|█▎        | 2692/20600 [15:43:51<107:41:14, 21.65s/it] 13%|█▎        | 2693/20600 [15:44:20<118:15:22, 23.77s/it] 13%|█▎        | 2694/20600 [15:44:39<110:43:20, 22.26s/it] 13%|█▎        | 2695/20600 [15:45:09<122:07:02, 24.55s/it] 13%|█▎        | 2696/20600 [15:45:36<125:53:09, 25.31s/it] 13%|█▎        | 2697/20600 [15:45:55<116:40:31, 23.46s/it] 13%|█▎        | 2698/20600 [15:46:14<110:27:52, 22.21s/it] 13%|█▎        | 2699/20600 [15:46:43<120:23:56, 24.21s/it] 13%|█▎        | 2700/20600 [15:47:00<109:47:32, 22.08s/it]                                                           {'loss': 0.0, 'learning_rate': 4.815491915199225e-05, 'epoch': 26.02}
 13%|█▎        | 2700/20600 [15:47:00<109:47:32, 22.08s/it][INFO|trainer.py:3081] 2023-08-17 07:36:03,077 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:36:03,077 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:36:03,077 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3522, 'eval_samples_per_second': 2.088, 'eval_steps_per_second': 0.298, 'epoch': 26.02}
 13%|█▎        | 2700/20600 [15:47:03<109:47:32, 22.08s/it]
100%|██████████| 1/1 [00:02<00:00,  2.51s/it][A
                                             [A 13%|█▎        | 2701/20600 [15:47:27<117:07:49, 23.56s/it] 13%|█▎        | 2702/20600 [15:47:46<110:03:57, 22.14s/it] 13%|█▎        | 2703/20600 [15:48:06<106:22:26, 21.40s/it] 13%|█▎        | 2704/20600 [15:48:24<102:19:24, 20.58s/it] 13%|█▎        | 2705/20600 [15:48:45<103:07:12, 20.75s/it] 13%|█▎        | 2706/20600 [15:49:05<101:18:10, 20.38s/it] 13%|█▎        | 2707/20600 [15:49:23<98:15:31, 19.77s/it]  13%|█▎        | 2708/20600 [15:49:46<103:20:49, 20.79s/it] 13%|█▎        | 2709/20600 [15:50:09<105:44:47, 21.28s/it] 13%|█▎        | 2710/20600 [15:50:29<103:19:35, 20.79s/it]                                                           {'loss': 0.0, 'learning_rate': 4.814051713753148e-05, 'epoch': 26.12}
 13%|█▎        | 2710/20600 [15:50:29<103:19:35, 20.79s/it][INFO|trainer.py:3081] 2023-08-17 07:39:31,501 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:39:31,501 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:39:31,502 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.973, 'eval_samples_per_second': 0.78, 'eval_steps_per_second': 0.111, 'epoch': 26.12}
 13%|█▎        | 2710/20600 [15:50:38<103:19:35, 20.79s/it]
100%|██████████| 1/1 [00:08<00:00,  8.03s/it][A
                                             [A 13%|█▎        | 2711/20600 [15:50:56<112:47:16, 22.70s/it] 13%|█▎        | 2712/20600 [15:51:15<107:24:10, 21.62s/it] 13%|█▎        | 2713/20600 [15:51:40<112:58:24, 22.74s/it] 13%|█▎        | 2714/20600 [15:52:01<110:42:30, 22.28s/it] 13%|█▎        | 2715/20600 [15:52:20<105:09:46, 21.17s/it] 13%|█▎        | 2716/20600 [15:52:40<103:54:08, 20.92s/it] 13%|█▎        | 2717/20600 [15:53:03<106:33:53, 21.45s/it] 13%|█▎        | 2718/20600 [15:53:21<101:58:33, 20.53s/it] 13%|█▎        | 2719/20600 [15:53:44<104:46:33, 21.09s/it] 13%|█▎        | 2720/20600 [15:54:02<101:01:02, 20.34s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8126061303741475e-05, 'epoch': 26.22}
 13%|█▎        | 2720/20600 [15:54:02<101:01:02, 20.34s/it][INFO|trainer.py:3081] 2023-08-17 07:43:05,279 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:43:05,279 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:43:05,279 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3296, 'eval_samples_per_second': 0.955, 'eval_steps_per_second': 0.136, 'epoch': 26.22}
 13%|█▎        | 2720/20600 [15:54:10<101:01:02, 20.34s/it]
100%|██████████| 1/1 [00:06<00:00,  6.49s/it][A
                                             [A 13%|█▎        | 2721/20600 [15:54:27<107:51:54, 21.72s/it] 13%|█▎        | 2722/20600 [15:54:48<106:45:21, 21.50s/it] 13%|█▎        | 2723/20600 [15:55:03<96:08:48, 19.36s/it]  13%|█▎        | 2724/20600 [15:55:24<98:42:06, 19.88s/it] 13%|█▎        | 2725/20600 [15:55:42<95:59:07, 19.33s/it] 13%|█▎        | 2726/20600 [15:56:00<94:17:01, 18.99s/it] 13%|█▎        | 2727/20600 [15:56:19<94:32:19, 19.04s/it] 13%|█▎        | 2728/20600 [15:56:42<99:37:14, 20.07s/it] 13%|█▎        | 2729/20600 [15:57:03<102:21:11, 20.62s/it] 13%|█▎        | 2730/20600 [15:57:25<103:17:46, 20.81s/it]                                                           {'loss': 0.0, 'learning_rate': 4.811155168424307e-05, 'epoch': 26.31}
 13%|█▎        | 2730/20600 [15:57:25<103:17:46, 20.81s/it][INFO|trainer.py:3081] 2023-08-17 07:46:27,690 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:46:27,690 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:46:27,690 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0553, 'eval_samples_per_second': 0.992, 'eval_steps_per_second': 0.142, 'epoch': 26.31}
 13%|█▎        | 2730/20600 [15:57:32<103:17:46, 20.81s/it]
100%|██████████| 1/1 [00:06<00:00,  6.19s/it][A
                                             [A 13%|█▎        | 2731/20600 [15:57:45<102:44:03, 20.70s/it] 13%|█▎        | 2732/20600 [15:58:02<96:46:27, 19.50s/it]  13%|█▎        | 2733/20600 [15:58:24<100:55:09, 20.33s/it] 13%|█▎        | 2734/20600 [15:58:41<95:04:44, 19.16s/it]  13%|█▎        | 2735/20600 [15:58:58<92:17:02, 18.60s/it] 13%|█▎        | 2736/20600 [15:59:23<102:42:23, 20.70s/it] 13%|█▎        | 2737/20600 [15:59:42<99:12:36, 19.99s/it]  13%|█▎        | 2738/20600 [15:59:58<93:36:09, 18.87s/it] 13%|█▎        | 2739/20600 [16:00:16<93:02:01, 18.75s/it] 13%|█▎        | 2740/20600 [16:00:41<101:36:57, 20.48s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8096988312782174e-05, 'epoch': 26.41}
 13%|█▎        | 2740/20600 [16:00:41<101:36:57, 20.48s/it][INFO|trainer.py:3081] 2023-08-17 07:49:44,001 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:49:44,001 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:49:44,001 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9364, 'eval_samples_per_second': 1.778, 'eval_steps_per_second': 0.254, 'epoch': 26.41}
 13%|█▎        | 2740/20600 [16:00:45<101:36:57, 20.48s/it]
100%|██████████| 1/1 [00:03<00:00,  3.12s/it][A
                                             [A 13%|█▎        | 2741/20600 [16:01:02<102:24:16, 20.64s/it] 13%|█▎        | 2742/20600 [16:01:29<111:35:14, 22.49s/it] 13%|█▎        | 2743/20600 [16:01:44<100:14:59, 20.21s/it] 13%|█▎        | 2744/20600 [16:02:02<97:38:43, 19.69s/it]  13%|█▎        | 2745/20600 [16:02:26<104:26:35, 21.06s/it] 13%|█▎        | 2746/20600 [16:02:57<117:52:29, 23.77s/it] 13%|█▎        | 2747/20600 [16:03:17<113:29:11, 22.88s/it] 13%|█▎        | 2748/20600 [16:03:38<109:43:13, 22.13s/it] 13%|█▎        | 2749/20600 [16:03:57<105:11:56, 21.22s/it] 13%|█▎        | 2750/20600 [16:04:25<116:14:28, 23.44s/it]                                                           {'loss': 0.0, 'learning_rate': 4.808237122322972e-05, 'epoch': 26.51}
 13%|█▎        | 2750/20600 [16:04:25<116:14:28, 23.44s/it][INFO|trainer.py:3081] 2023-08-17 07:53:28,446 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:53:28,446 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:53:28,446 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4894, 'eval_samples_per_second': 2.006, 'eval_steps_per_second': 0.287, 'epoch': 26.51}
 13%|█▎        | 2750/20600 [16:04:29<116:14:28, 23.44s/it]
100%|██████████| 1/1 [00:02<00:00,  2.65s/it][A
                                             [A 13%|█▎        | 2751/20600 [16:04:45<111:11:13, 22.43s/it] 13%|█▎        | 2752/20600 [16:05:06<109:00:04, 21.99s/it] 13%|█▎        | 2753/20600 [16:05:27<106:32:27, 21.49s/it] 13%|█▎        | 2754/20600 [16:05:45<102:13:34, 20.62s/it] 13%|█▎        | 2755/20600 [16:06:04<99:34:28, 20.09s/it]  13%|█▎        | 2756/20600 [16:06:23<97:41:04, 19.71s/it] 13%|█▎        | 2757/20600 [16:06:54<113:45:35, 22.95s/it] 13%|█▎        | 2758/20600 [16:07:16<113:19:01, 22.86s/it] 13%|█▎        | 2759/20600 [16:07:37<110:49:13, 22.36s/it] 13%|█▎        | 2760/20600 [16:08:01<112:25:02, 22.69s/it]                                                           {'loss': 0.0, 'learning_rate': 4.806770044958159e-05, 'epoch': 26.6}
 13%|█▎        | 2760/20600 [16:08:13<112:25:02, 22.69s/it][INFO|trainer.py:3081] 2023-08-17 07:57:15,692 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 07:57:15,692 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 07:57:15,692 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 1.5495, 'eval_samples_per_second': 4.517, 'eval_steps_per_second': 0.645, 'epoch': 26.6}
 13%|█▎        | 2760/20600 [16:08:14<112:25:02, 22.69s/it]
100%|██████████| 1/1 [00:00<00:00,  1.47it/s][A
                                             [A 13%|█▎        | 2761/20600 [16:08:28<119:05:49, 24.03s/it] 13%|█▎        | 2762/20600 [16:08:44<106:21:27, 21.46s/it] 13%|█▎        | 2763/20600 [16:09:12<117:08:44, 23.64s/it] 13%|█▎        | 2764/20600 [16:09:32<110:41:54, 22.34s/it] 13%|█▎        | 2765/20600 [16:09:50<104:19:48, 21.06s/it] 13%|█▎        | 2766/20600 [16:10:11<104:16:36, 21.05s/it] 13%|█▎        | 2767/20600 [16:10:34<107:44:31, 21.75s/it] 13%|█▎        | 2768/20600 [16:10:48<96:47:31, 19.54s/it]  13%|█▎        | 2769/20600 [16:11:17<109:35:59, 22.13s/it] 13%|█▎        | 2770/20600 [16:11:36<105:35:19, 21.32s/it]                                                           {'loss': 0.0, 'learning_rate': 4.805297602595849e-05, 'epoch': 26.7}
 13%|█▎        | 2770/20600 [16:11:43<105:35:19, 21.32s/it][INFO|trainer.py:3081] 2023-08-17 08:00:46,217 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:00:46,217 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:00:46,217 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 1.5388, 'eval_samples_per_second': 4.549, 'eval_steps_per_second': 0.65, 'epoch': 26.7}
 13%|█▎        | 2770/20600 [16:11:45<105:35:19, 21.32s/it]
100%|██████████| 1/1 [00:00<00:00,  1.51it/s][A
                                             [A 13%|█▎        | 2771/20600 [16:12:02<111:56:09, 22.60s/it] 13%|█▎        | 2772/20600 [16:12:27<116:13:04, 23.47s/it] 13%|█▎        | 2773/20600 [16:12:48<112:45:23, 22.77s/it] 13%|█▎        | 2774/20600 [16:13:10<111:00:09, 22.42s/it] 13%|█▎        | 2775/20600 [16:13:27<102:34:08, 20.72s/it] 13%|█▎        | 2776/20600 [16:13:44<97:27:44, 19.68s/it]  13%|█▎        | 2777/20600 [16:14:01<94:13:42, 19.03s/it] 13%|█▎        | 2778/20600 [16:14:21<95:12:05, 19.23s/it] 13%|█▎        | 2779/20600 [16:14:38<91:39:44, 18.52s/it] 13%|█▎        | 2780/20600 [16:14:56<90:31:00, 18.29s/it]                                                          {'loss': 0.0, 'learning_rate': 4.803819798660592e-05, 'epoch': 26.8}
 13%|█▎        | 2780/20600 [16:14:56<90:31:00, 18.29s/it][INFO|trainer.py:3081] 2023-08-17 08:03:58,637 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:03:58,637 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:03:58,637 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8905, 'eval_samples_per_second': 1.016, 'eval_steps_per_second': 0.145, 'epoch': 26.8}
 13%|█▎        | 2780/20600 [16:15:03<90:31:00, 18.29s/it]
100%|██████████| 1/1 [00:06<00:00,  6.01s/it][A
                                             [A 14%|█▎        | 2781/20600 [16:15:21<101:23:42, 20.49s/it] 14%|█▎        | 2782/20600 [16:15:39<97:58:29, 19.80s/it]  14%|█▎        | 2783/20600 [16:15:57<94:34:10, 19.11s/it] 14%|█▎        | 2784/20600 [16:16:17<96:13:32, 19.44s/it] 14%|█▎        | 2785/20600 [16:16:38<97:56:28, 19.79s/it] 14%|█▎        | 2786/20600 [16:16:54<92:44:10, 18.74s/it] 14%|█▎        | 2787/20600 [16:17:23<107:57:58, 21.82s/it] 14%|█▎        | 2788/20600 [16:17:39<99:33:43, 20.12s/it]  14%|█▎        | 2789/20600 [16:17:56<94:21:22, 19.07s/it] 14%|█▎        | 2790/20600 [16:18:12<89:55:48, 18.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.8023366365894095e-05, 'epoch': 26.89}
 14%|█▎        | 2790/20600 [16:18:12<89:55:48, 18.18s/it][INFO|trainer.py:3081] 2023-08-17 08:07:14,944 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:07:14,944 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:07:14,944 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0905, 'eval_samples_per_second': 1.711, 'eval_steps_per_second': 0.244, 'epoch': 26.89}
 14%|█▎        | 2790/20600 [16:18:16<89:55:48, 18.18s/it]
100%|██████████| 1/1 [00:03<00:00,  3.18s/it][A
                                             [A 14%|█▎        | 2791/20600 [16:18:35<96:29:00, 19.50s/it] 14%|█▎        | 2792/20600 [16:18:52<93:18:40, 18.86s/it] 14%|█▎        | 2793/20600 [16:19:19<106:07:04, 21.45s/it] 14%|█▎        | 2794/20600 [16:19:36<99:32:58, 20.13s/it]  14%|█▎        | 2795/20600 [16:19:56<98:00:41, 19.82s/it] 14%|█▎        | 2796/20600 [16:20:16<98:57:39, 20.01s/it] 14%|█▎        | 2797/20600 [16:20:39<104:04:49, 21.05s/it] 14%|█▎        | 2798/20600 [16:20:58<100:01:56, 20.23s/it] 14%|█▎        | 2799/20600 [16:21:20<103:35:48, 20.95s/it] 14%|█▎        | 2800/20600 [16:21:35<94:19:23, 19.08s/it]                                                           {'loss': 0.0, 'learning_rate': 4.8008481198317824e-05, 'epoch': 26.99}
 14%|█▎        | 2800/20600 [16:21:35<94:19:23, 19.08s/it][INFO|trainer.py:3081] 2023-08-17 08:10:38,122 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:10:38,122 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:10:38,122 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5893, 'eval_samples_per_second': 1.95, 'eval_steps_per_second': 0.279, 'epoch': 26.99}
 14%|█▎        | 2800/20600 [16:21:39<94:19:23, 19.08s/it]
100%|██████████| 1/1 [00:02<00:00,  2.68s/it][A
                                             [A 14%|█▎        | 2801/20600 [16:22:07<113:34:19, 22.97s/it] 14%|█▎        | 2802/20600 [16:22:23<102:42:40, 20.78s/it] 14%|█▎        | 2803/20600 [16:22:39<95:56:02, 19.41s/it]  14%|█▎        | 2804/20600 [16:22:57<93:48:54, 18.98s/it] 14%|█▎        | 2805/20600 [16:23:15<91:41:59, 18.55s/it] 14%|█▎        | 2806/20600 [16:23:33<91:09:45, 18.44s/it] 14%|█▎        | 2807/20600 [16:23:52<92:36:39, 18.74s/it] 14%|█▎        | 2808/20600 [16:24:18<102:48:42, 20.80s/it] 14%|█▎        | 2809/20600 [16:24:39<103:15:22, 20.89s/it] 14%|█▎        | 2810/20600 [16:25:02<107:04:07, 21.67s/it]                                                           {'loss': 0.0, 'learning_rate': 4.799354251849645e-05, 'epoch': 27.08}
 14%|█▎        | 2810/20600 [16:25:02<107:04:07, 21.67s/it][INFO|trainer.py:3081] 2023-08-17 08:14:05,372 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:14:05,373 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:14:05,373 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.8708, 'eval_samples_per_second': 0.889, 'eval_steps_per_second': 0.127, 'epoch': 27.08}
 14%|█▎        | 2810/20600 [16:25:10<107:04:07, 21.67s/it]
100%|██████████| 1/1 [00:06<00:00,  7.00s/it][A
                                             [A 14%|█▎        | 2811/20600 [16:25:29<114:32:10, 23.18s/it] 14%|█▎        | 2812/20600 [16:25:57<122:05:40, 24.71s/it] 14%|█▎        | 2813/20600 [16:26:13<107:54:55, 21.84s/it] 14%|█▎        | 2814/20600 [16:26:43<120:21:24, 24.36s/it] 14%|█▎        | 2815/20600 [16:26:59<108:53:35, 22.04s/it] 14%|█▎        | 2816/20600 [16:27:20<106:36:21, 21.58s/it] 14%|█▎        | 2817/20600 [16:27:41<105:46:47, 21.41s/it] 14%|█▎        | 2818/20600 [16:28:07<113:19:58, 22.94s/it] 14%|█▎        | 2819/20600 [16:28:39<126:08:20, 25.54s/it] 14%|█▎        | 2820/20600 [16:28:57<114:27:08, 23.17s/it]                                                           {'loss': 0.0, 'learning_rate': 4.797855036117379e-05, 'epoch': 27.18}
 14%|█▎        | 2820/20600 [16:28:57<114:27:08, 23.17s/it][INFO|trainer.py:3081] 2023-08-17 08:17:59,691 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:17:59,691 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:17:59,691 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.1155, 'eval_samples_per_second': 0.984, 'eval_steps_per_second': 0.141, 'epoch': 27.18}
 14%|█▎        | 2820/20600 [16:29:04<114:27:08, 23.17s/it]
100%|██████████| 1/1 [00:06<00:00,  6.25s/it][A
                                             [A 14%|█▎        | 2821/20600 [16:29:24<120:33:49, 24.41s/it] 14%|█▎        | 2822/20600 [16:29:42<110:22:35, 22.35s/it] 14%|█▎        | 2823/20600 [16:30:08<117:10:01, 23.73s/it] 14%|█▎        | 2824/20600 [16:30:24<104:47:36, 21.22s/it] 14%|█▎        | 2825/20600 [16:30:49<110:00:34, 22.28s/it] 14%|█▎        | 2826/20600 [16:31:05<101:35:17, 20.58s/it] 14%|█▎        | 2827/20600 [16:31:22<95:23:24, 19.32s/it]  14%|█▎        | 2828/20600 [16:31:50<108:54:47, 22.06s/it] 14%|█▎        | 2829/20600 [16:32:13<110:53:54, 22.47s/it] 14%|█▎        | 2830/20600 [16:32:36<110:17:44, 22.34s/it]                                                           {'loss': 0.0, 'learning_rate': 4.7963504761218034e-05, 'epoch': 27.28}
 14%|█▎        | 2830/20600 [16:32:38<110:17:44, 22.34s/it][INFO|trainer.py:3081] 2023-08-17 08:21:41,063 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:21:41,063 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:21:41,063 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 1.5618, 'eval_samples_per_second': 4.482, 'eval_steps_per_second': 0.64, 'epoch': 27.28}
 14%|█▎        | 2830/20600 [16:32:40<110:17:44, 22.34s/it]
100%|██████████| 1/1 [00:00<00:00,  1.42it/s][A
                                             [A 14%|█▎        | 2831/20600 [16:33:01<114:33:50, 23.21s/it] 14%|█▎        | 2832/20600 [16:33:22<111:45:06, 22.64s/it] 14%|█▍        | 2833/20600 [16:33:42<107:44:12, 21.83s/it] 14%|█▍        | 2834/20600 [16:34:03<106:07:33, 21.50s/it] 14%|█▍        | 2835/20600 [16:34:30<114:06:39, 23.12s/it] 14%|█▍        | 2836/20600 [16:34:43<99:47:55, 20.22s/it]  14%|█▍        | 2837/20600 [16:35:06<103:18:18, 20.94s/it] 14%|█▍        | 2838/20600 [16:35:29<106:06:23, 21.51s/it] 14%|█▍        | 2839/20600 [16:35:49<104:53:45, 21.26s/it] 14%|█▍        | 2840/20600 [16:36:03<94:04:35, 19.07s/it]                                                           {'loss': 0.0, 'learning_rate': 4.794840575362167e-05, 'epoch': 27.37}
 14%|█▍        | 2840/20600 [16:36:13<94:04:35, 19.07s/it][INFO|trainer.py:3081] 2023-08-17 08:25:16,299 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:25:16,299 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:25:16,299 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 1.5194, 'eval_samples_per_second': 4.607, 'eval_steps_per_second': 0.658, 'epoch': 27.37}
 14%|█▍        | 2840/20600 [16:36:15<94:04:35, 19.07s/it]
100%|██████████| 1/1 [00:00<00:00,  1.52it/s][A
                                             [A 14%|█▍        | 2841/20600 [16:36:30<106:13:22, 21.53s/it] 14%|█▍        | 2842/20600 [16:36:54<108:34:04, 22.01s/it] 14%|█▍        | 2843/20600 [16:37:10<99:43:13, 20.22s/it]  14%|█▍        | 2844/20600 [16:37:36<108:55:54, 22.09s/it] 14%|█▍        | 2845/20600 [16:37:58<109:15:23, 22.15s/it] 14%|█▍        | 2846/20600 [16:38:20<107:57:37, 21.89s/it] 14%|█▍        | 2847/20600 [16:38:38<103:05:27, 20.91s/it] 14%|█▍        | 2848/20600 [16:38:58<100:44:02, 20.43s/it] 14%|█▍        | 2849/20600 [16:39:19<102:27:27, 20.78s/it] 14%|█▍        | 2850/20600 [16:39:37<97:50:15, 19.84s/it]                                                           {'loss': 0.0, 'learning_rate': 4.793325337350137e-05, 'epoch': 27.47}
 14%|█▍        | 2850/20600 [16:40:06<97:50:15, 19.84s/it][INFO|trainer.py:3081] 2023-08-17 08:29:08,744 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:29:08,744 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:29:08,744 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 1.4194, 'eval_samples_per_second': 4.932, 'eval_steps_per_second': 0.705, 'epoch': 27.47}
 14%|█▍        | 2850/20600 [16:40:07<97:50:15, 19.84s/it]
100%|██████████| 1/1 [00:00<00:00,  1.65it/s][A
                                             [A 14%|█▍        | 2851/20600 [16:40:18<129:37:50, 26.29s/it] 14%|█▍        | 2852/20600 [16:40:31<109:09:53, 22.14s/it] 14%|█▍        | 2853/20600 [16:40:52<107:33:27, 21.82s/it] 14%|█▍        | 2854/20600 [16:41:10<102:05:09, 20.71s/it] 14%|█▍        | 2855/20600 [16:41:27<96:34:15, 19.59s/it]  14%|█▍        | 2856/20600 [16:41:46<95:16:04, 19.33s/it] 14%|█▍        | 2857/20600 [16:42:05<95:31:23, 19.38s/it] 14%|█▍        | 2858/20600 [16:42:25<96:08:02, 19.51s/it] 14%|█▍        | 2859/20600 [16:42:50<104:23:18, 21.18s/it] 14%|█▍        | 2860/20600 [16:43:06<97:23:11, 19.76s/it]                                                           {'loss': 0.0, 'learning_rate': 4.791804765609798e-05, 'epoch': 27.57}
 14%|█▍        | 2860/20600 [16:43:06<97:23:11, 19.76s/it][INFO|trainer.py:3081] 2023-08-17 08:32:09,372 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:32:09,372 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:32:09,372 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6071, 'eval_samples_per_second': 1.941, 'eval_steps_per_second': 0.277, 'epoch': 27.57}
 14%|█▍        | 2860/20600 [16:43:10<97:23:11, 19.76s/it]
100%|██████████| 1/1 [00:02<00:00,  2.66s/it][A
                                             [A 14%|█▍        | 2861/20600 [16:43:26<97:38:44, 19.82s/it] 14%|█▍        | 2862/20600 [16:43:46<98:07:03, 19.91s/it] 14%|█▍        | 2863/20600 [16:44:06<97:21:04, 19.76s/it] 14%|█▍        | 2864/20600 [16:44:25<96:59:01, 19.69s/it] 14%|█▍        | 2865/20600 [16:44:42<92:25:32, 18.76s/it] 14%|█▍        | 2866/20600 [16:45:02<94:59:46, 19.28s/it] 14%|█▍        | 2867/20600 [16:45:20<92:05:57, 18.70s/it] 14%|█▍        | 2868/20600 [16:45:42<97:39:01, 19.83s/it] 14%|█▍        | 2869/20600 [16:45:59<93:47:36, 19.04s/it] 14%|█▍        | 2870/20600 [16:46:17<92:16:14, 18.74s/it]                                                          {'loss': 0.0, 'learning_rate': 4.790278863677635e-05, 'epoch': 27.66}
 14%|█▍        | 2870/20600 [16:46:18<92:16:14, 18.74s/it][INFO|trainer.py:3081] 2023-08-17 08:35:20,499 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:35:20,499 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:35:20,499 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.4156, 'eval_samples_per_second': 1.091, 'eval_steps_per_second': 0.156, 'epoch': 27.66}
 14%|█▍        | 2870/20600 [16:46:24<92:16:14, 18.74s/it]
100%|██████████| 1/1 [00:05<00:00,  5.57s/it][A
                                             [A 14%|█▍        | 2871/20600 [16:46:40<98:23:43, 19.98s/it] 14%|█▍        | 2872/20600 [16:46:57<93:02:51, 18.90s/it] 14%|█▍        | 2873/20600 [16:47:14<91:09:34, 18.51s/it] 14%|█▍        | 2874/20600 [16:47:33<91:08:58, 18.51s/it] 14%|█▍        | 2875/20600 [16:47:51<90:11:01, 18.32s/it] 14%|█▍        | 2876/20600 [16:48:09<89:35:55, 18.20s/it] 14%|█▍        | 2877/20600 [16:48:30<94:29:02, 19.19s/it] 14%|█▍        | 2878/20600 [16:48:48<92:27:23, 18.78s/it] 14%|█▍        | 2879/20600 [16:49:06<90:43:40, 18.43s/it] 14%|█▍        | 2880/20600 [16:49:25<92:03:01, 18.70s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7887476351025354e-05, 'epoch': 27.76}
 14%|█▍        | 2880/20600 [16:49:25<92:03:01, 18.70s/it][INFO|trainer.py:3081] 2023-08-17 08:38:27,938 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:38:27,939 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:38:27,939 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.5514, 'eval_samples_per_second': 0.927, 'eval_steps_per_second': 0.132, 'epoch': 27.76}
 14%|█▍        | 2880/20600 [16:49:33<92:03:01, 18.70s/it]
100%|██████████| 1/1 [00:06<00:00,  6.67s/it][A
                                             [A 14%|█▍        | 2881/20600 [16:49:52<103:51:28, 21.10s/it] 14%|█▍        | 2882/20600 [16:50:11<101:46:03, 20.68s/it] 14%|█▍        | 2883/20600 [16:50:30<99:23:14, 20.19s/it]  14%|█▍        | 2884/20600 [16:50:53<103:23:27, 21.01s/it] 14%|█▍        | 2885/20600 [16:51:14<103:04:21, 20.95s/it] 14%|█▍        | 2886/20600 [16:51:31<97:00:36, 19.72s/it]  14%|█▍        | 2887/20600 [16:51:49<94:17:27, 19.16s/it] 14%|█▍        | 2888/20600 [16:52:06<90:40:41, 18.43s/it] 14%|█▍        | 2889/20600 [16:52:28<97:09:33, 19.75s/it] 14%|█▍        | 2890/20600 [16:52:50<99:40:36, 20.26s/it]                                                          {'loss': 0.0, 'learning_rate': 4.78721108344577e-05, 'epoch': 27.86}
 14%|█▍        | 2890/20600 [16:52:50<99:40:36, 20.26s/it][INFO|trainer.py:3081] 2023-08-17 08:41:52,805 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:41:52,805 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:41:52,805 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.8305, 'eval_samples_per_second': 1.449, 'eval_steps_per_second': 0.207, 'epoch': 27.86}
 14%|█▍        | 2890/20600 [16:52:55<99:40:36, 20.26s/it]
100%|██████████| 1/1 [00:03<00:00,  3.92s/it][A
                                             [A 14%|█▍        | 2891/20600 [16:53:11<101:41:39, 20.67s/it] 14%|█▍        | 2892/20600 [16:53:35<105:41:50, 21.49s/it] 14%|█▍        | 2893/20600 [16:53:53<101:21:05, 20.61s/it] 14%|█▍        | 2894/20600 [16:54:13<100:29:48, 20.43s/it] 14%|█▍        | 2895/20600 [16:54:35<102:42:47, 20.88s/it] 14%|█▍        | 2896/20600 [16:54:53<97:53:18, 19.91s/it]  14%|█▍        | 2897/20600 [16:55:20<107:57:20, 21.95s/it] 14%|█▍        | 2898/20600 [16:55:34<96:46:18, 19.68s/it]  14%|█▍        | 2899/20600 [16:55:58<102:21:21, 20.82s/it] 14%|█▍        | 2900/20600 [16:56:14<95:51:41, 19.50s/it]                                                           {'loss': 0.0, 'learning_rate': 4.785669212280993e-05, 'epoch': 27.95}
 14%|█▍        | 2900/20600 [16:56:14<95:51:41, 19.50s/it][INFO|trainer.py:3081] 2023-08-17 08:45:16,980 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:45:16,981 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:45:16,981 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.0877, 'eval_samples_per_second': 0.866, 'eval_steps_per_second': 0.124, 'epoch': 27.95}
 14%|█▍        | 2900/20600 [16:56:22<95:51:41, 19.50s/it]
100%|██████████| 1/1 [00:07<00:00,  7.15s/it][A
                                             [A 14%|█▍        | 2901/20600 [16:56:41<106:24:18, 21.64s/it] 14%|█▍        | 2902/20600 [16:57:05<110:36:15, 22.50s/it] 14%|█▍        | 2903/20600 [16:57:26<108:28:06, 22.07s/it] 14%|█▍        | 2904/20600 [16:57:44<101:40:40, 20.68s/it] 14%|█▍        | 2905/20600 [16:58:10<109:44:50, 22.33s/it] 14%|█▍        | 2906/20600 [16:58:28<103:34:49, 21.07s/it] 14%|█▍        | 2907/20600 [16:58:55<112:08:01, 22.82s/it] 14%|█▍        | 2908/20600 [16:59:14<107:00:55, 21.78s/it] 14%|█▍        | 2909/20600 [16:59:46<122:05:27, 24.84s/it] 14%|█▍        | 2910/20600 [17:00:07<116:33:08, 23.72s/it]                                                           {'loss': 0.0, 'learning_rate': 4.784122025194228e-05, 'epoch': 28.05}
 14%|█▍        | 2910/20600 [17:00:07<116:33:08, 23.72s/it][INFO|trainer.py:3081] 2023-08-17 08:49:10,288 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:49:10,288 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:49:10,288 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.9728, 'eval_samples_per_second': 0.78, 'eval_steps_per_second': 0.111, 'epoch': 28.05}
 14%|█▍        | 2910/20600 [17:00:16<116:33:08, 23.72s/it]
100%|██████████| 1/1 [00:08<00:00,  8.09s/it][A
                                             [A 14%|█▍        | 2911/20600 [17:00:36<124:28:40, 25.33s/it] 14%|█▍        | 2912/20600 [17:00:59<120:37:43, 24.55s/it] 14%|█▍        | 2913/20600 [17:01:20<114:46:53, 23.36s/it] 14%|█▍        | 2914/20600 [17:01:45<116:57:29, 23.81s/it] 14%|█▍        | 2915/20600 [17:02:04<110:42:16, 22.54s/it] 14%|█▍        | 2916/20600 [17:02:23<104:35:34, 21.29s/it] 14%|█▍        | 2917/20600 [17:02:43<103:16:51, 21.03s/it] 14%|█▍        | 2918/20600 [17:03:04<103:57:19, 21.16s/it] 14%|█▍        | 2919/20600 [17:03:32<113:33:29, 23.12s/it] 14%|█▍        | 2920/20600 [17:03:51<107:13:11, 21.83s/it]                                                           {'loss': 0.0, 'learning_rate': 4.782569525783865e-05, 'epoch': 28.14}
 14%|█▍        | 2920/20600 [17:03:51<107:13:11, 21.83s/it][INFO|trainer.py:3081] 2023-08-17 08:52:53,903 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:52:53,903 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:52:53,903 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.0683, 'eval_samples_per_second': 2.281, 'eval_steps_per_second': 0.326, 'epoch': 28.14}
 14%|█▍        | 2920/20600 [17:03:54<107:13:11, 21.83s/it]
100%|██████████| 1/1 [00:02<00:00,  2.19s/it][A
                                             [A 14%|█▍        | 2921/20600 [17:04:10<103:16:10, 21.03s/it] 14%|█▍        | 2922/20600 [17:04:30<101:32:14, 20.68s/it] 14%|█▍        | 2923/20600 [17:04:55<108:06:01, 22.02s/it] 14%|█▍        | 2924/20600 [17:05:14<103:35:15, 21.10s/it] 14%|█▍        | 2925/20600 [17:05:31<97:43:45, 19.91s/it]  14%|█▍        | 2926/20600 [17:05:55<102:58:35, 20.98s/it] 14%|█▍        | 2927/20600 [17:06:15<101:46:40, 20.73s/it] 14%|█▍        | 2928/20600 [17:06:34<98:52:45, 20.14s/it]  14%|█▍        | 2929/20600 [17:06:54<98:45:37, 20.12s/it] 14%|█▍        | 2930/20600 [17:07:09<92:01:58, 18.75s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7810117176606476e-05, 'epoch': 28.24}
 14%|█▍        | 2930/20600 [17:07:09<92:01:58, 18.75s/it][INFO|trainer.py:3081] 2023-08-17 08:56:12,157 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:56:12,158 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:56:12,158 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8782, 'eval_samples_per_second': 1.805, 'eval_steps_per_second': 0.258, 'epoch': 28.24}
 14%|█▍        | 2930/20600 [17:07:13<92:01:58, 18.75s/it]
100%|██████████| 1/1 [00:02<00:00,  2.93s/it][A
                                             [A 14%|█▍        | 2931/20600 [17:07:32<97:42:29, 19.91s/it] 14%|█▍        | 2932/20600 [17:07:54<100:47:04, 20.54s/it] 14%|█▍        | 2933/20600 [17:08:19<107:29:05, 21.90s/it] 14%|█▍        | 2934/20600 [17:08:36<100:32:26, 20.49s/it] 14%|█▍        | 2935/20600 [17:09:01<107:15:38, 21.86s/it] 14%|█▍        | 2936/20600 [17:09:17<99:01:52, 20.18s/it]  14%|█▍        | 2937/20600 [17:09:33<91:36:29, 18.67s/it] 14%|█▍        | 2938/20600 [17:10:00<104:23:10, 21.28s/it] 14%|█▍        | 2939/20600 [17:10:24<108:08:33, 22.04s/it] 14%|█▍        | 2940/20600 [17:10:47<109:51:24, 22.39s/it]                                                           {'loss': 0.0, 'learning_rate': 4.779448604447664e-05, 'epoch': 28.34}
 14%|█▍        | 2940/20600 [17:10:47<109:51:24, 22.39s/it][INFO|trainer.py:3081] 2023-08-17 08:59:49,919 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 08:59:49,919 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 08:59:49,919 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.2164, 'eval_samples_per_second': 1.342, 'eval_steps_per_second': 0.192, 'epoch': 28.34}
 14%|█▍        | 2940/20600 [17:10:52<109:51:24, 22.39s/it]
100%|██████████| 1/1 [00:04<00:00,  4.38s/it][A
                                             [A 14%|█▍        | 2941/20600 [17:11:08<108:25:41, 22.10s/it] 14%|█▍        | 2942/20600 [17:11:26<102:32:05, 20.90s/it] 14%|█▍        | 2943/20600 [17:11:49<104:39:20, 21.34s/it] 14%|█▍        | 2944/20600 [17:12:07<99:52:50, 20.37s/it]  14%|█▍        | 2945/20600 [17:12:28<101:02:56, 20.60s/it] 14%|█▍        | 2946/20600 [17:12:50<103:10:22, 21.04s/it] 14%|█▍        | 2947/20600 [17:13:11<103:18:51, 21.07s/it] 14%|█▍        | 2948/20600 [17:13:30<99:40:19, 20.33s/it]  14%|█▍        | 2949/20600 [17:13:51<100:11:51, 20.44s/it] 14%|█▍        | 2950/20600 [17:14:08<95:26:02, 19.47s/it]                                                           {'loss': 0.0, 'learning_rate': 4.777880189780346e-05, 'epoch': 28.43}
 14%|█▍        | 2950/20600 [17:14:08<95:26:02, 19.47s/it][INFO|trainer.py:3081] 2023-08-17 09:03:10,743 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:03:10,743 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:03:10,743 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8273, 'eval_samples_per_second': 1.025, 'eval_steps_per_second': 0.146, 'epoch': 28.43}
 14%|█▍        | 2950/20600 [17:14:15<95:26:02, 19.47s/it]
100%|██████████| 1/1 [00:05<00:00,  5.95s/it][A
                                             [A 14%|█▍        | 2951/20600 [17:14:35<107:07:56, 21.85s/it] 14%|█▍        | 2952/20600 [17:14:52<99:05:39, 20.21s/it]  14%|█▍        | 2953/20600 [17:15:09<95:09:14, 19.41s/it] 14%|█▍        | 2954/20600 [17:15:29<96:32:45, 19.70s/it] 14%|█▍        | 2955/20600 [17:15:46<91:35:54, 18.69s/it] 14%|█▍        | 2956/20600 [17:16:12<102:02:50, 20.82s/it] 14%|█▍        | 2957/20600 [17:16:34<104:09:05, 21.25s/it] 14%|█▍        | 2958/20600 [17:16:51<98:31:08, 20.10s/it]  14%|█▍        | 2959/20600 [17:17:18<108:55:26, 22.23s/it] 14%|█▍        | 2960/20600 [17:17:38<105:32:36, 21.54s/it]                                                           {'loss': 0.0, 'learning_rate': 4.776306477306451e-05, 'epoch': 28.53}
 14%|█▍        | 2960/20600 [17:17:38<105:32:36, 21.54s/it][INFO|trainer.py:3081] 2023-08-17 09:06:41,391 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:06:41,391 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:06:41,391 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.8385, 'eval_samples_per_second': 1.447, 'eval_steps_per_second': 0.207, 'epoch': 28.53}
 14%|█▍        | 2960/20600 [17:17:43<105:32:36, 21.54s/it]
100%|██████████| 1/1 [00:03<00:00,  3.97s/it][A
                                             [A 14%|█▍        | 2961/20600 [17:18:03<110:46:19, 22.61s/it] 14%|█▍        | 2962/20600 [17:18:20<101:32:15, 20.72s/it] 14%|█▍        | 2963/20600 [17:18:37<96:30:57, 19.70s/it]  14%|█▍        | 2964/20600 [17:18:55<93:43:15, 19.13s/it] 14%|█▍        | 2965/20600 [17:19:16<96:35:24, 19.72s/it] 14%|█▍        | 2966/20600 [17:19:34<94:31:12, 19.30s/it] 14%|█▍        | 2967/20600 [17:19:51<90:07:35, 18.40s/it] 14%|█▍        | 2968/20600 [17:20:10<91:28:35, 18.68s/it] 14%|█▍        | 2969/20600 [17:20:34<98:57:16, 20.21s/it] 14%|█▍        | 2970/20600 [17:20:58<105:34:44, 21.56s/it]                                                           {'loss': 0.0, 'learning_rate': 4.77472747068606e-05, 'epoch': 28.63}
 14%|█▍        | 2970/20600 [17:20:58<105:34:44, 21.56s/it][INFO|trainer.py:3081] 2023-08-17 09:10:01,453 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:10:01,453 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:10:01,453 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.0244, 'eval_samples_per_second': 1.393, 'eval_steps_per_second': 0.199, 'epoch': 28.63}
 14%|█▍        | 2970/20600 [17:21:04<105:34:44, 21.56s/it]
100%|██████████| 1/1 [00:04<00:00,  4.18s/it][A
                                             [A 14%|█▍        | 2971/20600 [17:21:25<112:48:09, 23.04s/it] 14%|█▍        | 2972/20600 [17:21:50<115:54:23, 23.67s/it] 14%|█▍        | 2973/20600 [17:22:08<107:09:58, 21.89s/it] 14%|█▍        | 2974/20600 [17:22:24<98:07:13, 20.04s/it]  14%|█▍        | 2975/20600 [17:22:42<95:51:15, 19.58s/it] 14%|█▍        | 2976/20600 [17:23:00<93:44:06, 19.15s/it] 14%|█▍        | 2977/20600 [17:23:21<96:25:51, 19.70s/it] 14%|█▍        | 2978/20600 [17:23:43<99:21:44, 20.30s/it] 14%|█▍        | 2979/20600 [17:24:05<101:27:01, 20.73s/it] 14%|█▍        | 2980/20600 [17:24:25<100:14:39, 20.48s/it]                                                           {'loss': 0.0, 'learning_rate': 4.7731431735915655e-05, 'epoch': 28.72}
 14%|█▍        | 2980/20600 [17:24:25<100:14:39, 20.48s/it][INFO|trainer.py:3081] 2023-08-17 09:13:27,501 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:13:27,501 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:13:27,501 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.8485, 'eval_samples_per_second': 1.444, 'eval_steps_per_second': 0.206, 'epoch': 28.72}
 14%|█▍        | 2980/20600 [17:24:29<100:14:39, 20.48s/it]
100%|██████████| 1/1 [00:03<00:00,  3.99s/it][A
                                             [A 14%|█▍        | 2981/20600 [17:24:49<105:24:51, 21.54s/it] 14%|█▍        | 2982/20600 [17:25:10<105:47:29, 21.62s/it] 14%|█▍        | 2983/20600 [17:25:28<100:00:38, 20.44s/it] 14%|█▍        | 2984/20600 [17:25:45<94:48:18, 19.37s/it]  14%|█▍        | 2985/20600 [17:26:02<91:55:41, 18.79s/it] 14%|█▍        | 2986/20600 [17:26:22<93:20:57, 19.08s/it] 14%|█▍        | 2987/20600 [17:26:44<97:09:01, 19.86s/it] 15%|█▍        | 2988/20600 [17:27:03<96:14:59, 19.67s/it] 15%|█▍        | 2989/20600 [17:27:22<94:59:13, 19.42s/it] 15%|█▍        | 2990/20600 [17:27:39<91:16:20, 18.66s/it]                                                          {'loss': 0.0, 'learning_rate': 4.771553589707666e-05, 'epoch': 28.82}
 15%|█▍        | 2990/20600 [17:27:39<91:16:20, 18.66s/it][INFO|trainer.py:3081] 2023-08-17 09:16:41,688 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:16:41,688 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:16:41,688 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2263, 'eval_samples_per_second': 0.969, 'eval_steps_per_second': 0.138, 'epoch': 28.82}
 15%|█▍        | 2990/20600 [17:27:46<91:16:20, 18.66s/it]
100%|██████████| 1/1 [00:06<00:00,  6.33s/it][A
                                             [A 15%|█▍        | 2991/20600 [17:28:08<106:18:22, 21.73s/it] 15%|█▍        | 2992/20600 [17:28:30<106:56:45, 21.87s/it] 15%|█▍        | 2993/20600 [17:28:49<102:32:24, 20.97s/it] 15%|█▍        | 2994/20600 [17:29:07<98:57:49, 20.24s/it]  15%|█▍        | 2995/20600 [17:29:26<97:32:44, 19.95s/it] 15%|█▍        | 2996/20600 [17:29:47<98:40:51, 20.18s/it] 15%|█▍        | 2997/20600 [17:30:05<95:26:26, 19.52s/it] 15%|█▍        | 2998/20600 [17:30:23<92:44:06, 18.97s/it] 15%|█▍        | 2999/20600 [17:30:41<91:02:56, 18.62s/it] 15%|█▍        | 3000/20600 [17:30:58<89:30:14, 18.31s/it]                                                          {'loss': 0.0, 'learning_rate': 4.769958722731353e-05, 'epoch': 28.92}
 15%|█▍        | 3000/20600 [17:30:58<89:30:14, 18.31s/it][INFO|trainer.py:3081] 2023-08-17 09:20:01,212 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:20:01,213 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:20:01,213 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.1928, 'eval_samples_per_second': 1.348, 'eval_steps_per_second': 0.193, 'epoch': 28.92}
 15%|█▍        | 3000/20600 [17:31:03<89:30:14, 18.31s/it]
100%|██████████| 1/1 [00:04<00:00,  4.30s/it][A
                                             [A 15%|█▍        | 3001/20600 [17:31:21<95:46:09, 19.59s/it] 15%|█▍        | 3002/20600 [17:31:44<101:20:10, 20.73s/it] 15%|█▍        | 3003/20600 [17:32:10<108:55:04, 22.28s/it] 15%|█▍        | 3004/20600 [17:32:32<109:04:09, 22.31s/it] 15%|█▍        | 3005/20600 [17:32:50<101:42:07, 20.81s/it] 15%|█▍        | 3006/20600 [17:33:07<96:09:06, 19.67s/it]  15%|█▍        | 3007/20600 [17:33:31<102:12:50, 20.92s/it] 15%|█▍        | 3008/20600 [17:33:47<95:51:17, 19.62s/it]  15%|█▍        | 3009/20600 [17:34:08<97:57:55, 20.05s/it] 15%|█▍        | 3010/20600 [17:34:35<107:55:39, 22.09s/it]                                                           {'loss': 0.0, 'learning_rate': 4.768358576371908e-05, 'epoch': 29.01}
 15%|█▍        | 3010/20600 [17:34:35<107:55:39, 22.09s/it][INFO|trainer.py:3081] 2023-08-17 09:23:38,109 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:23:38,109 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:23:38,109 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3831, 'eval_samples_per_second': 2.069, 'eval_steps_per_second': 0.296, 'epoch': 29.01}
 15%|█▍        | 3010/20600 [17:34:39<107:55:39, 22.09s/it]
100%|██████████| 1/1 [00:02<00:00,  2.53s/it][A
                                             [A 15%|█▍        | 3011/20600 [17:35:00<112:39:34, 23.06s/it] 15%|█▍        | 3012/20600 [17:35:16<101:56:12, 20.86s/it] 15%|█▍        | 3013/20600 [17:35:34<97:09:29, 19.89s/it]  15%|█▍        | 3014/20600 [17:35:59<105:40:09, 21.63s/it] 15%|█▍        | 3015/20600 [17:36:19<103:12:24, 21.13s/it] 15%|█▍        | 3016/20600 [17:36:40<102:54:54, 21.07s/it] 15%|█▍        | 3017/20600 [17:37:02<103:32:41, 21.20s/it] 15%|█▍        | 3018/20600 [17:37:25<106:09:25, 21.74s/it] 15%|█▍        | 3019/20600 [17:37:54<117:01:29, 23.96s/it] 15%|█▍        | 3020/20600 [17:38:14<111:06:17, 22.75s/it]                                                           {'loss': 0.0, 'learning_rate': 4.766753154350891e-05, 'epoch': 29.11}
 15%|█▍        | 3020/20600 [17:38:14<111:06:17, 22.75s/it][INFO|trainer.py:3081] 2023-08-17 09:27:16,936 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:27:16,937 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:27:16,937 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4509, 'eval_samples_per_second': 2.028, 'eval_steps_per_second': 0.29, 'epoch': 29.11}
 15%|█▍        | 3020/20600 [17:38:17<111:06:17, 22.75s/it]
100%|██████████| 1/1 [00:02<00:00,  2.61s/it][A
                                             [A 15%|█▍        | 3021/20600 [17:38:42<118:19:20, 24.23s/it] 15%|█▍        | 3022/20600 [17:39:05<117:21:25, 24.03s/it] 15%|█▍        | 3023/20600 [17:39:24<110:11:59, 22.57s/it] 15%|█▍        | 3024/20600 [17:39:49<113:38:16, 23.28s/it] 15%|█▍        | 3025/20600 [17:40:10<110:19:47, 22.60s/it] 15%|█▍        | 3026/20600 [17:40:29<104:02:49, 21.31s/it] 15%|█▍        | 3027/20600 [17:40:46<98:56:53, 20.27s/it]  15%|█▍        | 3028/20600 [17:41:04<95:06:05, 19.48s/it] 15%|█▍        | 3029/20600 [17:41:44<125:01:59, 25.62s/it] 15%|█▍        | 3030/20600 [17:42:03<115:08:33, 23.59s/it]                                                           {'loss': 0.0, 'learning_rate': 4.765142460402131e-05, 'epoch': 29.2}
 15%|█▍        | 3030/20600 [17:42:12<115:08:33, 23.59s/it][INFO|trainer.py:3081] 2023-08-17 09:31:15,397 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:31:15,397 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:31:15,397 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 1.5316, 'eval_samples_per_second': 4.57, 'eval_steps_per_second': 0.653, 'epoch': 29.2}
 15%|█▍        | 3030/20600 [17:42:14<115:08:33, 23.59s/it]
100%|██████████| 1/1 [00:00<00:00,  1.52it/s][A
                                             [A 15%|█▍        | 3031/20600 [17:42:31<121:20:21, 24.86s/it] 15%|█▍        | 3032/20600 [17:42:49<111:22:01, 22.82s/it] 15%|█▍        | 3033/20600 [17:43:08<106:40:14, 21.86s/it] 15%|█▍        | 3034/20600 [17:43:28<104:04:37, 21.33s/it] 15%|█▍        | 3035/20600 [17:43:47<100:01:05, 20.50s/it] 15%|█▍        | 3036/20600 [17:44:06<98:07:48, 20.11s/it]  15%|█▍        | 3037/20600 [17:44:29<102:21:00, 20.98s/it] 15%|█▍        | 3038/20600 [17:44:46<95:35:59, 19.60s/it]  15%|█▍        | 3039/20600 [17:45:04<93:50:29, 19.24s/it] 15%|█▍        | 3040/20600 [17:45:26<97:22:36, 19.96s/it]                                                          {'loss': 0.0, 'learning_rate': 4.763526498271718e-05, 'epoch': 29.3}
 15%|█▍        | 3040/20600 [17:45:26<97:22:36, 19.96s/it][INFO|trainer.py:3081] 2023-08-17 09:34:28,698 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:34:28,698 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:34:28,698 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.9837, 'eval_samples_per_second': 0.779, 'eval_steps_per_second': 0.111, 'epoch': 29.3}
 15%|█▍        | 3040/20600 [17:45:35<97:22:36, 19.96s/it]
100%|██████████| 1/1 [00:08<00:00,  8.09s/it][A
                                             [A 15%|█▍        | 3041/20600 [17:45:57<114:20:37, 23.44s/it] 15%|█▍        | 3042/20600 [17:46:15<105:17:24, 21.59s/it] 15%|█▍        | 3043/20600 [17:46:35<103:44:10, 21.27s/it] 15%|█▍        | 3044/20600 [17:46:57<104:03:31, 21.34s/it] 15%|█▍        | 3045/20600 [17:47:14<98:43:10, 20.24s/it]  15%|█▍        | 3046/20600 [17:47:43<111:38:47, 22.90s/it] 15%|█▍        | 3047/20600 [17:48:05<109:07:59, 22.38s/it] 15%|█▍        | 3048/20600 [17:48:26<107:11:20, 21.98s/it] 15%|█▍        | 3049/20600 [17:48:45<103:13:28, 21.17s/it] 15%|█▍        | 3050/20600 [17:49:03<99:03:20, 20.32s/it]                                                           {'loss': 0.0, 'learning_rate': 4.761905271717993e-05, 'epoch': 29.4}
 15%|█▍        | 3050/20600 [17:49:03<99:03:20, 20.32s/it][INFO|trainer.py:3081] 2023-08-17 09:38:06,159 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:38:06,159 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:38:06,159 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.6522, 'eval_samples_per_second': 0.809, 'eval_steps_per_second': 0.116, 'epoch': 29.4}
 15%|█▍        | 3050/20600 [17:49:12<99:03:20, 20.32s/it]
100%|██████████| 1/1 [00:07<00:00,  7.70s/it][A
                                             [A 15%|█▍        | 3051/20600 [17:49:37<119:25:13, 24.50s/it] 15%|█▍        | 3052/20600 [17:49:57<112:19:25, 23.04s/it] 15%|█▍        | 3053/20600 [17:50:16<106:11:14, 21.79s/it] 15%|█▍        | 3054/20600 [17:50:41<111:30:16, 22.88s/it] 15%|█▍        | 3055/20600 [17:50:59<104:02:32, 21.35s/it] 15%|█▍        | 3056/20600 [17:51:19<101:25:56, 20.81s/it] 15%|█▍        | 3057/20600 [17:51:37<97:30:52, 20.01s/it]  15%|█▍        | 3058/20600 [17:51:54<93:11:45, 19.13s/it] 15%|█▍        | 3059/20600 [17:52:16<98:05:32, 20.13s/it] 15%|█▍        | 3060/20600 [17:52:34<94:45:39, 19.45s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7602787845115457e-05, 'epoch': 29.49}
 15%|█▍        | 3060/20600 [17:52:34<94:45:39, 19.45s/it][INFO|trainer.py:3081] 2023-08-17 09:41:37,219 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:41:37,219 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:41:37,219 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.1024, 'eval_samples_per_second': 0.864, 'eval_steps_per_second': 0.123, 'epoch': 29.49}
 15%|█▍        | 3060/20600 [17:52:42<94:45:39, 19.45s/it]
100%|██████████| 1/1 [00:07<00:00,  7.22s/it][A
                                             [A 15%|█▍        | 3061/20600 [17:53:03<108:07:39, 22.19s/it] 15%|█▍        | 3062/20600 [17:53:22<103:23:02, 21.22s/it] 15%|█▍        | 3063/20600 [17:53:42<102:01:48, 20.94s/it] 15%|█▍        | 3064/20600 [17:53:59<96:18:59, 19.77s/it]  15%|█▍        | 3065/20600 [17:54:23<103:01:29, 21.15s/it] 15%|█▍        | 3066/20600 [17:54:43<101:06:56, 20.76s/it] 15%|█▍        | 3067/20600 [17:55:05<102:28:12, 21.04s/it] 15%|█▍        | 3068/20600 [17:55:21<95:30:47, 19.61s/it]  15%|█▍        | 3069/20600 [17:55:45<100:53:35, 20.72s/it] 15%|█▍        | 3070/20600 [17:56:05<99:45:46, 20.49s/it]                                                           {'loss': 0.0, 'learning_rate': 4.758647040435197e-05, 'epoch': 29.59}
 15%|█▍        | 3070/20600 [17:56:05<99:45:46, 20.49s/it][INFO|trainer.py:3081] 2023-08-17 09:45:07,541 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:45:07,541 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:45:07,541 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.127, 'eval_samples_per_second': 2.239, 'eval_steps_per_second': 0.32, 'epoch': 29.59}
 15%|█▍        | 3070/20600 [17:56:08<99:45:46, 20.49s/it]
100%|██████████| 1/1 [00:02<00:00,  2.21s/it][A
                                             [A 15%|█▍        | 3071/20600 [17:56:30<107:20:50, 22.05s/it] 15%|█▍        | 3072/20600 [17:56:55<110:40:51, 22.73s/it] 15%|█▍        | 3073/20600 [17:57:13<105:00:21, 21.57s/it] 15%|█▍        | 3074/20600 [17:57:36<106:42:59, 21.92s/it] 15%|█▍        | 3075/20600 [17:57:58<106:09:26, 21.81s/it] 15%|█▍        | 3076/20600 [17:58:20<107:11:02, 22.02s/it] 15%|█▍        | 3077/20600 [17:58:43<108:18:15, 22.25s/it] 15%|█▍        | 3078/20600 [17:59:02<103:53:54, 21.35s/it] 15%|█▍        | 3079/20600 [17:59:26<106:56:36, 21.97s/it] 15%|█▍        | 3080/20600 [17:59:44<101:47:40, 20.92s/it]                                                           {'loss': 0.0, 'learning_rate': 4.757010043283993e-05, 'epoch': 29.69}
 15%|█▍        | 3080/20600 [17:59:44<101:47:40, 20.92s/it][INFO|trainer.py:3081] 2023-08-17 09:48:47,129 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:48:47,130 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:48:47,130 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2338, 'eval_samples_per_second': 0.968, 'eval_steps_per_second': 0.138, 'epoch': 29.69}
 15%|█▍        | 3080/20600 [17:59:51<101:47:40, 20.92s/it]
100%|██████████| 1/1 [00:06<00:00,  6.38s/it][A
                                             [A 15%|█▍        | 3081/20600 [18:00:09<107:41:24, 22.13s/it] 15%|█▍        | 3082/20600 [18:00:30<105:30:19, 21.68s/it] 15%|█▍        | 3083/20600 [18:00:46<98:13:24, 20.19s/it]  15%|█▍        | 3084/20600 [18:01:07<98:21:57, 20.22s/it] 15%|█▍        | 3085/20600 [18:01:26<96:51:56, 19.91s/it] 15%|█▍        | 3086/20600 [18:01:45<95:50:04, 19.70s/it] 15%|█▍        | 3087/20600 [18:02:07<98:51:45, 20.32s/it] 15%|█▍        | 3088/20600 [18:02:26<96:44:23, 19.89s/it] 15%|█▍        | 3089/20600 [18:02:44<94:48:28, 19.49s/it] 15%|█▌        | 3090/20600 [18:03:16<112:18:46, 23.09s/it]                                                           {'loss': 0.0, 'learning_rate': 4.7553677968652014e-05, 'epoch': 29.78}
 15%|█▌        | 3090/20600 [18:03:16<112:18:46, 23.09s/it][INFO|trainer.py:3081] 2023-08-17 09:52:18,812 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:52:18,812 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:52:18,812 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7891, 'eval_samples_per_second': 1.847, 'eval_steps_per_second': 0.264, 'epoch': 29.78}
 15%|█▌        | 3090/20600 [18:03:20<112:18:46, 23.09s/it]
100%|██████████| 1/1 [00:02<00:00,  2.94s/it][A
                                             [A 15%|█▌        | 3091/20600 [18:03:37<109:41:05, 22.55s/it] 15%|█▌        | 3092/20600 [18:03:55<102:24:30, 21.06s/it] 15%|█▌        | 3093/20600 [18:04:09<93:17:32, 19.18s/it]  15%|█▌        | 3094/20600 [18:04:34<101:43:42, 20.92s/it] 15%|█▌        | 3095/20600 [18:04:53<98:13:32, 20.20s/it]  15%|█▌        | 3096/20600 [18:05:08<90:18:52, 18.57s/it] 15%|█▌        | 3097/20600 [18:05:29<94:47:20, 19.50s/it] 15%|█▌        | 3098/20600 [18:05:46<90:58:54, 18.71s/it] 15%|█▌        | 3099/20600 [18:06:14<103:33:12, 21.30s/it] 15%|█▌        | 3100/20600 [18:06:38<108:20:44, 22.29s/it]                                                           {'loss': 0.0, 'learning_rate': 4.7537203049982944e-05, 'epoch': 29.88}
 15%|█▌        | 3100/20600 [18:06:38<108:20:44, 22.29s/it][INFO|trainer.py:3081] 2023-08-17 09:55:41,228 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:55:41,228 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:55:41,228 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.6256, 'eval_samples_per_second': 1.244, 'eval_steps_per_second': 0.178, 'epoch': 29.88}
 15%|█▌        | 3100/20600 [18:06:44<108:20:44, 22.29s/it]
100%|██████████| 1/1 [00:04<00:00,  4.78s/it][A
                                             [A 15%|█▌        | 3101/20600 [18:06:58<104:01:14, 21.40s/it] 15%|█▌        | 3102/20600 [18:07:16<100:15:42, 20.63s/it] 15%|█▌        | 3103/20600 [18:07:46<113:12:36, 23.29s/it] 15%|█▌        | 3104/20600 [18:08:01<101:23:42, 20.86s/it] 15%|█▌        | 3105/20600 [18:08:20<98:00:41, 20.17s/it]  15%|█▌        | 3106/20600 [18:08:40<98:02:54, 20.18s/it] 15%|█▌        | 3107/20600 [18:08:58<95:40:57, 19.69s/it] 15%|█▌        | 3108/20600 [18:09:24<104:53:09, 21.59s/it] 15%|█▌        | 3109/20600 [18:09:46<104:52:14, 21.58s/it] 15%|█▌        | 3110/20600 [18:10:06<102:53:39, 21.18s/it]                                                           {'loss': 0.0, 'learning_rate': 4.752067571514946e-05, 'epoch': 29.98}
 15%|█▌        | 3110/20600 [18:10:29<102:53:39, 21.18s/it][INFO|trainer.py:3081] 2023-08-17 09:59:32,351 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 09:59:32,351 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 09:59:32,352 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 1.4523, 'eval_samples_per_second': 4.82, 'eval_steps_per_second': 0.689, 'epoch': 29.98}
 15%|█▌        | 3110/20600 [18:10:31<102:53:39, 21.18s/it]
100%|██████████| 1/1 [00:00<00:00,  1.60it/s][A
                                             [A 15%|█▌        | 3111/20600 [18:10:40<121:35:28, 25.03s/it] 15%|█▌        | 3112/20600 [18:10:58<110:50:22, 22.82s/it] 15%|█▌        | 3113/20600 [18:11:13<100:12:47, 20.63s/it] 15%|█▌        | 3114/20600 [18:11:30<94:18:09, 19.41s/it]  15%|█▌        | 3115/20600 [18:11:51<96:38:38, 19.90s/it] 15%|█▌        | 3116/20600 [18:12:08<92:22:05, 19.02s/it] 15%|█▌        | 3117/20600 [18:12:25<88:53:34, 18.30s/it] 15%|█▌        | 3118/20600 [18:12:40<85:04:01, 17.52s/it] 15%|█▌        | 3119/20600 [18:13:11<104:13:06, 21.46s/it] 15%|█▌        | 3120/20600 [18:13:32<103:40:58, 21.35s/it]                                                           {'loss': 0.0, 'learning_rate': 4.750409600259021e-05, 'epoch': 30.07}
 15%|█▌        | 3120/20600 [18:13:32<103:40:58, 21.35s/it][INFO|trainer.py:3081] 2023-08-17 10:02:35,080 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:02:35,081 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:02:35,081 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3428, 'eval_samples_per_second': 0.839, 'eval_steps_per_second': 0.12, 'epoch': 30.07}
 15%|█▌        | 3120/20600 [18:13:40<103:40:58, 21.35s/it]
100%|██████████| 1/1 [00:07<00:00,  7.45s/it][A
                                             [A 15%|█▌        | 3121/20600 [18:13:59<111:39:35, 23.00s/it] 15%|█▌        | 3122/20600 [18:14:20<109:17:06, 22.51s/it] 15%|█▌        | 3123/20600 [18:14:50<120:00:01, 24.72s/it] 15%|█▌        | 3124/20600 [18:15:08<110:08:55, 22.69s/it] 15%|█▌        | 3125/20600 [18:15:31<110:29:18, 22.76s/it] 15%|█▌        | 3126/20600 [18:15:52<107:11:02, 22.08s/it] 15%|█▌        | 3127/20600 [18:16:09<100:36:14, 20.73s/it] 15%|█▌        | 3128/20600 [18:16:35<108:06:46, 22.28s/it] 15%|█▌        | 3129/20600 [18:16:52<100:54:50, 20.79s/it] 15%|█▌        | 3130/20600 [18:17:10<97:02:11, 20.00s/it]                                                           {'loss': 0.0, 'learning_rate': 4.748746395086565e-05, 'epoch': 30.17}
 15%|█▌        | 3130/20600 [18:17:10<97:02:11, 20.00s/it][INFO|trainer.py:3081] 2023-08-17 10:06:13,443 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:06:13,444 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:06:13,444 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.1688, 'eval_samples_per_second': 0.976, 'eval_steps_per_second': 0.139, 'epoch': 30.17}
 15%|█▌        | 3130/20600 [18:17:18<97:02:11, 20.00s/it]
100%|██████████| 1/1 [00:06<00:00,  6.25s/it][A
                                             [A 15%|█▌        | 3131/20600 [18:17:31<98:10:57, 20.23s/it] 15%|█▌        | 3132/20600 [18:17:49<94:47:28, 19.54s/it] 15%|█▌        | 3133/20600 [18:18:13<101:13:03, 20.86s/it] 15%|█▌        | 3134/20600 [18:18:35<102:42:51, 21.17s/it] 15%|█▌        | 3135/20600 [18:18:49<92:09:35, 19.00s/it]  15%|█▌        | 3136/20600 [18:19:16<103:58:08, 21.43s/it] 15%|█▌        | 3137/20600 [18:19:34<99:02:45, 20.42s/it]  15%|█▌        | 3138/20600 [18:19:51<93:22:02, 19.25s/it] 15%|█▌        | 3139/20600 [18:20:11<94:52:43, 19.56s/it] 15%|█▌        | 3140/20600 [18:20:31<96:02:00, 19.80s/it]                                                          {'loss': 0.0, 'learning_rate': 4.747077959865798e-05, 'epoch': 30.27}
 15%|█▌        | 3140/20600 [18:20:31<96:02:00, 19.80s/it][INFO|trainer.py:3081] 2023-08-17 10:09:34,249 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:09:34,249 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:09:34,249 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4292, 'eval_samples_per_second': 2.041, 'eval_steps_per_second': 0.292, 'epoch': 30.27}
 15%|█▌        | 3140/20600 [18:20:35<96:02:00, 19.80s/it]
100%|██████████| 1/1 [00:02<00:00,  2.54s/it][A
                                             [A 15%|█▌        | 3141/20600 [18:21:00<109:11:16, 22.51s/it] 15%|█▌        | 3142/20600 [18:21:15<98:43:10, 20.36s/it]  15%|█▌        | 3143/20600 [18:21:39<103:30:04, 21.34s/it] 15%|█▌        | 3144/20600 [18:22:00<103:35:50, 21.37s/it] 15%|█▌        | 3145/20600 [18:22:19<99:11:57, 20.46s/it]  15%|█▌        | 3146/20600 [18:22:37<95:39:31, 19.73s/it] 15%|█▌        | 3147/20600 [18:22:58<97:41:45, 20.15s/it] 15%|█▌        | 3148/20600 [18:23:13<90:06:38, 18.59s/it] 15%|█▌        | 3149/20600 [18:23:38<98:56:16, 20.41s/it] 15%|█▌        | 3150/20600 [18:23:53<91:34:14, 18.89s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7454042984771006e-05, 'epoch': 30.36}
 15%|█▌        | 3150/20600 [18:23:53<91:34:14, 18.89s/it][INFO|trainer.py:3081] 2023-08-17 10:12:55,939 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:12:55,939 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:12:55,939 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.8858, 'eval_samples_per_second': 0.888, 'eval_steps_per_second': 0.127, 'epoch': 30.36}
 15%|█▌        | 3150/20600 [18:24:01<91:34:14, 18.89s/it]
100%|██████████| 1/1 [00:06<00:00,  6.98s/it][A
                                             [A 15%|█▌        | 3151/20600 [18:24:23<107:42:13, 22.22s/it] 15%|█▌        | 3152/20600 [18:24:40<100:45:49, 20.79s/it] 15%|█▌        | 3153/20600 [18:25:02<102:24:23, 21.13s/it] 15%|█▌        | 3154/20600 [18:25:23<101:12:52, 20.89s/it] 15%|█▌        | 3155/20600 [18:25:45<103:33:10, 21.37s/it] 15%|█▌        | 3156/20600 [18:26:03<98:33:50, 20.34s/it]  15%|█▌        | 3157/20600 [18:26:19<92:14:14, 19.04s/it] 15%|█▌        | 3158/20600 [18:26:38<91:22:43, 18.86s/it] 15%|█▌        | 3159/20600 [18:26:58<93:45:59, 19.35s/it] 15%|█▌        | 3160/20600 [18:27:20<97:44:19, 20.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.743725414813012e-05, 'epoch': 30.46}
 15%|█▌        | 3160/20600 [18:27:20<97:44:19, 20.18s/it][INFO|trainer.py:3081] 2023-08-17 10:16:23,130 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:16:23,130 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:16:23,130 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4124, 'eval_samples_per_second': 0.944, 'eval_steps_per_second': 0.135, 'epoch': 30.46}
 15%|█▌        | 3160/20600 [18:27:28<97:44:19, 20.18s/it]
100%|██████████| 1/1 [00:06<00:00,  6.57s/it][A
                                             [A 15%|█▌        | 3161/20600 [18:27:43<101:04:57, 20.87s/it] 15%|█▌        | 3162/20600 [18:28:11<111:44:03, 23.07s/it] 15%|█▌        | 3163/20600 [18:28:31<108:10:01, 22.33s/it] 15%|█▌        | 3164/20600 [18:28:52<105:48:31, 21.85s/it] 15%|█▌        | 3165/20600 [18:29:12<102:59:05, 21.26s/it] 15%|█▌        | 3166/20600 [18:29:32<101:00:12, 20.86s/it] 15%|█▌        | 3167/20600 [18:29:59<109:27:33, 22.60s/it] 15%|█▌        | 3168/20600 [18:30:16<101:46:51, 21.02s/it] 15%|█▌        | 3169/20600 [18:30:35<98:34:53, 20.36s/it]  15%|█▌        | 3170/20600 [18:30:52<94:27:13, 19.51s/it]                                                          {'loss': 0.0, 'learning_rate': 4.742041312778216e-05, 'epoch': 30.55}
 15%|█▌        | 3170/20600 [18:30:52<94:27:13, 19.51s/it][INFO|trainer.py:3081] 2023-08-17 10:19:55,262 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:19:55,262 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:19:55,262 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8039, 'eval_samples_per_second': 1.84, 'eval_steps_per_second': 0.263, 'epoch': 30.55}
 15%|█▌        | 3170/20600 [18:30:56<94:27:13, 19.51s/it]
100%|██████████| 1/1 [00:02<00:00,  2.87s/it][A
                                             [A 15%|█▌        | 3171/20600 [18:31:15<98:48:42, 20.41s/it] 15%|█▌        | 3172/20600 [18:31:35<99:08:11, 20.48s/it] 15%|█▌        | 3173/20600 [18:31:53<94:18:47, 19.48s/it] 15%|█▌        | 3174/20600 [18:32:15<98:12:20, 20.29s/it] 15%|█▌        | 3175/20600 [18:32:39<103:39:52, 21.42s/it] 15%|█▌        | 3176/20600 [18:33:05<110:09:59, 22.76s/it] 15%|█▌        | 3177/20600 [18:33:25<105:53:40, 21.88s/it] 15%|█▌        | 3178/20600 [18:33:43<101:39:44, 21.01s/it] 15%|█▌        | 3179/20600 [18:34:03<99:22:56, 20.54s/it]  15%|█▌        | 3180/20600 [18:34:21<95:44:40, 19.79s/it]                                                          {'loss': 0.0, 'learning_rate': 4.740351996289532e-05, 'epoch': 30.65}
 15%|█▌        | 3180/20600 [18:34:21<95:44:40, 19.79s/it][INFO|trainer.py:3081] 2023-08-17 10:23:23,966 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:23:23,966 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:23:23,966 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.7933, 'eval_samples_per_second': 1.03, 'eval_steps_per_second': 0.147, 'epoch': 30.65}
 15%|█▌        | 3180/20600 [18:34:28<95:44:40, 19.79s/it]
100%|██████████| 1/1 [00:05<00:00,  5.91s/it][A
                                             [A 15%|█▌        | 3181/20600 [18:34:46<103:03:10, 21.30s/it] 15%|█▌        | 3182/20600 [18:35:07<103:32:55, 21.40s/it] 15%|█▌        | 3183/20600 [18:35:26<99:59:31, 20.67s/it]  15%|█▌        | 3184/20600 [18:35:51<105:49:34, 21.87s/it] 15%|█▌        | 3185/20600 [18:36:09<100:16:14, 20.73s/it] 15%|█▌        | 3186/20600 [18:36:30<99:52:30, 20.65s/it]  15%|█▌        | 3187/20600 [18:36:46<94:08:29, 19.46s/it] 15%|█▌        | 3188/20600 [18:37:07<95:33:32, 19.76s/it] 15%|█▌        | 3189/20600 [18:37:32<103:37:55, 21.43s/it] 15%|█▌        | 3190/20600 [18:37:50<99:10:29, 20.51s/it]                                                           {'loss': 0.0, 'learning_rate': 4.738657469275907e-05, 'epoch': 30.75}
 15%|█▌        | 3190/20600 [18:37:50<99:10:29, 20.51s/it][INFO|trainer.py:3081] 2023-08-17 10:26:53,425 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:26:53,425 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:26:53,425 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3601, 'eval_samples_per_second': 1.101, 'eval_steps_per_second': 0.157, 'epoch': 30.75}
 15%|█▌        | 3190/20600 [18:37:57<99:10:29, 20.51s/it]
100%|██████████| 1/1 [00:05<00:00,  5.49s/it][A
                                             [A 15%|█▌        | 3191/20600 [18:38:15<104:49:12, 21.68s/it] 15%|█▌        | 3192/20600 [18:38:36<104:26:58, 21.60s/it] 16%|█▌        | 3193/20600 [18:38:54<99:00:41, 20.48s/it]  16%|█▌        | 3194/20600 [18:39:12<95:19:53, 19.72s/it] 16%|█▌        | 3195/20600 [18:39:37<102:41:04, 21.24s/it] 16%|█▌        | 3196/20600 [18:39:57<101:31:29, 21.00s/it] 16%|█▌        | 3197/20600 [18:40:22<107:28:05, 22.23s/it] 16%|█▌        | 3198/20600 [18:40:41<101:40:57, 21.04s/it] 16%|█▌        | 3199/20600 [18:40:57<94:22:06, 19.52s/it]  16%|█▌        | 3200/20600 [18:41:14<91:17:11, 18.89s/it]                                                          {'loss': 0.0, 'learning_rate': 4.736957735678407e-05, 'epoch': 30.84}
 16%|█▌        | 3200/20600 [18:41:14<91:17:11, 18.89s/it][INFO|trainer.py:3081] 2023-08-17 10:30:17,025 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:30:17,026 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:30:17,026 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.0617, 'eval_samples_per_second': 1.155, 'eval_steps_per_second': 0.165, 'epoch': 30.84}
 16%|█▌        | 3200/20600 [18:41:20<91:17:11, 18.89s/it]
100%|██████████| 1/1 [00:05<00:00,  5.14s/it][A
                                             [A08/17/2023 10:30:23 - INFO - llmtuner.tuner.core.trainer - Saving model checkpoint to ../outputs/Ihin/Ihin-sft-llama2/checkpoint-3200
 16%|█▌        | 3201/20600 [18:41:37<97:48:36, 20.24s/it] 16%|█▌        | 3202/20600 [18:41:53<91:03:12, 18.84s/it] 16%|█▌        | 3203/20600 [18:42:19<101:25:25, 20.99s/it] 16%|█▌        | 3204/20600 [18:42:36<95:06:12, 19.68s/it]  16%|█▌        | 3205/20600 [18:42:58<99:33:16, 20.60s/it] 16%|█▌        | 3206/20600 [18:43:15<93:04:05, 19.26s/it] 16%|█▌        | 3207/20600 [18:43:32<91:02:09, 18.84s/it] 16%|█▌        | 3208/20600 [18:44:00<104:00:55, 21.53s/it] 16%|█▌        | 3209/20600 [18:44:15<94:05:45, 19.48s/it]  16%|█▌        | 3210/20600 [18:44:33<92:03:24, 19.06s/it]                                                          {'loss': 0.0, 'learning_rate': 4.735252799450209e-05, 'epoch': 30.94}
 16%|█▌        | 3210/20600 [18:44:33<92:03:24, 19.06s/it][INFO|trainer.py:3081] 2023-08-17 10:33:35,944 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:33:35,944 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:33:35,944 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2748, 'eval_samples_per_second': 0.962, 'eval_steps_per_second': 0.137, 'epoch': 30.94}
 16%|█▌        | 3210/20600 [18:44:40<92:03:24, 19.06s/it]
100%|██████████| 1/1 [00:06<00:00,  6.40s/it][A
                                             [A 16%|█▌        | 3211/20600 [18:45:02<107:11:01, 22.19s/it] 16%|█▌        | 3212/20600 [18:45:18<97:28:54, 20.18s/it]  16%|█▌        | 3213/20600 [18:45:36<94:10:53, 19.50s/it] 16%|█▌        | 3214/20600 [18:45:58<98:31:14, 20.40s/it] 16%|█▌        | 3215/20600 [18:46:16<94:37:32, 19.59s/it] 16%|█▌        | 3216/20600 [18:46:37<96:16:06, 19.94s/it] 16%|█▌        | 3217/20600 [18:46:55<93:11:48, 19.30s/it] 16%|█▌        | 3218/20600 [18:47:13<92:04:04, 19.07s/it] 16%|█▌        | 3219/20600 [18:47:33<93:24:02, 19.35s/it] 16%|█▌        | 3220/20600 [18:47:56<98:20:40, 20.37s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7335426645565875e-05, 'epoch': 31.04}
 16%|█▌        | 3220/20600 [18:47:56<98:20:40, 20.37s/it][INFO|trainer.py:3081] 2023-08-17 10:36:58,877 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:36:58,878 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:36:58,878 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0535, 'eval_samples_per_second': 0.992, 'eval_steps_per_second': 0.142, 'epoch': 31.04}
 16%|█▌        | 3220/20600 [18:48:03<98:20:40, 20.37s/it]
100%|██████████| 1/1 [00:06<00:00,  6.16s/it][A
                                             [A 16%|█▌        | 3221/20600 [18:48:20<104:26:16, 21.63s/it] 16%|█▌        | 3222/20600 [18:48:40<100:53:54, 20.90s/it] 16%|█▌        | 3223/20600 [18:48:56<94:50:14, 19.65s/it]  16%|█▌        | 3224/20600 [18:49:13<90:14:37, 18.70s/it] 16%|█▌        | 3225/20600 [18:49:31<88:59:03, 18.44s/it] 16%|█▌        | 3226/20600 [18:49:52<92:41:27, 19.21s/it] 16%|█▌        | 3227/20600 [18:50:10<91:50:57, 19.03s/it] 16%|█▌        | 3228/20600 [18:50:29<91:39:40, 18.99s/it] 16%|█▌        | 3229/20600 [18:50:51<95:00:49, 19.69s/it] 16%|█▌        | 3230/20600 [18:51:08<91:38:19, 18.99s/it]                                                          {'loss': 0.0, 'learning_rate': 4.731827334974909e-05, 'epoch': 31.13}
 16%|█▌        | 3230/20600 [18:51:08<91:38:19, 18.99s/it][INFO|trainer.py:3081] 2023-08-17 10:40:10,914 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:40:10,914 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:40:10,914 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.2809, 'eval_samples_per_second': 1.326, 'eval_steps_per_second': 0.189, 'epoch': 31.13}
 16%|█▌        | 3230/20600 [18:51:13<91:38:19, 18.99s/it]
100%|██████████| 1/1 [00:04<00:00,  4.43s/it][A
                                             [A 16%|█▌        | 3231/20600 [18:51:29<94:11:14, 19.52s/it] 16%|█▌        | 3232/20600 [18:51:46<90:32:49, 18.77s/it] 16%|█▌        | 3233/20600 [18:52:02<87:41:42, 18.18s/it] 16%|█▌        | 3234/20600 [18:52:26<95:31:55, 19.80s/it] 16%|█▌        | 3235/20600 [18:52:45<93:31:58, 19.39s/it] 16%|█▌        | 3236/20600 [18:53:05<94:37:53, 19.62s/it] 16%|█▌        | 3237/20600 [18:53:28<99:19:24, 20.59s/it] 16%|█▌        | 3238/20600 [18:53:50<102:01:04, 21.15s/it] 16%|█▌        | 3239/20600 [18:54:07<95:39:07, 19.83s/it]  16%|█▌        | 3240/20600 [18:54:28<98:15:28, 20.38s/it]                                                          {'loss': 0.0, 'learning_rate': 4.73010681469462e-05, 'epoch': 31.23}
 16%|█▌        | 3240/20600 [18:54:28<98:15:28, 20.38s/it][INFO|trainer.py:3081] 2023-08-17 10:43:31,387 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:43:31,387 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:43:31,387 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.4182, 'eval_samples_per_second': 0.832, 'eval_steps_per_second': 0.119, 'epoch': 31.23}
 16%|█▌        | 3240/20600 [18:54:37<98:15:28, 20.38s/it]
100%|██████████| 1/1 [00:07<00:00,  7.59s/it][A
                                             [A 16%|█▌        | 3241/20600 [18:54:53<105:05:22, 21.79s/it] 16%|█▌        | 3242/20600 [18:55:19<109:52:25, 22.79s/it] 16%|█▌        | 3243/20600 [18:55:36<101:36:46, 21.08s/it] 16%|█▌        | 3244/20600 [18:55:58<103:27:38, 21.46s/it] 16%|█▌        | 3245/20600 [18:56:17<100:25:41, 20.83s/it] 16%|█▌        | 3246/20600 [18:56:33<92:51:18, 19.26s/it]  16%|█▌        | 3247/20600 [18:56:52<92:23:19, 19.17s/it] 16%|█▌        | 3248/20600 [18:57:13<95:46:40, 19.87s/it] 16%|█▌        | 3249/20600 [18:57:33<95:13:07, 19.76s/it] 16%|█▌        | 3250/20600 [18:57:55<98:38:40, 20.47s/it]                                                          {'loss': 0.0, 'learning_rate': 4.728381107717243e-05, 'epoch': 31.33}
 16%|█▌        | 3250/20600 [18:57:55<98:38:40, 20.47s/it][INFO|trainer.py:3081] 2023-08-17 10:46:58,078 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:46:58,078 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:46:58,078 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.3054, 'eval_samples_per_second': 2.118, 'eval_steps_per_second': 0.303, 'epoch': 31.33}
 16%|█▌        | 3250/20600 [18:57:58<98:38:40, 20.47s/it]
100%|██████████| 1/1 [00:02<00:00,  2.43s/it][A
                                             [A 16%|█▌        | 3251/20600 [18:58:16<99:16:50, 20.60s/it] 16%|█▌        | 3252/20600 [18:58:43<109:14:10, 22.67s/it] 16%|█▌        | 3253/20600 [18:59:07<110:41:56, 22.97s/it] 16%|█▌        | 3254/20600 [18:59:25<103:53:14, 21.56s/it] 16%|█▌        | 3255/20600 [18:59:43<98:12:40, 20.38s/it]  16%|█▌        | 3256/20600 [18:59:59<91:15:22, 18.94s/it] 16%|█▌        | 3257/20600 [19:00:18<91:08:39, 18.92s/it] 16%|█▌        | 3258/20600 [19:00:34<87:53:30, 18.25s/it] 16%|█▌        | 3259/20600 [19:00:51<85:24:29, 17.73s/it] 16%|█▌        | 3260/20600 [19:01:10<87:16:10, 18.12s/it]                                                          {'loss': 0.0, 'learning_rate': 4.72665021805636e-05, 'epoch': 31.42}
 16%|█▌        | 3260/20600 [19:01:10<87:16:10, 18.12s/it][INFO|trainer.py:3081] 2023-08-17 10:50:12,733 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:50:12,733 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:50:12,733 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9881, 'eval_samples_per_second': 1.755, 'eval_steps_per_second': 0.251, 'epoch': 31.42}
 16%|█▌        | 3260/20600 [19:01:14<87:16:10, 18.12s/it]
100%|██████████| 1/1 [00:03<00:00,  3.07s/it][A
                                             [A 16%|█▌        | 3261/20600 [19:01:38<101:34:55, 21.09s/it] 16%|█▌        | 3262/20600 [19:01:57<99:20:21, 20.63s/it]  16%|█▌        | 3263/20600 [19:02:17<98:29:26, 20.45s/it] 16%|█▌        | 3264/20600 [19:02:45<109:25:42, 22.72s/it] 16%|█▌        | 3265/20600 [19:03:07<107:25:13, 22.31s/it] 16%|█▌        | 3266/20600 [19:03:22<97:23:08, 20.23s/it]  16%|█▌        | 3267/20600 [19:03:41<94:54:11, 19.71s/it] 16%|█▌        | 3268/20600 [19:03:59<93:00:16, 19.32s/it] 16%|█▌        | 3269/20600 [19:04:17<91:33:56, 19.02s/it] 16%|█▌        | 3270/20600 [19:04:34<88:50:32, 18.46s/it]                                                          {'loss': 0.0, 'learning_rate': 4.724914149737608e-05, 'epoch': 31.52}
 16%|█▌        | 3270/20600 [19:04:34<88:50:32, 18.46s/it][INFO|trainer.py:3081] 2023-08-17 10:53:37,466 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:53:37,466 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:53:37,466 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9281, 'eval_samples_per_second': 1.782, 'eval_steps_per_second': 0.255, 'epoch': 31.52}
 16%|█▌        | 3270/20600 [19:04:38<88:50:32, 18.46s/it]
100%|██████████| 1/1 [00:03<00:00,  3.03s/it][A
                                             [A 16%|█▌        | 3271/20600 [19:05:01<100:42:35, 20.92s/it] 16%|█▌        | 3272/20600 [19:05:20<98:08:06, 20.39s/it]  16%|█▌        | 3273/20600 [19:05:37<92:15:54, 19.17s/it] 16%|█▌        | 3274/20600 [19:06:00<97:46:50, 20.32s/it] 16%|█▌        | 3275/20600 [19:06:15<90:42:39, 18.85s/it] 16%|█▌        | 3276/20600 [19:06:35<91:39:51, 19.05s/it] 16%|█▌        | 3277/20600 [19:06:57<96:20:27, 20.02s/it] 16%|█▌        | 3278/20600 [19:07:15<93:04:53, 19.34s/it] 16%|█▌        | 3279/20600 [19:07:30<86:42:27, 18.02s/it] 16%|█▌        | 3280/20600 [19:07:46<84:51:32, 17.64s/it]                                                          {'loss': 0.0, 'learning_rate': 4.723172906798668e-05, 'epoch': 31.61}
 16%|█▌        | 3280/20600 [19:07:46<84:51:32, 17.64s/it][INFO|trainer.py:3081] 2023-08-17 10:56:49,269 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 10:56:49,269 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 10:56:49,269 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.557, 'eval_samples_per_second': 1.26, 'eval_steps_per_second': 0.18, 'epoch': 31.61}
 16%|█▌        | 3280/20600 [19:07:52<84:51:32, 17.64s/it]
100%|██████████| 1/1 [00:04<00:00,  4.62s/it][A
                                             [A 16%|█▌        | 3281/20600 [19:08:13<97:32:47, 20.28s/it] 16%|█▌        | 3282/20600 [19:08:29<92:18:49, 19.19s/it] 16%|█▌        | 3283/20600 [19:08:46<88:12:24, 18.34s/it] 16%|█▌        | 3284/20600 [19:09:10<96:53:45, 20.14s/it] 16%|█▌        | 3285/20600 [19:09:27<91:47:23, 19.08s/it] 16%|█▌        | 3286/20600 [19:09:47<93:59:26, 19.54s/it] 16%|█▌        | 3287/20600 [19:10:05<91:04:08, 18.94s/it] 16%|█▌        | 3288/20600 [19:10:29<98:20:36, 20.45s/it] 16%|█▌        | 3289/20600 [19:10:53<103:51:23, 21.60s/it] 16%|█▌        | 3290/20600 [19:11:10<97:32:26, 20.29s/it]                                                           {'loss': 0.0, 'learning_rate': 4.721426493289257e-05, 'epoch': 31.71}
 16%|█▌        | 3290/20600 [19:11:10<97:32:26, 20.29s/it][INFO|trainer.py:3081] 2023-08-17 11:00:13,285 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:00:13,285 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:00:13,286 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3022, 'eval_samples_per_second': 1.111, 'eval_steps_per_second': 0.159, 'epoch': 31.71}
 16%|█▌        | 3290/20600 [19:11:17<97:32:26, 20.29s/it]
100%|██████████| 1/1 [00:05<00:00,  5.40s/it][A
                                             [A 16%|█▌        | 3291/20600 [19:11:36<105:47:32, 22.00s/it] 16%|█▌        | 3292/20600 [19:11:54<99:07:51, 20.62s/it]  16%|█▌        | 3293/20600 [19:12:19<106:13:21, 22.10s/it] 16%|█▌        | 3294/20600 [19:12:41<105:33:48, 21.96s/it] 16%|█▌        | 3295/20600 [19:13:00<102:11:15, 21.26s/it] 16%|█▌        | 3296/20600 [19:13:24<105:39:05, 21.98s/it] 16%|█▌        | 3297/20600 [19:13:47<107:15:54, 22.32s/it] 16%|█▌        | 3298/20600 [19:14:02<96:38:14, 20.11s/it]  16%|█▌        | 3299/20600 [19:14:21<94:50:09, 19.73s/it] 16%|█▌        | 3300/20600 [19:14:42<97:06:56, 20.21s/it]                                                          {'loss': 0.0, 'learning_rate': 4.719674913271116e-05, 'epoch': 31.81}
 16%|█▌        | 3300/20600 [19:14:42<97:06:56, 20.21s/it][INFO|trainer.py:3081] 2023-08-17 11:03:45,369 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:03:45,369 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:03:45,369 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.4652, 'eval_samples_per_second': 0.938, 'eval_steps_per_second': 0.134, 'epoch': 31.81}
 16%|█▌        | 3300/20600 [19:14:50<97:06:56, 20.21s/it]
100%|██████████| 1/1 [00:06<00:00,  6.59s/it][A
                                             [A 16%|█▌        | 3301/20600 [19:15:07<103:37:34, 21.57s/it] 16%|█▌        | 3302/20600 [19:15:25<98:37:34, 20.53s/it]  16%|█▌        | 3303/20600 [19:15:43<94:02:08, 19.57s/it] 16%|█▌        | 3304/20600 [19:16:00<91:27:46, 19.04s/it] 16%|█▌        | 3305/20600 [19:16:23<97:01:39, 20.20s/it] 16%|█▌        | 3306/20600 [19:16:42<94:31:08, 19.68s/it] 16%|█▌        | 3307/20600 [19:16:59<90:20:46, 18.81s/it] 16%|█▌        | 3308/20600 [19:17:19<93:04:49, 19.38s/it] 16%|█▌        | 3309/20600 [19:17:37<91:28:39, 19.05s/it] 16%|█▌        | 3310/20600 [19:17:55<88:54:38, 18.51s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7179181708180034e-05, 'epoch': 31.9}
 16%|█▌        | 3310/20600 [19:17:55<88:54:38, 18.51s/it][INFO|trainer.py:3081] 2023-08-17 11:06:57,746 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:06:57,746 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:06:57,746 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.7656, 'eval_samples_per_second': 1.214, 'eval_steps_per_second': 0.173, 'epoch': 31.9}
 16%|█▌        | 3310/20600 [19:18:01<88:54:38, 18.51s/it]
100%|██████████| 1/1 [00:04<00:00,  4.86s/it][A
                                             [A 16%|█▌        | 3311/20600 [19:18:21<100:29:49, 20.93s/it] 16%|█▌        | 3312/20600 [19:18:41<98:50:25, 20.58s/it]  16%|█▌        | 3313/20600 [19:19:02<99:42:43, 20.76s/it] 16%|█▌        | 3314/20600 [19:19:21<96:33:45, 20.11s/it] 16%|█▌        | 3315/20600 [19:19:40<95:27:32, 19.88s/it] 16%|█▌        | 3316/20600 [19:19:58<91:47:01, 19.12s/it] 16%|█▌        | 3317/20600 [19:20:20<95:56:00, 19.98s/it] 16%|█▌        | 3318/20600 [19:20:40<97:15:43, 20.26s/it] 16%|█▌        | 3319/20600 [19:21:00<96:27:56, 20.10s/it] 16%|█▌        | 3320/20600 [19:21:22<98:41:40, 20.56s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7161562700156826e-05, 'epoch': 32.0}
 16%|█▌        | 3320/20600 [19:21:22<98:41:40, 20.56s/it][INFO|trainer.py:3081] 2023-08-17 11:10:24,811 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:10:24,811 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:10:24,812 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.156, 'eval_samples_per_second': 1.358, 'eval_steps_per_second': 0.194, 'epoch': 32.0}
 16%|█▌        | 3320/20600 [19:21:27<98:41:40, 20.56s/it]
100%|██████████| 1/1 [00:04<00:00,  4.28s/it][A
                                             [A 16%|█▌        | 3321/20600 [19:21:48<106:17:29, 22.15s/it] 16%|█▌        | 3322/20600 [19:22:05<98:43:17, 20.57s/it]  16%|█▌        | 3323/20600 [19:22:23<95:47:37, 19.96s/it] 16%|█▌        | 3324/20600 [19:22:40<91:50:35, 19.14s/it] 16%|█▌        | 3325/20600 [19:22:59<91:53:05, 19.15s/it] 16%|█▌        | 3326/20600 [19:23:20<93:17:49, 19.44s/it] 16%|█▌        | 3327/20600 [19:23:36<88:45:35, 18.50s/it] 16%|█▌        | 3328/20600 [19:23:54<88:43:49, 18.49s/it] 16%|█▌        | 3329/20600 [19:24:23<102:58:01, 21.46s/it] 16%|█▌        | 3330/20600 [19:24:43<101:42:32, 21.20s/it]                                                           {'loss': 0.0, 'learning_rate': 4.7143892149619154e-05, 'epoch': 32.1}
 16%|█▌        | 3330/20600 [19:24:43<101:42:32, 21.20s/it][INFO|trainer.py:3081] 2023-08-17 11:13:46,371 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:13:46,371 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:13:46,371 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.5877, 'eval_samples_per_second': 1.253, 'eval_steps_per_second': 0.179, 'epoch': 32.1}
 16%|█▌        | 3330/20600 [19:24:49<101:42:32, 21.20s/it]
100%|██████████| 1/1 [00:04<00:00,  4.70s/it][A
                                             [A 16%|█▌        | 3331/20600 [19:25:11<111:14:56, 23.19s/it] 16%|█▌        | 3332/20600 [19:25:34<111:09:52, 23.18s/it] 16%|█▌        | 3333/20600 [19:25:56<109:39:16, 22.86s/it] 16%|█▌        | 3334/20600 [19:26:15<103:48:44, 21.65s/it] 16%|█▌        | 3335/20600 [19:26:36<102:28:31, 21.37s/it] 16%|█▌        | 3336/20600 [19:26:56<100:03:33, 20.86s/it] 16%|█▌        | 3337/20600 [19:27:13<95:33:06, 19.93s/it]  16%|█▌        | 3338/20600 [19:27:36<99:06:38, 20.67s/it] 16%|█▌        | 3339/20600 [19:27:55<96:49:27, 20.19s/it] 16%|█▌        | 3340/20600 [19:28:11<91:15:15, 19.03s/it]                                                          {'loss': 0.0, 'learning_rate': 4.712617009766452e-05, 'epoch': 32.19}
 16%|█▌        | 3340/20600 [19:28:11<91:15:15, 19.03s/it][INFO|trainer.py:3081] 2023-08-17 11:17:14,250 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:17:14,250 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:17:14,250 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.81, 'eval_samples_per_second': 1.205, 'eval_steps_per_second': 0.172, 'epoch': 32.19}
 16%|█▌        | 3340/20600 [19:28:17<91:15:15, 19.03s/it]
100%|██████████| 1/1 [00:04<00:00,  4.99s/it][A
                                             [A 16%|█▌        | 3341/20600 [19:28:35<98:23:59, 20.52s/it] 16%|█▌        | 3342/20600 [19:28:57<100:23:24, 20.94s/it] 16%|█▌        | 3343/20600 [19:29:18<99:41:50, 20.80s/it]  16%|█▌        | 3344/20600 [19:29:36<96:06:23, 20.05s/it] 16%|█▌        | 3345/20600 [19:29:59<101:01:21, 21.08s/it] 16%|█▌        | 3346/20600 [19:30:16<94:19:27, 19.68s/it]  16%|█▌        | 3347/20600 [19:30:33<90:43:02, 18.93s/it] 16%|█▋        | 3348/20600 [19:30:55<95:41:47, 19.97s/it] 16%|█▋        | 3349/20600 [19:31:14<93:49:19, 19.58s/it] 16%|█▋        | 3350/20600 [19:31:36<96:37:17, 20.16s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7108396585510177e-05, 'epoch': 32.29}
 16%|█▋        | 3350/20600 [19:31:36<96:37:17, 20.16s/it][INFO|trainer.py:3081] 2023-08-17 11:20:38,593 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:20:38,593 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:20:38,593 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.8857, 'eval_samples_per_second': 1.189, 'eval_steps_per_second': 0.17, 'epoch': 32.29}
 16%|█▋        | 3350/20600 [19:31:42<96:37:17, 20.16s/it]
100%|██████████| 1/1 [00:05<00:00,  5.02s/it][A
                                             [A 16%|█▋        | 3351/20600 [19:31:57<98:05:38, 20.47s/it] 16%|█▋        | 3352/20600 [19:32:20<101:22:17, 21.16s/it] 16%|█▋        | 3353/20600 [19:32:40<100:14:13, 20.92s/it] 16%|█▋        | 3354/20600 [19:32:59<97:28:54, 20.35s/it]  16%|█▋        | 3355/20600 [19:33:17<94:54:57, 19.81s/it] 16%|█▋        | 3356/20600 [19:33:33<88:26:19, 18.46s/it] 16%|█▋        | 3357/20600 [19:34:00<100:15:56, 20.93s/it] 16%|█▋        | 3358/20600 [19:34:28<110:46:03, 23.13s/it] 16%|█▋        | 3359/20600 [19:34:47<104:41:56, 21.86s/it] 16%|█▋        | 3360/20600 [19:35:05<100:11:01, 20.92s/it]                                                           {'loss': 0.0, 'learning_rate': 4.7090571654493095e-05, 'epoch': 32.39}
 16%|█▋        | 3360/20600 [19:35:05<100:11:01, 20.92s/it][INFO|trainer.py:3081] 2023-08-17 11:24:08,382 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:24:08,383 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:24:08,383 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.899, 'eval_samples_per_second': 1.795, 'eval_steps_per_second': 0.256, 'epoch': 32.39}
 16%|█▋        | 3360/20600 [19:35:09<100:11:01, 20.92s/it]
100%|██████████| 1/1 [00:03<00:00,  3.06s/it][A
                                             [A 16%|█▋        | 3361/20600 [19:35:27<100:44:43, 21.04s/it] 16%|█▋        | 3362/20600 [19:35:49<103:12:50, 21.56s/it] 16%|█▋        | 3363/20600 [19:36:15<108:59:14, 22.76s/it] 16%|█▋        | 3364/20600 [19:36:41<114:04:53, 23.83s/it] 16%|█▋        | 3365/20600 [19:37:00<106:35:06, 22.26s/it] 16%|█▋        | 3366/20600 [19:37:19<101:20:40, 21.17s/it] 16%|█▋        | 3367/20600 [19:37:37<96:56:44, 20.25s/it]  16%|█▋        | 3368/20600 [19:37:57<97:12:19, 20.31s/it] 16%|█▋        | 3369/20600 [19:38:17<95:53:47, 20.04s/it] 16%|█▋        | 3370/20600 [19:38:32<89:53:30, 18.78s/it]                                                          {'loss': 0.0, 'learning_rate': 4.7072695346069805e-05, 'epoch': 32.48}
 16%|█▋        | 3370/20600 [19:38:32<89:53:30, 18.78s/it][INFO|trainer.py:3081] 2023-08-17 11:27:35,401 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:27:35,401 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:27:35,401 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0494, 'eval_samples_per_second': 1.729, 'eval_steps_per_second': 0.247, 'epoch': 32.48}
 16%|█▋        | 3370/20600 [19:38:36<89:53:30, 18.78s/it]
100%|██████████| 1/1 [00:03<00:00,  3.16s/it][A
                                             [A 16%|█▋        | 3371/20600 [19:38:56<96:56:23, 20.26s/it] 16%|█▋        | 3372/20600 [19:39:14<93:00:00, 19.43s/it] 16%|█▋        | 3373/20600 [19:39:32<91:27:30, 19.11s/it] 16%|█▋        | 3374/20600 [19:39:52<92:20:22, 19.30s/it] 16%|█▋        | 3375/20600 [19:40:17<101:18:22, 21.17s/it] 16%|█▋        | 3376/20600 [19:40:39<101:38:42, 21.24s/it] 16%|█▋        | 3377/20600 [19:40:53<92:19:34, 19.30s/it]  16%|█▋        | 3378/20600 [19:41:17<98:39:24, 20.62s/it] 16%|█▋        | 3379/20600 [19:41:35<94:46:26, 19.81s/it] 16%|█▋        | 3380/20600 [19:41:57<97:27:25, 20.37s/it]                                                          {'loss': 0.0, 'learning_rate': 4.705476770181634e-05, 'epoch': 32.58}
 16%|█▋        | 3380/20600 [19:41:57<97:27:25, 20.37s/it][INFO|trainer.py:3081] 2023-08-17 11:30:59,726 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:30:59,726 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:30:59,726 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.816, 'eval_samples_per_second': 1.834, 'eval_steps_per_second': 0.262, 'epoch': 32.58}
 16%|█▋        | 3380/20600 [19:42:01<97:27:25, 20.37s/it]
100%|██████████| 1/1 [00:02<00:00,  2.91s/it][A
                                             [A 16%|█▋        | 3381/20600 [19:42:17<97:07:39, 20.31s/it] 16%|█▋        | 3382/20600 [19:42:34<92:21:41, 19.31s/it] 16%|█▋        | 3383/20600 [19:42:57<97:17:25, 20.34s/it] 16%|█▋        | 3384/20600 [19:43:14<93:07:10, 19.47s/it] 16%|█▋        | 3385/20600 [19:43:32<91:00:18, 19.03s/it] 16%|█▋        | 3386/20600 [19:43:55<96:49:37, 20.25s/it] 16%|█▋        | 3387/20600 [19:44:13<93:43:16, 19.60s/it] 16%|█▋        | 3388/20600 [19:44:34<95:18:07, 19.93s/it] 16%|█▋        | 3389/20600 [19:44:53<94:42:02, 19.81s/it] 16%|█▋        | 3390/20600 [19:45:10<90:02:45, 18.84s/it]                                                          {'loss': 0.0, 'learning_rate': 4.703678876342814e-05, 'epoch': 32.67}
 16%|█▋        | 3390/20600 [19:45:10<90:02:45, 18.84s/it][INFO|trainer.py:3081] 2023-08-17 11:34:13,019 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:34:13,020 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:34:13,020 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.7146, 'eval_samples_per_second': 0.907, 'eval_steps_per_second': 0.13, 'epoch': 32.67}
 16%|█▋        | 3390/20600 [19:45:18<90:02:45, 18.84s/it]
100%|██████████| 1/1 [00:06<00:00,  6.86s/it][A
                                             [A 16%|█▋        | 3391/20600 [19:45:40<105:41:40, 22.11s/it] 16%|█▋        | 3392/20600 [19:46:04<108:37:00, 22.72s/it] 16%|█▋        | 3393/20600 [19:46:22<102:28:55, 21.44s/it] 16%|█▋        | 3394/20600 [19:46:45<103:29:06, 21.65s/it] 16%|█▋        | 3395/20600 [19:47:03<99:33:22, 20.83s/it]  16%|█▋        | 3396/20600 [19:47:24<99:43:29, 20.87s/it] 16%|█▋        | 3397/20600 [19:47:44<97:22:20, 20.38s/it] 16%|█▋        | 3398/20600 [19:48:04<98:03:27, 20.52s/it] 16%|█▋        | 3399/20600 [19:48:22<93:58:07, 19.67s/it] 17%|█▋        | 3400/20600 [19:48:39<90:27:31, 18.93s/it]                                                          {'loss': 0.0, 'learning_rate': 4.701875857271993e-05, 'epoch': 32.77}
 17%|█▋        | 3400/20600 [19:48:39<90:27:31, 18.93s/it][INFO|trainer.py:3081] 2023-08-17 11:37:42,376 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:37:42,377 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:37:42,377 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3417, 'eval_samples_per_second': 0.953, 'eval_steps_per_second': 0.136, 'epoch': 32.77}
 17%|█▋        | 3400/20600 [19:48:47<90:27:31, 18.93s/it]
100%|██████████| 1/1 [00:06<00:00,  6.46s/it][A
                                             [A 17%|█▋        | 3401/20600 [19:49:04<99:03:08, 20.73s/it] 17%|█▋        | 3402/20600 [19:49:21<93:40:42, 19.61s/it] 17%|█▋        | 3403/20600 [19:49:41<93:27:56, 19.57s/it] 17%|█▋        | 3404/20600 [19:50:00<93:11:32, 19.51s/it] 17%|█▋        | 3405/20600 [19:50:18<91:14:56, 19.10s/it] 17%|█▋        | 3406/20600 [19:50:48<106:59:54, 22.40s/it] 17%|█▋        | 3407/20600 [19:51:06<99:49:07, 20.90s/it]  17%|█▋        | 3408/20600 [19:51:26<99:14:56, 20.78s/it] 17%|█▋        | 3409/20600 [19:51:51<104:32:27, 21.89s/it] 17%|█▋        | 3410/20600 [19:52:08<98:12:46, 20.57s/it]                                                           {'loss': 0.0, 'learning_rate': 4.700067717162563e-05, 'epoch': 32.87}
 17%|█▋        | 3410/20600 [19:52:08<98:12:46, 20.57s/it][INFO|trainer.py:3081] 2023-08-17 11:41:11,267 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:41:11,267 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:41:11,267 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.8112, 'eval_samples_per_second': 1.455, 'eval_steps_per_second': 0.208, 'epoch': 32.87}
 17%|█▋        | 3410/20600 [19:52:13<98:12:46, 20.57s/it]
100%|██████████| 1/1 [00:03<00:00,  3.92s/it][A
                                             [A 17%|█▋        | 3411/20600 [19:52:36<108:11:52, 22.66s/it] 17%|█▋        | 3412/20600 [19:52:56<104:27:02, 21.88s/it] 17%|█▋        | 3413/20600 [19:53:16<102:39:16, 21.50s/it] 17%|█▋        | 3414/20600 [19:53:35<98:53:43, 20.72s/it]  17%|█▋        | 3415/20600 [19:53:55<97:25:14, 20.41s/it] 17%|█▋        | 3416/20600 [19:54:12<92:53:22, 19.46s/it] 17%|█▋        | 3417/20600 [19:54:29<89:33:39, 18.76s/it] 17%|█▋        | 3418/20600 [19:54:48<88:34:21, 18.56s/it] 17%|█▋        | 3419/20600 [19:55:08<91:04:39, 19.08s/it] 17%|█▋        | 3420/20600 [19:55:24<86:13:26, 18.07s/it]                                                          {'loss': 0.0, 'learning_rate': 4.698254460219827e-05, 'epoch': 32.96}
 17%|█▋        | 3420/20600 [19:55:24<86:13:26, 18.07s/it][INFO|trainer.py:3081] 2023-08-17 11:44:26,520 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:44:26,520 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:44:26,520 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0058, 'eval_samples_per_second': 1.747, 'eval_steps_per_second': 0.25, 'epoch': 32.96}
 17%|█▋        | 3420/20600 [19:55:28<86:13:26, 18.07s/it]
100%|██████████| 1/1 [00:03<00:00,  3.13s/it][A
                                             [A 17%|█▋        | 3421/20600 [19:55:52<100:38:46, 21.09s/it] 17%|█▋        | 3422/20600 [19:56:07<92:41:47, 19.43s/it]  17%|█▋        | 3423/20600 [19:56:26<91:55:10, 19.26s/it] 17%|█▋        | 3424/20600 [19:56:44<90:23:22, 18.95s/it] 17%|█▋        | 3425/20600 [19:57:04<91:42:44, 19.22s/it] 17%|█▋        | 3426/20600 [19:57:22<89:26:35, 18.75s/it] 17%|█▋        | 3427/20600 [19:57:51<104:30:32, 21.91s/it] 17%|█▋        | 3428/20600 [19:58:15<107:31:44, 22.54s/it] 17%|█▋        | 3429/20600 [19:58:38<108:10:22, 22.68s/it] 17%|█▋        | 3430/20600 [19:58:59<105:58:21, 22.22s/it]                                                           {'loss': 0.0, 'learning_rate': 4.6964360906609895e-05, 'epoch': 33.06}
 17%|█▋        | 3430/20600 [19:58:59<105:58:21, 22.22s/it][INFO|trainer.py:3081] 2023-08-17 11:48:02,260 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:48:02,260 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:48:02,260 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9281, 'eval_samples_per_second': 1.782, 'eval_steps_per_second': 0.255, 'epoch': 33.06}
 17%|█▋        | 3430/20600 [19:59:03<105:58:21, 22.22s/it]
100%|██████████| 1/1 [00:03<00:00,  3.04s/it][A
                                             [A 17%|█▋        | 3431/20600 [19:59:22<106:18:04, 22.29s/it] 17%|█▋        | 3432/20600 [19:59:41<102:25:16, 21.48s/it] 17%|█▋        | 3433/20600 [19:59:57<93:52:51, 19.69s/it]  17%|█▋        | 3434/20600 [20:00:19<97:06:32, 20.37s/it] 17%|█▋        | 3435/20600 [20:00:38<94:50:57, 19.89s/it] 17%|█▋        | 3436/20600 [20:00:59<97:19:30, 20.41s/it] 17%|█▋        | 3437/20600 [20:01:20<97:24:43, 20.43s/it] 17%|█▋        | 3438/20600 [20:01:39<96:01:57, 20.14s/it] 17%|█▋        | 3439/20600 [20:01:55<89:29:34, 18.77s/it] 17%|█▋        | 3440/20600 [20:02:13<88:19:51, 18.53s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6946126127151435e-05, 'epoch': 33.16}
 17%|█▋        | 3440/20600 [20:02:13<88:19:51, 18.53s/it][INFO|trainer.py:3081] 2023-08-17 11:51:15,672 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:51:15,672 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:51:15,672 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.7127, 'eval_samples_per_second': 0.908, 'eval_steps_per_second': 0.13, 'epoch': 33.16}
 17%|█▋        | 3440/20600 [20:02:20<88:19:51, 18.53s/it]
100%|██████████| 1/1 [00:06<00:00,  6.89s/it][A
                                             [A 17%|█▋        | 3441/20600 [20:02:38<97:42:53, 20.50s/it] 17%|█▋        | 3442/20600 [20:03:00<100:04:41, 21.00s/it] 17%|█▋        | 3443/20600 [20:03:18<96:26:58, 20.24s/it]  17%|█▋        | 3444/20600 [20:03:37<93:49:25, 19.69s/it] 17%|█▋        | 3445/20600 [20:03:54<90:22:00, 18.96s/it] 17%|█▋        | 3446/20600 [20:04:12<88:55:37, 18.66s/it] 17%|█▋        | 3447/20600 [20:04:37<98:30:51, 20.68s/it] 17%|█▋        | 3448/20600 [20:04:56<95:29:35, 20.04s/it] 17%|█▋        | 3449/20600 [20:05:13<90:57:35, 19.09s/it] 17%|█▋        | 3450/20600 [20:05:30<87:59:56, 18.47s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6927840306232664e-05, 'epoch': 33.25}
 17%|█▋        | 3450/20600 [20:05:30<87:59:56, 18.47s/it][INFO|trainer.py:3081] 2023-08-17 11:54:32,853 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:54:32,853 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:54:32,853 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1568, 'eval_samples_per_second': 1.684, 'eval_steps_per_second': 0.241, 'epoch': 33.25}
 17%|█▋        | 3450/20600 [20:05:34<87:59:56, 18.47s/it]
100%|██████████| 1/1 [00:03<00:00,  3.25s/it][A
                                             [A 17%|█▋        | 3451/20600 [20:05:51<92:01:47, 19.32s/it] 17%|█▋        | 3452/20600 [20:06:13<95:55:55, 20.14s/it] 17%|█▋        | 3453/20600 [20:06:32<93:39:21, 19.66s/it] 17%|█▋        | 3454/20600 [20:06:50<91:22:59, 19.19s/it] 17%|█▋        | 3455/20600 [20:07:09<90:43:33, 19.05s/it] 17%|█▋        | 3456/20600 [20:07:26<88:25:06, 18.57s/it] 17%|█▋        | 3457/20600 [20:07:55<102:59:17, 21.63s/it] 17%|█▋        | 3458/20600 [20:08:12<96:47:33, 20.33s/it]  17%|█▋        | 3459/20600 [20:08:31<95:21:18, 20.03s/it] 17%|█▋        | 3460/20600 [20:08:55<99:46:38, 20.96s/it]                                                          {'loss': 0.0, 'learning_rate': 4.690950348638202e-05, 'epoch': 33.35}
 17%|█▋        | 3460/20600 [20:08:55<99:46:38, 20.96s/it][INFO|trainer.py:3081] 2023-08-17 11:57:57,515 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 11:57:57,515 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 11:57:57,515 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0698, 'eval_samples_per_second': 1.72, 'eval_steps_per_second': 0.246, 'epoch': 33.35}
 17%|█▋        | 3460/20600 [20:08:59<99:46:38, 20.96s/it]
100%|██████████| 1/1 [00:03<00:00,  3.20s/it][A
                                             [A 17%|█▋        | 3461/20600 [20:09:18<103:25:01, 21.72s/it] 17%|█▋        | 3462/20600 [20:09:37<99:33:07, 20.91s/it]  17%|█▋        | 3463/20600 [20:09:53<92:16:02, 19.38s/it] 17%|█▋        | 3464/20600 [20:10:10<89:33:01, 18.81s/it] 17%|█▋        | 3465/20600 [20:10:32<92:56:07, 19.53s/it] 17%|█▋        | 3466/20600 [20:10:51<92:55:38, 19.52s/it] 17%|█▋        | 3467/20600 [20:11:11<92:52:50, 19.52s/it] 17%|█▋        | 3468/20600 [20:11:27<88:22:43, 18.57s/it] 17%|█▋        | 3469/20600 [20:11:45<87:53:53, 18.47s/it] 17%|█▋        | 3470/20600 [20:12:05<89:18:41, 18.77s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6891115710246596e-05, 'epoch': 33.45}
 17%|█▋        | 3470/20600 [20:12:05<89:18:41, 18.77s/it][INFO|trainer.py:3081] 2023-08-17 12:01:07,625 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:01:07,625 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:01:07,625 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.354, 'eval_samples_per_second': 1.102, 'eval_steps_per_second': 0.157, 'epoch': 33.45}
 17%|█▋        | 3470/20600 [20:12:11<89:18:41, 18.77s/it]
100%|██████████| 1/1 [00:05<00:00,  5.40s/it][A
                                             [A 17%|█▋        | 3471/20600 [20:12:28<95:27:10, 20.06s/it] 17%|█▋        | 3472/20600 [20:12:48<95:17:44, 20.03s/it] 17%|█▋        | 3473/20600 [20:13:12<102:07:59, 21.47s/it] 17%|█▋        | 3474/20600 [20:13:30<97:00:38, 20.39s/it]  17%|█▋        | 3475/20600 [20:13:53<99:31:05, 20.92s/it] 17%|█▋        | 3476/20600 [20:14:11<95:30:13, 20.08s/it] 17%|█▋        | 3477/20600 [20:14:31<95:35:57, 20.10s/it] 17%|█▋        | 3478/20600 [20:14:51<95:38:15, 20.11s/it] 17%|█▋        | 3479/20600 [20:15:10<94:32:43, 19.88s/it] 17%|█▋        | 3480/20600 [20:15:27<90:39:15, 19.06s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6872677020591974e-05, 'epoch': 33.54}
 17%|█▋        | 3480/20600 [20:15:27<90:39:15, 19.06s/it][INFO|trainer.py:3081] 2023-08-17 12:04:30,409 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:04:30,409 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:04:30,409 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.1287, 'eval_samples_per_second': 0.767, 'eval_steps_per_second': 0.11, 'epoch': 33.54}
 17%|█▋        | 3480/20600 [20:15:37<90:39:15, 19.06s/it]
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A
                                             [A 17%|█▋        | 3481/20600 [20:15:52<98:49:04, 20.78s/it] 17%|█▋        | 3482/20600 [20:16:08<91:45:13, 19.30s/it] 17%|█▋        | 3483/20600 [20:16:33<99:42:25, 20.97s/it] 17%|█▋        | 3484/20600 [20:16:56<102:16:40, 21.51s/it] 17%|█▋        | 3485/20600 [20:17:14<98:23:25, 20.70s/it]  17%|█▋        | 3486/20600 [20:17:37<101:21:17, 21.32s/it] 17%|█▋        | 3487/20600 [20:17:58<100:25:19, 21.13s/it] 17%|█▋        | 3488/20600 [20:18:16<95:40:55, 20.13s/it]  17%|█▋        | 3489/20600 [20:18:37<96:55:39, 20.39s/it] 17%|█▋        | 3490/20600 [20:18:56<95:47:30, 20.15s/it]                                                          {'loss': 0.0, 'learning_rate': 4.685418746030213e-05, 'epoch': 33.64}
 17%|█▋        | 3490/20600 [20:18:56<95:47:30, 20.15s/it][INFO|trainer.py:3081] 2023-08-17 12:07:59,343 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:07:59,343 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:07:59,343 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.827, 'eval_samples_per_second': 1.45, 'eval_steps_per_second': 0.207, 'epoch': 33.64}
 17%|█▋        | 3490/20600 [20:19:01<95:47:30, 20.15s/it]
100%|██████████| 1/1 [00:03<00:00,  3.93s/it][A
                                             [A 17%|█▋        | 3491/20600 [20:19:18<97:54:10, 20.60s/it] 17%|█▋        | 3492/20600 [20:19:33<90:15:16, 18.99s/it] 17%|█▋        | 3493/20600 [20:19:53<91:30:10, 19.26s/it] 17%|█▋        | 3494/20600 [20:20:11<89:35:05, 18.85s/it] 17%|█▋        | 3495/20600 [20:20:30<89:52:30, 18.92s/it] 17%|█▋        | 3496/20600 [20:20:47<87:23:45, 18.39s/it] 17%|█▋        | 3497/20600 [20:21:14<99:54:17, 21.03s/it] 17%|█▋        | 3498/20600 [20:21:31<94:14:03, 19.84s/it] 17%|█▋        | 3499/20600 [20:21:50<93:02:17, 19.59s/it] 17%|█▋        | 3500/20600 [20:22:11<94:14:46, 19.84s/it]                                                          {'loss': 0.0, 'learning_rate': 4.683564707237941e-05, 'epoch': 33.73}
 17%|█▋        | 3500/20600 [20:22:11<94:14:46, 19.84s/it][INFO|trainer.py:3081] 2023-08-17 12:11:13,911 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:11:13,911 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:11:13,911 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.6728, 'eval_samples_per_second': 0.912, 'eval_steps_per_second': 0.13, 'epoch': 33.73}
 17%|█▋        | 3500/20600 [20:22:19<94:14:46, 19.84s/it]
100%|██████████| 1/1 [00:06<00:00,  6.75s/it][A
                                             [A 17%|█▋        | 3501/20600 [20:22:39<105:47:54, 22.27s/it] 17%|█▋        | 3502/20600 [20:22:58<100:38:58, 21.19s/it] 17%|█▋        | 3503/20600 [20:23:21<103:54:34, 21.88s/it] 17%|█▋        | 3504/20600 [20:23:40<99:51:09, 21.03s/it]  17%|█▋        | 3505/20600 [20:24:00<98:01:29, 20.64s/it] 17%|█▋        | 3506/20600 [20:24:16<91:21:17, 19.24s/it] 17%|█▋        | 3507/20600 [20:24:35<91:12:50, 19.21s/it] 17%|█▋        | 3508/20600 [20:24:54<91:20:51, 19.24s/it] 17%|█▋        | 3509/20600 [20:25:12<88:40:54, 18.68s/it] 17%|█▋        | 3510/20600 [20:25:30<87:59:50, 18.54s/it]                                                          {'loss': 0.0, 'learning_rate': 4.681705589994433e-05, 'epoch': 33.83}
 17%|█▋        | 3510/20600 [20:25:30<87:59:50, 18.54s/it][INFO|trainer.py:3081] 2023-08-17 12:14:32,780 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:14:32,780 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:14:32,780 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.6016, 'eval_samples_per_second': 1.06, 'eval_steps_per_second': 0.151, 'epoch': 33.83}
 17%|█▋        | 3510/20600 [20:25:36<87:59:50, 18.54s/it]
100%|██████████| 1/1 [00:05<00:00,  5.68s/it][A
                                             [A 17%|█▋        | 3511/20600 [20:25:57<100:43:42, 21.22s/it] 17%|█▋        | 3512/20600 [20:26:15<95:22:46, 20.09s/it]  17%|█▋        | 3513/20600 [20:26:32<91:58:38, 19.38s/it] 17%|█▋        | 3514/20600 [20:26:51<91:30:00, 19.28s/it] 17%|█▋        | 3515/20600 [20:27:13<94:00:25, 19.81s/it] 17%|█▋        | 3516/20600 [20:27:36<98:51:59, 20.83s/it] 17%|█▋        | 3517/20600 [20:28:07<113:25:45, 23.90s/it] 17%|█▋        | 3518/20600 [20:28:26<106:16:12, 22.40s/it] 17%|█▋        | 3519/20600 [20:28:48<106:13:12, 22.39s/it] 17%|█▋        | 3520/20600 [20:29:13<110:03:43, 23.20s/it]                                                           {'loss': 0.0, 'learning_rate': 4.679841398623551e-05, 'epoch': 33.93}
 17%|█▋        | 3520/20600 [20:29:13<110:03:43, 23.20s/it][INFO|trainer.py:3081] 2023-08-17 12:18:16,176 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:18:16,176 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:18:16,176 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4177, 'eval_samples_per_second': 2.048, 'eval_steps_per_second': 0.293, 'epoch': 33.93}
 17%|█▋        | 3520/20600 [20:29:17<110:03:43, 23.20s/it]
100%|██████████| 1/1 [00:02<00:00,  2.56s/it][A
                                             [A 17%|█▋        | 3521/20600 [20:29:39<114:00:19, 24.03s/it] 17%|█▋        | 3522/20600 [20:30:06<118:18:29, 24.94s/it] 17%|█▋        | 3523/20600 [20:30:25<109:16:05, 23.03s/it] 17%|█▋        | 3524/20600 [20:30:53<116:28:07, 24.55s/it] 17%|█▋        | 3525/20600 [20:31:09<104:26:35, 22.02s/it] 17%|█▋        | 3526/20600 [20:31:26<97:54:42, 20.64s/it]  17%|█▋        | 3527/20600 [20:31:49<100:34:04, 21.21s/it] 17%|█▋        | 3528/20600 [20:32:11<102:24:35, 21.60s/it] 17%|█▋        | 3529/20600 [20:32:34<103:36:50, 21.85s/it] 17%|█▋        | 3530/20600 [20:32:59<107:40:17, 22.71s/it]                                                           {'loss': 0.0, 'learning_rate': 4.677972137460961e-05, 'epoch': 34.02}
 17%|█▋        | 3530/20600 [20:32:59<107:40:17, 22.71s/it][INFO|trainer.py:3081] 2023-08-17 12:22:01,594 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:22:01,595 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:22:01,595 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4182, 'eval_samples_per_second': 2.048, 'eval_steps_per_second': 0.293, 'epoch': 34.02}
 17%|█▋        | 3530/20600 [20:33:02<107:40:17, 22.71s/it]
100%|██████████| 1/1 [00:02<00:00,  2.58s/it][A
                                             [A 17%|█▋        | 3531/20600 [20:33:17<101:56:38, 21.50s/it] 17%|█▋        | 3532/20600 [20:33:43<107:14:17, 22.62s/it] 17%|█▋        | 3533/20600 [20:34:07<109:42:28, 23.14s/it] 17%|█▋        | 3534/20600 [20:34:27<106:04:30, 22.38s/it] 17%|█▋        | 3535/20600 [20:34:44<97:38:30, 20.60s/it]  17%|█▋        | 3536/20600 [20:35:09<103:20:54, 21.80s/it] 17%|█▋        | 3537/20600 [20:35:33<106:28:02, 22.46s/it] 17%|█▋        | 3538/20600 [20:35:50<99:40:55, 21.03s/it]  17%|█▋        | 3539/20600 [20:36:17<107:42:59, 22.73s/it] 17%|█▋        | 3540/20600 [20:36:34<99:08:09, 20.92s/it]                                                           {'loss': 0.0, 'learning_rate': 4.6760978108541195e-05, 'epoch': 34.12}
 17%|█▋        | 3540/20600 [20:36:34<99:08:09, 20.92s/it][INFO|trainer.py:3081] 2023-08-17 12:25:36,604 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:25:36,604 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:25:36,604 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3558, 'eval_samples_per_second': 0.838, 'eval_steps_per_second': 0.12, 'epoch': 34.12}
 17%|█▋        | 3540/20600 [20:36:42<99:08:09, 20.92s/it]
100%|██████████| 1/1 [00:07<00:00,  7.52s/it][A
                                             [A 17%|█▋        | 3541/20600 [20:37:06<114:55:52, 24.25s/it] 17%|█▋        | 3542/20600 [20:37:25<107:31:35, 22.69s/it] 17%|█▋        | 3543/20600 [20:37:45<103:49:20, 21.91s/it] 17%|█▋        | 3544/20600 [20:38:03<99:15:03, 20.95s/it]  17%|█▋        | 3545/20600 [20:38:23<96:56:17, 20.46s/it] 17%|█▋        | 3546/20600 [20:38:43<96:16:16, 20.32s/it] 17%|█▋        | 3547/20600 [20:38:58<88:48:05, 18.75s/it] 17%|█▋        | 3548/20600 [20:39:22<96:05:45, 20.29s/it] 17%|█▋        | 3549/20600 [20:39:41<94:27:58, 19.94s/it] 17%|█▋        | 3550/20600 [20:39:58<91:05:10, 19.23s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6742184231622634e-05, 'epoch': 34.22}
 17%|█▋        | 3550/20600 [20:39:58<91:05:10, 19.23s/it][INFO|trainer.py:3081] 2023-08-17 12:29:01,474 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:29:01,475 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:29:01,475 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.1487, 'eval_samples_per_second': 0.765, 'eval_steps_per_second': 0.109, 'epoch': 34.22}
 17%|█▋        | 3550/20600 [20:40:08<91:05:10, 19.23s/it]
100%|██████████| 1/1 [00:08<00:00,  8.22s/it][A
                                             [A 17%|█▋        | 3551/20600 [20:40:29<107:16:53, 22.65s/it] 17%|█▋        | 3552/20600 [20:40:47<100:34:26, 21.24s/it] 17%|█▋        | 3553/20600 [20:41:05<96:03:28, 20.29s/it]  17%|█▋        | 3554/20600 [20:41:22<90:36:59, 19.14s/it] 17%|█▋        | 3555/20600 [20:41:43<93:57:25, 19.84s/it] 17%|█▋        | 3556/20600 [20:42:02<92:56:31, 19.63s/it] 17%|█▋        | 3557/20600 [20:42:23<95:10:41, 20.10s/it] 17%|█▋        | 3558/20600 [20:42:40<90:17:28, 19.07s/it] 17%|█▋        | 3559/20600 [20:43:04<97:15:12, 20.55s/it] 17%|█▋        | 3560/20600 [20:43:19<89:25:05, 18.89s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6723339787564004e-05, 'epoch': 34.31}
 17%|█▋        | 3560/20600 [20:43:19<89:25:05, 18.89s/it][INFO|trainer.py:3081] 2023-08-17 12:32:22,084 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:32:22,084 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:32:22,084 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.6614, 'eval_samples_per_second': 1.912, 'eval_steps_per_second': 0.273, 'epoch': 34.31}
 17%|█▋        | 3560/20600 [20:43:23<89:25:05, 18.89s/it]
100%|██████████| 1/1 [00:02<00:00,  2.74s/it][A
                                             [A 17%|█▋        | 3561/20600 [20:43:45<100:04:49, 21.15s/it] 17%|█▋        | 3562/20600 [20:44:07<100:27:05, 21.22s/it] 17%|█▋        | 3563/20600 [20:44:23<93:41:29, 19.80s/it]  17%|█▋        | 3564/20600 [20:44:45<95:46:51, 20.24s/it] 17%|█▋        | 3565/20600 [20:45:02<91:32:47, 19.35s/it] 17%|█▋        | 3566/20600 [20:45:23<94:24:57, 19.95s/it] 17%|█▋        | 3567/20600 [20:45:40<89:25:43, 18.90s/it] 17%|█▋        | 3568/20600 [20:46:00<90:58:05, 19.23s/it] 17%|█▋        | 3569/20600 [20:46:19<91:30:31, 19.34s/it] 17%|█▋        | 3570/20600 [20:46:36<87:40:34, 18.53s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6704444820192994e-05, 'epoch': 34.41}
 17%|█▋        | 3570/20600 [20:46:36<87:40:34, 18.53s/it][INFO|trainer.py:3081] 2023-08-17 12:35:38,961 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:35:38,961 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:35:38,961 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.3876, 'eval_samples_per_second': 0.948, 'eval_steps_per_second': 0.135, 'epoch': 34.41}
 17%|█▋        | 3570/20600 [20:46:43<87:40:34, 18.53s/it]
100%|██████████| 1/1 [00:06<00:00,  6.48s/it][A
                                             [A 17%|█▋        | 3571/20600 [20:47:01<96:37:54, 20.43s/it] 17%|█▋        | 3572/20600 [20:47:18<92:20:43, 19.52s/it] 17%|█▋        | 3573/20600 [20:47:40<96:14:17, 20.35s/it] 17%|█▋        | 3574/20600 [20:47:58<92:03:58, 19.47s/it] 17%|█▋        | 3575/20600 [20:48:17<92:01:57, 19.46s/it] 17%|█▋        | 3576/20600 [20:48:40<96:30:09, 20.41s/it] 17%|█▋        | 3577/20600 [20:48:59<94:05:04, 19.90s/it] 17%|█▋        | 3578/20600 [20:49:27<105:40:07, 22.35s/it] 17%|█▋        | 3579/20600 [20:49:44<98:57:38, 20.93s/it]  17%|█▋        | 3580/20600 [20:50:00<91:05:33, 19.27s/it]                                                          {'loss': 0.0, 'learning_rate': 4.668549937345479e-05, 'epoch': 34.51}
 17%|█▋        | 3580/20600 [20:50:00<91:05:33, 19.27s/it][INFO|trainer.py:3081] 2023-08-17 12:39:02,748 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:39:02,748 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:39:02,748 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6499, 'eval_samples_per_second': 1.505, 'eval_steps_per_second': 0.215, 'epoch': 34.51}
 17%|█▋        | 3580/20600 [20:50:04<91:05:33, 19.27s/it]
100%|██████████| 1/1 [00:03<00:00,  3.71s/it][A
                                             [A 17%|█▋        | 3581/20600 [20:50:27<102:06:57, 21.60s/it] 17%|█▋        | 3582/20600 [20:50:45<97:24:46, 20.61s/it]  17%|█▋        | 3583/20600 [20:51:04<94:41:45, 20.03s/it] 17%|█▋        | 3584/20600 [20:51:21<91:13:04, 19.30s/it] 17%|█▋        | 3585/20600 [20:51:37<86:27:14, 18.29s/it] 17%|█▋        | 3586/20600 [20:52:02<95:42:00, 20.25s/it] 17%|█▋        | 3587/20600 [20:52:22<94:53:59, 20.08s/it] 17%|█▋        | 3588/20600 [20:52:43<96:30:29, 20.42s/it] 17%|█▋        | 3589/20600 [20:52:59<90:47:44, 19.21s/it] 17%|█▋        | 3590/20600 [20:53:17<88:02:20, 18.63s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6666503491412e-05, 'epoch': 34.6}
 17%|█▋        | 3590/20600 [20:53:17<88:02:20, 18.63s/it][INFO|trainer.py:3081] 2023-08-17 12:42:19,722 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:42:19,722 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:42:19,722 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9875, 'eval_samples_per_second': 1.756, 'eval_steps_per_second': 0.251, 'epoch': 34.6}
 17%|█▋        | 3590/20600 [20:53:21<88:02:20, 18.63s/it]
100%|██████████| 1/1 [00:03<00:00,  3.12s/it][A
                                             [A 17%|█▋        | 3591/20600 [20:53:38<91:58:49, 19.47s/it] 17%|█▋        | 3592/20600 [20:53:54<86:15:40, 18.26s/it] 17%|█▋        | 3593/20600 [20:54:20<97:47:20, 20.70s/it] 17%|█▋        | 3594/20600 [20:54:36<91:27:21, 19.36s/it] 17%|█▋        | 3595/20600 [20:54:55<91:06:29, 19.29s/it] 17%|█▋        | 3596/20600 [20:55:21<100:42:22, 21.32s/it] 17%|█▋        | 3597/20600 [20:55:35<90:10:56, 19.09s/it]  17%|█▋        | 3598/20600 [20:56:01<99:24:00, 21.05s/it] 17%|█▋        | 3599/20600 [20:56:20<97:17:30, 20.60s/it] 17%|█▋        | 3600/20600 [20:56:44<101:10:33, 21.43s/it]                                                           {'loss': 0.0, 'learning_rate': 4.66474572182445e-05, 'epoch': 34.7}
 17%|█▋        | 3600/20600 [20:56:44<101:10:33, 21.43s/it][INFO|trainer.py:3081] 2023-08-17 12:45:46,781 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:45:46,782 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:45:46,782 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.4996, 'eval_samples_per_second': 1.556, 'eval_steps_per_second': 0.222, 'epoch': 34.7}
 17%|█▋        | 3600/20600 [20:56:48<101:10:33, 21.43s/it]
100%|██████████| 1/1 [00:03<00:00,  3.64s/it][A
                                             [A 17%|█▋        | 3601/20600 [20:57:02<97:15:32, 20.60s/it]  17%|█▋        | 3602/20600 [20:57:27<102:41:23, 21.75s/it] 17%|█▋        | 3603/20600 [20:57:55<111:02:55, 23.52s/it] 17%|█▋        | 3604/20600 [20:58:10<99:03:20, 20.98s/it]  18%|█▊        | 3605/20600 [20:58:28<95:40:45, 20.27s/it] 18%|█▊        | 3606/20600 [20:58:50<98:18:42, 20.83s/it] 18%|█▊        | 3607/20600 [20:59:13<100:12:56, 21.23s/it] 18%|█▊        | 3608/20600 [20:59:37<105:30:32, 22.35s/it] 18%|█▊        | 3609/20600 [20:59:59<104:27:01, 22.13s/it] 18%|█▊        | 3610/20600 [21:00:24<107:50:43, 22.85s/it]                                                           {'loss': 0.0, 'learning_rate': 4.66283605982494e-05, 'epoch': 34.8}
 18%|█▊        | 3610/20600 [21:00:24<107:50:43, 22.85s/it][INFO|trainer.py:3081] 2023-08-17 12:49:26,607 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:49:26,607 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:49:26,607 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.297, 'eval_samples_per_second': 2.123, 'eval_steps_per_second': 0.303, 'epoch': 34.8}
 18%|█▊        | 3610/20600 [21:00:27<107:50:43, 22.85s/it]
100%|██████████| 1/1 [00:02<00:00,  2.43s/it][A
                                             [A 18%|█▊        | 3611/20600 [21:00:49<111:06:31, 23.54s/it] 18%|█▊        | 3612/20600 [21:01:06<102:00:21, 21.62s/it] 18%|█▊        | 3613/20600 [21:01:23<95:10:08, 20.17s/it]  18%|█▊        | 3614/20600 [21:01:47<101:14:57, 21.46s/it] 18%|█▊        | 3615/20600 [21:02:03<93:11:15, 19.75s/it]  18%|█▊        | 3616/20600 [21:02:30<103:21:22, 21.91s/it] 18%|█▊        | 3617/20600 [21:02:46<95:01:33, 20.14s/it]  18%|█▊        | 3618/20600 [21:03:12<103:28:42, 21.94s/it] 18%|█▊        | 3619/20600 [21:03:28<94:26:11, 20.02s/it]  18%|█▊        | 3620/20600 [21:03:50<97:32:31, 20.68s/it]                                                          {'loss': 0.0, 'learning_rate': 4.660921367584089e-05, 'epoch': 34.89}
 18%|█▊        | 3620/20600 [21:03:50<97:32:31, 20.68s/it][INFO|trainer.py:3081] 2023-08-17 12:52:52,771 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:52:52,771 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:52:52,771 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0825, 'eval_samples_per_second': 0.771, 'eval_steps_per_second': 0.11, 'epoch': 34.89}
 18%|█▊        | 3620/20600 [21:03:59<97:32:31, 20.68s/it]
100%|██████████| 1/1 [00:08<00:00,  8.21s/it][A
                                             [A 18%|█▊        | 3621/20600 [21:04:26<118:53:37, 25.21s/it] 18%|█▊        | 3622/20600 [21:04:50<118:17:16, 25.08s/it] 18%|█▊        | 3623/20600 [21:05:12<113:52:51, 24.15s/it] 18%|█▊        | 3624/20600 [21:05:29<103:19:44, 21.91s/it] 18%|█▊        | 3625/20600 [21:05:51<103:52:20, 22.03s/it] 18%|█▊        | 3626/20600 [21:06:14<104:46:24, 22.22s/it] 18%|█▊        | 3627/20600 [21:06:45<117:43:50, 24.97s/it] 18%|█▊        | 3628/20600 [21:07:00<103:41:07, 21.99s/it] 18%|█▊        | 3629/20600 [21:07:26<108:25:26, 23.00s/it] 18%|█▊        | 3630/20600 [21:07:47<106:16:26, 22.54s/it]                                                           {'loss': 0.0, 'learning_rate': 4.659001649555014e-05, 'epoch': 34.99}
 18%|█▊        | 3630/20600 [21:07:47<106:16:26, 22.54s/it][INFO|trainer.py:3081] 2023-08-17 12:56:50,222 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 12:56:50,222 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 12:56:50,222 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8171, 'eval_samples_per_second': 1.834, 'eval_steps_per_second': 0.262, 'epoch': 34.99}
 18%|█▊        | 3630/20600 [21:07:51<106:16:26, 22.54s/it]
100%|██████████| 1/1 [00:02<00:00,  2.95s/it][A
                                             [A 18%|█▊        | 3631/20600 [21:08:07<102:54:20, 21.83s/it] 18%|█▊        | 3632/20600 [21:08:25<97:15:21, 20.63s/it]  18%|█▊        | 3633/20600 [21:08:49<101:39:35, 21.57s/it] 18%|█▊        | 3634/20600 [21:09:08<98:43:00, 20.95s/it]  18%|█▊        | 3635/20600 [21:09:41<115:04:16, 24.42s/it] 18%|█▊        | 3636/20600 [21:09:57<103:41:32, 22.00s/it] 18%|█▊        | 3637/20600 [21:10:12<93:53:15, 19.93s/it]  18%|█▊        | 3638/20600 [21:10:34<96:30:04, 20.48s/it] 18%|█▊        | 3639/20600 [21:10:52<92:46:33, 19.69s/it] 18%|█▊        | 3640/20600 [21:11:12<92:41:45, 19.68s/it]                                                          {'loss': 0.0, 'learning_rate': 4.657076910202521e-05, 'epoch': 35.08}
 18%|█▊        | 3640/20600 [21:11:12<92:41:45, 19.68s/it][INFO|trainer.py:3081] 2023-08-17 13:00:14,727 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:00:14,727 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:00:14,727 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9148, 'eval_samples_per_second': 1.788, 'eval_steps_per_second': 0.255, 'epoch': 35.08}
 18%|█▊        | 3640/20600 [21:11:16<92:41:45, 19.68s/it]
100%|██████████| 1/1 [00:03<00:00,  3.02s/it][A
                                             [A 18%|█▊        | 3641/20600 [21:11:33<95:01:50, 20.17s/it] 18%|█▊        | 3642/20600 [21:11:50<91:00:15, 19.32s/it] 18%|█▊        | 3643/20600 [21:12:11<92:35:46, 19.66s/it] 18%|█▊        | 3644/20600 [21:12:27<87:49:39, 18.65s/it] 18%|█▊        | 3645/20600 [21:12:54<99:05:57, 21.04s/it] 18%|█▊        | 3646/20600 [21:13:09<90:19:07, 19.18s/it] 18%|█▊        | 3647/20600 [21:13:29<91:47:49, 19.49s/it] 18%|█▊        | 3648/20600 [21:13:47<89:44:53, 19.06s/it] 18%|█▊        | 3649/20600 [21:14:06<89:19:16, 18.97s/it] 18%|█▊        | 3650/20600 [21:14:22<85:36:26, 18.18s/it]                                                          {'loss': 0.0, 'learning_rate': 4.655147154003097e-05, 'epoch': 35.18}
 18%|█▊        | 3650/20600 [21:14:22<85:36:26, 18.18s/it][INFO|trainer.py:3081] 2023-08-17 13:03:24,958 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:03:24,958 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:03:24,958 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3261, 'eval_samples_per_second': 1.107, 'eval_steps_per_second': 0.158, 'epoch': 35.18}
 18%|█▊        | 3650/20600 [21:14:28<85:36:26, 18.18s/it]
100%|██████████| 1/1 [00:05<00:00,  5.43s/it][A
                                             [A 18%|█▊        | 3651/20600 [21:14:48<96:47:31, 20.56s/it] 18%|█▊        | 3652/20600 [21:15:05<91:54:10, 19.52s/it] 18%|█▊        | 3653/20600 [21:15:33<104:14:40, 22.14s/it] 18%|█▊        | 3654/20600 [21:15:50<96:07:31, 20.42s/it]  18%|█▊        | 3655/20600 [21:16:12<99:00:05, 21.03s/it] 18%|█▊        | 3656/20600 [21:16:35<101:40:21, 21.60s/it] 18%|█▊        | 3657/20600 [21:16:51<93:37:50, 19.89s/it]  18%|█▊        | 3658/20600 [21:17:18<103:48:38, 22.06s/it] 18%|█▊        | 3659/20600 [21:17:33<94:09:00, 20.01s/it]  18%|█▊        | 3660/20600 [21:17:50<89:54:08, 19.11s/it]                                                          {'loss': 0.0, 'learning_rate': 4.653212385444894e-05, 'epoch': 35.28}
 18%|█▊        | 3660/20600 [21:17:50<89:54:08, 19.11s/it][INFO|trainer.py:3081] 2023-08-17 13:06:53,459 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:06:53,459 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:06:53,459 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6407, 'eval_samples_per_second': 1.508, 'eval_steps_per_second': 0.215, 'epoch': 35.28}
 18%|█▊        | 3660/20600 [21:17:55<89:54:08, 19.11s/it]
100%|██████████| 1/1 [00:03<00:00,  3.74s/it][A
                                             [A 18%|█▊        | 3661/20600 [21:18:14<96:01:02, 20.41s/it] 18%|█▊        | 3662/20600 [21:18:31<90:45:05, 19.29s/it] 18%|█▊        | 3663/20600 [21:18:50<90:18:56, 19.20s/it] 18%|█▊        | 3664/20600 [21:19:08<89:06:16, 18.94s/it] 18%|█▊        | 3665/20600 [21:19:25<86:59:13, 18.49s/it] 18%|█▊        | 3666/20600 [21:19:43<85:43:00, 18.22s/it] 18%|█▊        | 3667/20600 [21:20:00<84:31:56, 17.97s/it] 18%|█▊        | 3668/20600 [21:20:18<83:55:33, 17.84s/it] 18%|█▊        | 3669/20600 [21:20:35<83:31:02, 17.76s/it] 18%|█▊        | 3670/20600 [21:20:56<87:18:04, 18.56s/it]                                                          {'loss': 0.0, 'learning_rate': 4.651272609027723e-05, 'epoch': 35.37}
 18%|█▊        | 3670/20600 [21:20:56<87:18:04, 18.56s/it][INFO|trainer.py:3081] 2023-08-17 13:09:58,874 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:09:58,874 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:09:58,874 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.4582, 'eval_samples_per_second': 1.282, 'eval_steps_per_second': 0.183, 'epoch': 35.37}
 18%|█▊        | 3670/20600 [21:21:01<87:18:04, 18.56s/it]
100%|██████████| 1/1 [00:04<00:00,  4.59s/it][A
                                             [A 18%|█▊        | 3671/20600 [21:21:19<94:22:30, 20.07s/it] 18%|█▊        | 3672/20600 [21:21:36<89:13:33, 18.98s/it] 18%|█▊        | 3673/20600 [21:21:54<88:19:13, 18.78s/it] 18%|█▊        | 3674/20600 [21:22:10<84:44:44, 18.02s/it] 18%|█▊        | 3675/20600 [21:22:46<109:53:09, 23.37s/it] 18%|█▊        | 3676/20600 [21:23:09<109:20:12, 23.26s/it] 18%|█▊        | 3677/20600 [21:23:34<111:06:03, 23.63s/it] 18%|█▊        | 3678/20600 [21:23:54<106:28:23, 22.65s/it] 18%|█▊        | 3679/20600 [21:24:14<102:43:09, 21.85s/it] 18%|█▊        | 3680/20600 [21:24:41<110:10:25, 23.44s/it]                                                           {'loss': 0.0, 'learning_rate': 4.649327829263041e-05, 'epoch': 35.47}
 18%|█▊        | 3680/20600 [21:24:41<110:10:25, 23.44s/it][INFO|trainer.py:3081] 2023-08-17 13:13:44,327 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:13:44,328 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:13:44,328 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.3587, 'eval_samples_per_second': 0.837, 'eval_steps_per_second': 0.12, 'epoch': 35.47}
 18%|█▊        | 3680/20600 [21:24:50<110:10:25, 23.44s/it]
100%|██████████| 1/1 [00:07<00:00,  7.51s/it][A
                                             [A 18%|█▊        | 3681/20600 [21:25:08<114:24:09, 24.34s/it] 18%|█▊        | 3682/20600 [21:25:31<113:10:32, 24.08s/it] 18%|█▊        | 3683/20600 [21:25:51<106:40:02, 22.70s/it] 18%|█▊        | 3684/20600 [21:26:16<109:52:55, 23.38s/it] 18%|█▊        | 3685/20600 [21:26:32<99:30:40, 21.18s/it]  18%|█▊        | 3686/20600 [21:26:54<101:03:21, 21.51s/it] 18%|█▊        | 3687/20600 [21:27:09<91:51:24, 19.55s/it]  18%|█▊        | 3688/20600 [21:27:34<99:57:56, 21.28s/it] 18%|█▊        | 3689/20600 [21:27:54<97:44:46, 20.81s/it] 18%|█▊        | 3690/20600 [21:28:15<98:29:13, 20.97s/it]                                                          {'loss': 0.0, 'learning_rate': 4.647378050673944e-05, 'epoch': 35.57}
 18%|█▊        | 3690/20600 [21:28:15<98:29:13, 20.97s/it][INFO|trainer.py:3081] 2023-08-17 13:17:18,359 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:17:18,359 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:17:18,359 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.1788, 'eval_samples_per_second': 0.975, 'eval_steps_per_second': 0.139, 'epoch': 35.57}
 18%|█▊        | 3690/20600 [21:28:23<98:29:13, 20.97s/it]
100%|██████████| 1/1 [00:06<00:00,  6.24s/it][A
                                             [A 18%|█▊        | 3691/20600 [21:28:39<102:20:27, 21.79s/it] 18%|█▊        | 3692/20600 [21:29:04<107:19:07, 22.85s/it] 18%|█▊        | 3693/20600 [21:29:23<101:55:21, 21.70s/it] 18%|█▊        | 3694/20600 [21:29:51<109:39:15, 23.35s/it] 18%|█▊        | 3695/20600 [21:30:07<100:11:35, 21.34s/it] 18%|█▊        | 3696/20600 [21:30:32<105:35:02, 22.49s/it] 18%|█▊        | 3697/20600 [21:30:49<96:34:39, 20.57s/it]  18%|█▊        | 3698/20600 [21:31:05<91:15:33, 19.44s/it] 18%|█▊        | 3699/20600 [21:31:23<88:11:08, 18.78s/it] 18%|█▊        | 3700/20600 [21:31:47<95:51:31, 20.42s/it]                                                          {'loss': 0.0, 'learning_rate': 4.645423277795151e-05, 'epoch': 35.66}
 18%|█▊        | 3700/20600 [21:31:47<95:51:31, 20.42s/it][INFO|trainer.py:3081] 2023-08-17 13:20:49,800 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:20:49,800 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:20:49,800 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0673, 'eval_samples_per_second': 1.721, 'eval_steps_per_second': 0.246, 'epoch': 35.66}
 18%|█▊        | 3700/20600 [21:31:51<95:51:31, 20.42s/it]
100%|██████████| 1/1 [00:03<00:00,  3.21s/it][A
                                             [A 18%|█▊        | 3701/20600 [21:32:08<96:59:25, 20.66s/it] 18%|█▊        | 3702/20600 [21:32:28<96:05:27, 20.47s/it] 18%|█▊        | 3703/20600 [21:32:48<95:44:02, 20.40s/it] 18%|█▊        | 3704/20600 [21:33:07<92:49:14, 19.78s/it] 18%|█▊        | 3705/20600 [21:33:32<101:17:58, 21.58s/it] 18%|█▊        | 3706/20600 [21:33:49<93:40:46, 19.96s/it]  18%|█▊        | 3707/20600 [21:34:12<99:13:18, 21.14s/it] 18%|█▊        | 3708/20600 [21:34:30<94:06:32, 20.06s/it] 18%|█▊        | 3709/20600 [21:34:47<89:27:24, 19.07s/it] 18%|█▊        | 3710/20600 [21:35:15<102:55:07, 21.94s/it]                                                           {'loss': 0.0, 'learning_rate': 4.643463515172999e-05, 'epoch': 35.76}
 18%|█▊        | 3710/20600 [21:35:15<102:55:07, 21.94s/it][INFO|trainer.py:3081] 2023-08-17 13:24:18,398 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:24:18,398 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:24:18,398 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.9137, 'eval_samples_per_second': 1.184, 'eval_steps_per_second': 0.169, 'epoch': 35.76}
 18%|█▊        | 3710/20600 [21:35:21<102:55:07, 21.94s/it]
100%|██████████| 1/1 [00:05<00:00,  5.01s/it][A
                                             [A 18%|█▊        | 3711/20600 [21:35:38<103:13:53, 22.00s/it] 18%|█▊        | 3712/20600 [21:35:52<92:45:04, 19.77s/it]  18%|█▊        | 3713/20600 [21:36:14<95:01:41, 20.26s/it] 18%|█▊        | 3714/20600 [21:36:32<91:55:48, 19.60s/it] 18%|█▊        | 3715/20600 [21:36:50<90:51:13, 19.37s/it] 18%|█▊        | 3716/20600 [21:37:13<95:55:29, 20.45s/it] 18%|█▊        | 3717/20600 [21:37:37<99:41:23, 21.26s/it] 18%|█▊        | 3718/20600 [21:37:58<99:18:36, 21.18s/it] 18%|█▊        | 3719/20600 [21:38:20<101:45:33, 21.70s/it] 18%|█▊        | 3720/20600 [21:38:49<111:24:01, 23.76s/it]                                                           {'loss': 0.0, 'learning_rate': 4.641498767365427e-05, 'epoch': 35.86}
 18%|█▊        | 3720/20600 [21:38:49<111:24:01, 23.76s/it][INFO|trainer.py:3081] 2023-08-17 13:27:51,998 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:27:51,998 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:27:51,998 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 5.8251, 'eval_samples_per_second': 1.202, 'eval_steps_per_second': 0.172, 'epoch': 35.86}
 18%|█▊        | 3720/20600 [21:38:55<111:24:01, 23.76s/it]
100%|██████████| 1/1 [00:04<00:00,  5.00s/it][A
                                             [A 18%|█▊        | 3721/20600 [21:39:12<109:51:20, 23.43s/it] 18%|█▊        | 3722/20600 [21:39:33<107:08:24, 22.85s/it] 18%|█▊        | 3723/20600 [21:39:51<99:40:33, 21.26s/it]  18%|█▊        | 3724/20600 [21:40:12<99:33:54, 21.24s/it] 18%|█▊        | 3725/20600 [21:40:36<103:03:29, 21.99s/it] 18%|█▊        | 3726/20600 [21:40:54<98:36:59, 21.04s/it]  18%|█▊        | 3727/20600 [21:41:12<94:12:27, 20.10s/it] 18%|█▊        | 3728/20600 [21:41:37<100:24:06, 21.42s/it] 18%|█▊        | 3729/20600 [21:41:54<94:49:41, 20.23s/it]  18%|█▊        | 3730/20600 [21:42:23<107:10:46, 22.87s/it]                                                           {'loss': 0.0, 'learning_rate': 4.6395290389419724e-05, 'epoch': 35.95}
 18%|█▊        | 3730/20600 [21:42:23<107:10:46, 22.87s/it][INFO|trainer.py:3081] 2023-08-17 13:31:26,373 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:31:26,373 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:31:26,373 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0314, 'eval_samples_per_second': 1.736, 'eval_steps_per_second': 0.248, 'epoch': 35.95}
 18%|█▊        | 3730/20600 [21:42:27<107:10:46, 22.87s/it]
100%|██████████| 1/1 [00:03<00:00,  3.20s/it][A
                                             [A 18%|█▊        | 3731/20600 [21:42:44<104:12:21, 22.24s/it] 18%|█▊        | 3732/20600 [21:43:09<107:39:52, 22.98s/it] 18%|█▊        | 3733/20600 [21:43:35<112:34:33, 24.03s/it] 18%|█▊        | 3734/20600 [21:43:54<105:20:53, 22.49s/it] 18%|█▊        | 3735/20600 [21:44:23<114:31:11, 24.45s/it] 18%|█▊        | 3736/20600 [21:44:48<115:20:10, 24.62s/it] 18%|█▊        | 3737/20600 [21:45:05<104:26:46, 22.30s/it] 18%|█▊        | 3738/20600 [21:45:26<101:49:37, 21.74s/it] 18%|█▊        | 3739/20600 [21:45:50<105:33:41, 22.54s/it] 18%|█▊        | 3740/20600 [21:46:08<98:43:56, 21.08s/it]                                                           {'loss': 0.0, 'learning_rate': 4.6375543344837536e-05, 'epoch': 36.05}
 18%|█▊        | 3740/20600 [21:46:08<98:43:56, 21.08s/it][INFO|trainer.py:3081] 2023-08-17 13:35:10,651 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:35:10,651 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:35:10,651 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.0502, 'eval_samples_per_second': 1.386, 'eval_steps_per_second': 0.198, 'epoch': 36.05}
 18%|█▊        | 3740/20600 [21:46:13<98:43:56, 21.08s/it]
100%|██████████| 1/1 [00:04<00:00,  4.14s/it][A
                                             [A 18%|█▊        | 3741/20600 [21:46:29<98:49:23, 21.10s/it] 18%|█▊        | 3742/20600 [21:46:54<104:13:04, 22.26s/it] 18%|█▊        | 3743/20600 [21:47:22<112:44:02, 24.08s/it] 18%|█▊        | 3744/20600 [21:47:42<106:56:00, 22.84s/it] 18%|█▊        | 3745/20600 [21:48:06<108:50:36, 23.25s/it] 18%|█▊        | 3746/20600 [21:48:24<100:46:21, 21.52s/it] 18%|█▊        | 3747/20600 [21:48:40<93:39:02, 20.00s/it]  18%|█▊        | 3748/20600 [21:49:12<109:50:40, 23.47s/it] 18%|█▊        | 3749/20600 [21:49:31<104:16:30, 22.28s/it] 18%|█▊        | 3750/20600 [21:49:47<94:59:28, 20.29s/it]                                                           {'loss': 0.0, 'learning_rate': 4.635574658583462e-05, 'epoch': 36.14}
 18%|█▊        | 3750/20600 [21:49:47<94:59:28, 20.29s/it][INFO|trainer.py:3081] 2023-08-17 13:38:49,897 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:38:49,897 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:38:49,897 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0308, 'eval_samples_per_second': 0.996, 'eval_steps_per_second': 0.142, 'epoch': 36.14}
 18%|█▊        | 3750/20600 [21:49:54<94:59:28, 20.29s/it]
100%|██████████| 1/1 [00:06<00:00,  6.12s/it][A
                                             [A 18%|█▊        | 3751/20600 [21:50:18<109:36:07, 23.42s/it] 18%|█▊        | 3752/20600 [21:50:41<109:19:05, 23.36s/it] 18%|█▊        | 3753/20600 [21:50:58<100:59:22, 21.58s/it] 18%|█▊        | 3754/20600 [21:51:17<97:08:11, 20.76s/it]  18%|█▊        | 3755/20600 [21:51:37<96:35:03, 20.64s/it] 18%|█▊        | 3756/20600 [21:51:54<91:22:09, 19.53s/it] 18%|█▊        | 3757/20600 [21:52:15<93:19:13, 19.95s/it] 18%|█▊        | 3758/20600 [21:52:40<99:22:51, 21.24s/it] 18%|█▊        | 3759/20600 [21:53:06<106:36:10, 22.79s/it] 18%|█▊        | 3760/20600 [21:53:23<97:57:15, 20.94s/it]                                                           {'loss': 0.0, 'learning_rate': 4.633590015845352e-05, 'epoch': 36.24}
 18%|█▊        | 3760/20600 [21:53:23<97:57:15, 20.94s/it][INFO|trainer.py:3081] 2023-08-17 13:42:25,612 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:42:25,612 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:42:25,612 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.2564, 'eval_samples_per_second': 1.119, 'eval_steps_per_second': 0.16, 'epoch': 36.24}
 18%|█▊        | 3760/20600 [21:53:29<97:57:15, 20.94s/it]
100%|██████████| 1/1 [00:05<00:00,  5.38s/it][A
                                             [A 18%|█▊        | 3761/20600 [21:53:44<99:14:38, 21.22s/it] 18%|█▊        | 3762/20600 [21:54:06<100:19:34, 21.45s/it] 18%|█▊        | 3763/20600 [21:54:28<100:49:28, 21.56s/it] 18%|█▊        | 3764/20600 [21:54:47<97:03:36, 20.75s/it]  18%|█▊        | 3765/20600 [21:55:05<92:17:40, 19.74s/it] 18%|█▊        | 3766/20600 [21:55:21<88:25:04, 18.91s/it] 18%|█▊        | 3767/20600 [21:55:45<94:09:48, 20.14s/it] 18%|█▊        | 3768/20600 [21:56:04<92:52:29, 19.86s/it] 18%|█▊        | 3769/20600 [21:56:23<91:28:23, 19.57s/it] 18%|█▊        | 3770/20600 [21:56:38<86:14:04, 18.45s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6316004108852305e-05, 'epoch': 36.34}
 18%|█▊        | 3770/20600 [21:56:38<86:14:04, 18.45s/it][INFO|trainer.py:3081] 2023-08-17 13:45:41,425 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:45:41,425 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:45:41,425 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.1522, 'eval_samples_per_second': 1.359, 'eval_steps_per_second': 0.194, 'epoch': 36.34}
 18%|█▊        | 3770/20600 [21:56:44<86:14:04, 18.45s/it]
100%|██████████| 1/1 [00:04<00:00,  4.29s/it][A
                                             [A 18%|█▊        | 3771/20600 [21:57:01<91:19:38, 19.54s/it] 18%|█▊        | 3772/20600 [21:57:20<90:42:50, 19.41s/it] 18%|█▊        | 3773/20600 [21:57:36<86:40:21, 18.54s/it] 18%|█▊        | 3774/20600 [21:57:56<88:25:39, 18.92s/it] 18%|█▊        | 3775/20600 [21:58:15<88:31:19, 18.94s/it] 18%|█▊        | 3776/20600 [21:58:38<94:02:57, 20.12s/it] 18%|█▊        | 3777/20600 [21:58:58<93:30:11, 20.01s/it] 18%|█▊        | 3778/20600 [21:59:17<92:07:39, 19.72s/it] 18%|█▊        | 3779/20600 [21:59:36<91:56:47, 19.68s/it] 18%|█▊        | 3780/20600 [21:59:56<91:52:52, 19.67s/it]                                                          {'loss': 0.0, 'learning_rate': 4.629605848330445e-05, 'epoch': 36.43}
 18%|█▊        | 3780/20600 [21:59:56<91:52:52, 19.67s/it][INFO|trainer.py:3081] 2023-08-17 13:48:58,802 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:48:58,802 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:48:58,802 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.4651, 'eval_samples_per_second': 1.281, 'eval_steps_per_second': 0.183, 'epoch': 36.43}
 18%|█▊        | 3780/20600 [22:00:01<91:52:52, 19.67s/it]
100%|██████████| 1/1 [00:04<00:00,  4.59s/it][A
                                             [A 18%|█▊        | 3781/20600 [22:00:19<96:47:37, 20.72s/it] 18%|█▊        | 3782/20600 [22:00:37<92:36:48, 19.82s/it] 18%|█▊        | 3783/20600 [22:00:57<93:39:04, 20.05s/it] 18%|█▊        | 3784/20600 [22:01:18<95:05:37, 20.36s/it] 18%|█▊        | 3785/20600 [22:01:35<90:12:44, 19.31s/it] 18%|█▊        | 3786/20600 [22:01:59<96:53:15, 20.74s/it] 18%|█▊        | 3787/20600 [22:02:20<96:17:11, 20.62s/it] 18%|█▊        | 3788/20600 [22:02:38<92:47:18, 19.87s/it] 18%|█▊        | 3789/20600 [22:03:02<98:57:47, 21.19s/it] 18%|█▊        | 3790/20600 [22:03:18<91:05:12, 19.51s/it]                                                          {'loss': 0.0, 'learning_rate': 4.627606332819872e-05, 'epoch': 36.53}
 18%|█▊        | 3790/20600 [22:03:18<91:05:12, 19.51s/it][INFO|trainer.py:3081] 2023-08-17 13:52:20,620 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:52:20,620 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:52:20,620 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.8482, 'eval_samples_per_second': 0.892, 'eval_steps_per_second': 0.127, 'epoch': 36.53}
 18%|█▊        | 3790/20600 [22:03:26<91:05:12, 19.51s/it]
100%|██████████| 1/1 [00:06<00:00,  6.95s/it][A
                                             [A 18%|█▊        | 3791/20600 [22:03:48<106:56:42, 22.90s/it] 18%|█▊        | 3792/20600 [22:04:04<96:05:48, 20.58s/it]  18%|█▊        | 3793/20600 [22:04:29<102:18:14, 21.91s/it] 18%|█▊        | 3794/20600 [22:04:45<94:21:34, 20.21s/it]  18%|█▊        | 3795/20600 [22:05:10<101:05:28, 21.66s/it] 18%|█▊        | 3796/20600 [22:05:27<94:25:17, 20.23s/it]  18%|█▊        | 3797/20600 [22:05:46<93:36:25, 20.06s/it] 18%|█▊        | 3798/20600 [22:06:12<100:44:51, 21.59s/it] 18%|█▊        | 3799/20600 [22:06:27<91:59:31, 19.71s/it]  18%|█▊        | 3800/20600 [22:06:49<94:54:51, 20.34s/it]                                                          {'loss': 0.0, 'learning_rate': 4.625601869003907e-05, 'epoch': 36.63}
 18%|█▊        | 3800/20600 [22:06:49<94:54:51, 20.34s/it][INFO|trainer.py:3081] 2023-08-17 13:55:51,762 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:55:51,763 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:55:51,763 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.3122, 'eval_samples_per_second': 0.752, 'eval_steps_per_second': 0.107, 'epoch': 36.63}
 18%|█▊        | 3800/20600 [22:06:58<94:54:51, 20.34s/it]
100%|██████████| 1/1 [00:08<00:00,  8.42s/it][A
                                             [A 18%|█▊        | 3801/20600 [22:07:16<104:06:45, 22.31s/it] 18%|█▊        | 3802/20600 [22:07:44<112:20:16, 24.08s/it] 18%|█▊        | 3803/20600 [22:08:07<110:28:35, 23.68s/it] 18%|█▊        | 3804/20600 [22:08:23<100:21:25, 21.51s/it] 18%|█▊        | 3805/20600 [22:08:49<106:24:25, 22.81s/it] 18%|█▊        | 3806/20600 [22:09:14<109:02:26, 23.37s/it] 18%|█▊        | 3807/20600 [22:09:38<109:55:37, 23.57s/it] 18%|█▊        | 3808/20600 [22:10:00<108:28:56, 23.26s/it] 18%|█▊        | 3809/20600 [22:10:20<103:06:43, 22.11s/it] 18%|█▊        | 3810/20600 [22:10:38<98:23:33, 21.10s/it]                                                           {'loss': 0.0, 'learning_rate': 4.623592461544457e-05, 'epoch': 36.72}
 18%|█▊        | 3810/20600 [22:10:38<98:23:33, 21.10s/it][INFO|trainer.py:3081] 2023-08-17 13:59:41,311 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 13:59:41,311 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 13:59:41,311 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.38, 'eval_samples_per_second': 1.598, 'eval_steps_per_second': 0.228, 'epoch': 36.72}
 18%|█▊        | 3810/20600 [22:10:43<98:23:33, 21.10s/it]
100%|██████████| 1/1 [00:03<00:00,  3.52s/it][A
                                             [A 18%|█▊        | 3811/20600 [22:11:09<111:28:40, 23.90s/it] 19%|█▊        | 3812/20600 [22:11:25<101:02:50, 21.67s/it] 19%|█▊        | 3813/20600 [22:11:42<94:25:43, 20.25s/it]  19%|█▊        | 3814/20600 [22:11:58<88:47:32, 19.04s/it] 19%|█▊        | 3815/20600 [22:12:24<97:37:20, 20.94s/it] 19%|█▊        | 3816/20600 [22:12:38<88:28:42, 18.98s/it] 19%|█▊        | 3817/20600 [22:12:56<86:37:18, 18.58s/it] 19%|█▊        | 3818/20600 [22:13:20<94:38:45, 20.30s/it] 19%|█▊        | 3819/20600 [22:13:40<94:32:18, 20.28s/it] 19%|█▊        | 3820/20600 [22:13:59<92:02:22, 19.75s/it]                                                          {'loss': 0.0, 'learning_rate': 4.621578115114925e-05, 'epoch': 36.82}
 19%|█▊        | 3820/20600 [22:13:59<92:02:22, 19.75s/it][INFO|trainer.py:3081] 2023-08-17 14:03:01,851 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:03:01,852 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:03:01,852 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0435, 'eval_samples_per_second': 0.774, 'eval_steps_per_second': 0.111, 'epoch': 36.82}
 19%|█▊        | 3820/20600 [22:14:08<92:02:22, 19.75s/it]
100%|██████████| 1/1 [00:08<00:00,  8.14s/it][A
                                             [A 19%|█▊        | 3821/20600 [22:14:28<104:46:01, 22.48s/it] 19%|█▊        | 3822/20600 [22:14:47<100:16:16, 21.51s/it] 19%|█▊        | 3823/20600 [22:15:11<103:36:50, 22.23s/it] 19%|█▊        | 3824/20600 [22:15:31<100:42:06, 21.61s/it] 19%|█▊        | 3825/20600 [22:15:52<100:22:32, 21.54s/it] 19%|█▊        | 3826/20600 [22:16:11<95:59:21, 20.60s/it]  19%|█▊        | 3827/20600 [22:16:30<93:45:30, 20.12s/it] 19%|█▊        | 3828/20600 [22:16:53<97:20:56, 20.90s/it] 19%|█▊        | 3829/20600 [22:17:16<101:23:05, 21.76s/it] 19%|█▊        | 3830/20600 [22:17:32<92:52:05, 19.94s/it]                                                           {'loss': 0.0, 'learning_rate': 4.6195588344002e-05, 'epoch': 36.92}
 19%|█▊        | 3830/20600 [22:17:32<92:52:05, 19.94s/it][INFO|trainer.py:3081] 2023-08-17 14:06:34,998 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:06:34,998 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:06:34,998 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.045, 'eval_samples_per_second': 1.731, 'eval_steps_per_second': 0.247, 'epoch': 36.92}
 19%|█▊        | 3830/20600 [22:17:36<92:52:05, 19.94s/it]
100%|██████████| 1/1 [00:03<00:00,  3.14s/it][A
                                             [A 19%|█▊        | 3831/20600 [22:17:50<90:24:24, 19.41s/it] 19%|█▊        | 3832/20600 [22:18:05<83:40:52, 17.97s/it] 19%|█▊        | 3833/20600 [22:18:30<94:13:27, 20.23s/it] 19%|█▊        | 3834/20600 [22:18:50<94:03:04, 20.19s/it] 19%|█▊        | 3835/20600 [22:19:14<98:23:52, 21.13s/it] 19%|█▊        | 3836/20600 [22:19:35<98:19:37, 21.12s/it] 19%|█▊        | 3837/20600 [22:19:50<89:55:36, 19.31s/it] 19%|█▊        | 3838/20600 [22:20:14<96:54:12, 20.81s/it] 19%|█▊        | 3839/20600 [22:20:37<99:46:20, 21.43s/it] 19%|█▊        | 3840/20600 [22:20:53<91:36:25, 19.68s/it]                                                          {'loss': 0.0, 'learning_rate': 4.617534624096648e-05, 'epoch': 37.01}
 19%|█▊        | 3840/20600 [22:20:53<91:36:25, 19.68s/it][INFO|trainer.py:3081] 2023-08-17 14:09:55,660 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:09:55,660 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:09:55,660 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8323, 'eval_samples_per_second': 1.827, 'eval_steps_per_second': 0.261, 'epoch': 37.01}
 19%|█▊        | 3840/20600 [22:20:57<91:36:25, 19.68s/it]
100%|██████████| 1/1 [00:02<00:00,  2.93s/it][A
                                             [A 19%|█▊        | 3841/20600 [22:21:15<94:37:31, 20.33s/it] 19%|█▊        | 3842/20600 [22:21:39<99:50:50, 21.45s/it] 19%|█▊        | 3843/20600 [22:21:55<92:59:11, 19.98s/it] 19%|█▊        | 3844/20600 [22:22:19<98:11:23, 21.10s/it] 19%|█▊        | 3845/20600 [22:22:35<90:48:19, 19.51s/it] 19%|█▊        | 3846/20600 [22:22:51<86:54:54, 18.68s/it] 19%|█▊        | 3847/20600 [22:23:16<95:38:18, 20.55s/it] 19%|█▊        | 3848/20600 [22:23:42<102:50:00, 22.10s/it] 19%|█▊        | 3849/20600 [22:24:05<103:54:14, 22.33s/it] 19%|█▊        | 3850/20600 [22:24:32<110:34:47, 23.77s/it]                                                           {'loss': 0.0, 'learning_rate': 4.615505488912099e-05, 'epoch': 37.11}
 19%|█▊        | 3850/20600 [22:24:32<110:34:47, 23.77s/it][INFO|trainer.py:3081] 2023-08-17 14:13:35,021 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:13:35,022 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:13:35,022 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.0745, 'eval_samples_per_second': 1.718, 'eval_steps_per_second': 0.245, 'epoch': 37.11}
 19%|█▊        | 3850/20600 [22:24:36<110:34:47, 23.77s/it]
100%|██████████| 1/1 [00:03<00:00,  3.21s/it][A
                                             [A 19%|█▊        | 3851/20600 [22:24:55<109:48:07, 23.60s/it] 19%|█▊        | 3852/20600 [22:25:18<108:16:54, 23.28s/it] 19%|█▊        | 3853/20600 [22:25:43<110:45:32, 23.81s/it] 19%|█▊        | 3854/20600 [22:26:13<119:49:39, 25.76s/it] 19%|█▊        | 3855/20600 [22:26:29<105:39:11, 22.71s/it] 19%|█▊        | 3856/20600 [22:26:55<111:17:28, 23.93s/it] 19%|█▊        | 3857/20600 [22:27:13<102:25:14, 22.02s/it] 19%|█▊        | 3858/20600 [22:27:31<97:10:52, 20.90s/it]  19%|█▊        | 3859/20600 [22:27:51<95:33:16, 20.55s/it] 19%|█▊        | 3860/20600 [22:28:11<94:20:35, 20.29s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6134714335658404e-05, 'epoch': 37.2}
 19%|█▊        | 3860/20600 [22:28:11<94:20:35, 20.29s/it][INFO|trainer.py:3081] 2023-08-17 14:17:13,711 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:17:13,711 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:17:13,711 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.3974, 'eval_samples_per_second': 1.094, 'eval_steps_per_second': 0.156, 'epoch': 37.2}
 19%|█▊        | 3860/20600 [22:28:17<94:20:35, 20.29s/it]
100%|██████████| 1/1 [00:05<00:00,  5.42s/it][A
                                             [A 19%|█▊        | 3861/20600 [22:28:34<99:11:49, 21.33s/it] 19%|█▊        | 3862/20600 [22:28:52<93:43:25, 20.16s/it] 19%|█▉        | 3863/20600 [22:29:24<110:24:16, 23.75s/it] 19%|█▉        | 3864/20600 [22:29:42<101:46:55, 21.89s/it] 19%|█▉        | 3865/20600 [22:30:00<96:52:35, 20.84s/it]  19%|█▉        | 3866/20600 [22:30:19<94:01:21, 20.23s/it] 19%|█▉        | 3867/20600 [22:30:36<89:51:14, 19.33s/it] 19%|█▉        | 3868/20600 [22:30:54<88:05:26, 18.95s/it] 19%|█▉        | 3869/20600 [22:31:12<86:55:27, 18.70s/it] 19%|█▉        | 3870/20600 [22:31:41<101:20:33, 21.81s/it]                                                           {'loss': 0.0, 'learning_rate': 4.611432462788599e-05, 'epoch': 37.3}
 19%|█▉        | 3870/20600 [22:31:41<101:20:33, 21.81s/it][INFO|trainer.py:3081] 2023-08-17 14:20:44,256 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:20:44,256 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:20:44,256 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7928, 'eval_samples_per_second': 1.846, 'eval_steps_per_second': 0.264, 'epoch': 37.3}
 19%|█▉        | 3870/20600 [22:31:45<101:20:33, 21.81s/it]
100%|██████████| 1/1 [00:02<00:00,  2.94s/it][A
                                             [A 19%|█▉        | 3871/20600 [22:32:02<100:28:34, 21.62s/it] 19%|█▉        | 3872/20600 [22:32:20<95:02:10, 20.45s/it]  19%|█▉        | 3873/20600 [22:32:47<103:51:29, 22.35s/it] 19%|█▉        | 3874/20600 [22:33:08<101:32:55, 21.86s/it] 19%|█▉        | 3875/20600 [22:33:32<104:43:05, 22.54s/it] 19%|█▉        | 3876/20600 [22:33:49<97:23:50, 20.97s/it]  19%|█▉        | 3877/20600 [22:34:05<89:47:35, 19.33s/it] 19%|█▉        | 3878/20600 [22:34:30<98:23:21, 21.18s/it] 19%|█▉        | 3879/20600 [22:34:49<94:54:26, 20.43s/it] 19%|█▉        | 3880/20600 [22:35:04<87:44:24, 18.89s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6093885813225336e-05, 'epoch': 37.4}
 19%|█▉        | 3880/20600 [22:35:04<87:44:24, 18.89s/it][INFO|trainer.py:3081] 2023-08-17 14:24:07,083 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:24:07,083 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:24:07,083 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8162, 'eval_samples_per_second': 1.834, 'eval_steps_per_second': 0.262, 'epoch': 37.4}
 19%|█▉        | 3880/20600 [22:35:08<87:44:24, 18.89s/it]
100%|██████████| 1/1 [00:02<00:00,  2.85s/it][A
                                             [A 19%|█▉        | 3881/20600 [22:35:23<88:12:01, 18.99s/it] 19%|█▉        | 3882/20600 [22:35:51<100:19:51, 21.60s/it] 19%|█▉        | 3883/20600 [22:36:06<91:20:17, 19.67s/it]  19%|█▉        | 3884/20600 [22:36:24<88:23:36, 19.04s/it] 19%|█▉        | 3885/20600 [22:36:41<85:18:33, 18.37s/it] 19%|█▉        | 3886/20600 [22:37:06<95:37:15, 20.60s/it] 19%|█▉        | 3887/20600 [22:37:23<90:24:31, 19.47s/it] 19%|█▉        | 3888/20600 [22:37:43<90:13:23, 19.44s/it] 19%|█▉        | 3889/20600 [22:38:01<89:25:32, 19.26s/it] 19%|█▉        | 3890/20600 [22:38:22<90:58:31, 19.60s/it]                                                          {'loss': 0.0, 'learning_rate': 4.6073397939212274e-05, 'epoch': 37.49}
 19%|█▉        | 3890/20600 [22:38:22<90:58:31, 19.60s/it][INFO|trainer.py:3081] 2023-08-17 14:27:24,784 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:27:24,785 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:27:24,785 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.134, 'eval_samples_per_second': 1.141, 'eval_steps_per_second': 0.163, 'epoch': 37.49}
 19%|█▉        | 3890/20600 [22:38:28<90:58:31, 19.60s/it]
100%|██████████| 1/1 [00:05<00:00,  5.26s/it][A
                                             [A 19%|█▉        | 3891/20600 [22:38:48<100:35:29, 21.67s/it] 19%|█▉        | 3892/20600 [22:39:08<97:36:00, 21.03s/it]  19%|█▉        | 3893/20600 [22:39:28<97:04:16, 20.92s/it] 19%|█▉        | 3894/20600 [22:39:45<91:15:38, 19.67s/it] 19%|█▉        | 3895/20600 [22:40:08<94:59:12, 20.47s/it] 19%|█▉        | 3896/20600 [22:40:29<95:54:07, 20.67s/it] 19%|█▉        | 3897/20600 [22:40:49<95:43:23, 20.63s/it] 19%|█▉        | 3898/20600 [22:41:11<96:36:50, 20.82s/it] 19%|█▉        | 3899/20600 [22:41:40<108:01:27, 23.29s/it] 19%|█▉        | 3900/20600 [22:42:02<107:10:24, 23.10s/it]                                                           {'loss': 0.0, 'learning_rate': 4.60528610534967e-05, 'epoch': 37.59}
 19%|█▉        | 3900/20600 [22:42:02<107:10:24, 23.10s/it][INFO|trainer.py:3081] 2023-08-17 14:31:05,223 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:31:05,224 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:31:05,224 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 8.9203, 'eval_samples_per_second': 0.785, 'eval_steps_per_second': 0.112, 'epoch': 37.59}
 19%|█▉        | 3900/20600 [22:42:11<107:10:24, 23.10s/it]
100%|██████████| 1/1 [00:08<00:00,  8.01s/it][A
                                             [A 19%|█▉        | 3901/20600 [22:42:28<110:57:42, 23.92s/it] 19%|█▉        | 3902/20600 [22:42:56<116:25:20, 25.10s/it] 19%|█▉        | 3903/20600 [22:43:16<109:00:59, 23.50s/it] 19%|█▉        | 3904/20600 [22:43:33<100:07:53, 21.59s/it] 19%|█▉        | 3905/20600 [22:43:51<95:44:56, 20.65s/it]  19%|█▉        | 3906/20600 [22:44:17<103:09:46, 22.25s/it] 19%|█▉        | 3907/20600 [22:44:38<100:50:35, 21.75s/it] 19%|█▉        | 3908/20600 [22:44:58<99:04:07, 21.37s/it]  19%|█▉        | 3909/20600 [22:45:15<92:56:08, 20.04s/it] 19%|█▉        | 3910/20600 [22:45:45<105:50:02, 22.83s/it]                                                           {'loss': 0.0, 'learning_rate': 4.603227520384253e-05, 'epoch': 37.69}
 19%|█▉        | 3910/20600 [22:45:45<105:50:02, 22.83s/it][INFO|trainer.py:3081] 2023-08-17 14:34:47,601 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:34:47,601 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:34:47,601 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7722, 'eval_samples_per_second': 1.856, 'eval_steps_per_second': 0.265, 'epoch': 37.69}
 19%|█▉        | 3910/20600 [22:45:48<105:50:02, 22.83s/it]
100%|██████████| 1/1 [00:02<00:00,  2.91s/it][A
                                             [A 19%|█▉        | 3911/20600 [22:46:08<105:58:21, 22.86s/it] 19%|█▉        | 3912/20600 [22:46:28<102:50:09, 22.18s/it] 19%|█▉        | 3913/20600 [22:46:48<99:03:11, 21.37s/it]  19%|█▉        | 3914/20600 [22:47:08<98:09:49, 21.18s/it] 19%|█▉        | 3915/20600 [22:47:45<119:32:18, 25.79s/it] 19%|█▉        | 3916/20600 [22:48:12<121:15:31, 26.16s/it] 19%|█▉        | 3917/20600 [22:48:29<108:18:13, 23.37s/it] 19%|█▉        | 3918/20600 [22:48:48<102:37:30, 22.15s/it] 19%|█▉        | 3919/20600 [22:49:05<96:01:04, 20.72s/it]  19%|█▉        | 3920/20600 [22:49:30<101:29:52, 21.91s/it]                                                           {'loss': 0.0, 'learning_rate': 4.601164043812755e-05, 'epoch': 37.78}
 19%|█▉        | 3920/20600 [22:49:30<101:29:52, 21.91s/it][INFO|trainer.py:3081] 2023-08-17 14:38:33,171 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:38:33,171 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:38:33,171 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 4.2208, 'eval_samples_per_second': 1.658, 'eval_steps_per_second': 0.237, 'epoch': 37.78}
 19%|█▉        | 3920/20600 [22:49:34<101:29:52, 21.91s/it]
100%|██████████| 1/1 [00:03<00:00,  3.33s/it][A
                                             [A 19%|█▉        | 3921/20600 [22:49:49<97:18:37, 21.00s/it]  19%|█▉        | 3922/20600 [22:50:16<106:15:41, 22.94s/it] 19%|█▉        | 3923/20600 [22:50:35<99:52:53, 21.56s/it]  19%|█▉        | 3924/20600 [22:50:55<97:17:59, 21.00s/it] 19%|█▉        | 3925/20600 [22:51:18<100:58:57, 21.80s/it] 19%|█▉        | 3926/20600 [22:51:37<97:15:13, 21.00s/it]  19%|█▉        | 3927/20600 [22:51:54<91:07:59, 19.68s/it] 19%|█▉        | 3928/20600 [22:52:12<88:41:59, 19.15s/it] 19%|█▉        | 3929/20600 [22:52:32<90:13:05, 19.48s/it] 19%|█▉        | 3930/20600 [22:52:55<94:54:26, 20.50s/it]                                                          {'loss': 0.0, 'learning_rate': 4.59909568043433e-05, 'epoch': 37.88}
 19%|█▉        | 3930/20600 [22:52:55<94:54:26, 20.50s/it][INFO|trainer.py:3081] 2023-08-17 14:41:57,938 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:41:57,938 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:41:57,938 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0554, 'eval_samples_per_second': 0.773, 'eval_steps_per_second': 0.11, 'epoch': 37.88}
 19%|█▉        | 3930/20600 [22:53:04<94:54:26, 20.50s/it]
100%|██████████| 1/1 [00:08<00:00,  8.20s/it][A
                                             [A 19%|█▉        | 3931/20600 [22:53:23<106:05:49, 22.91s/it] 19%|█▉        | 3932/20600 [22:53:40<97:11:50, 20.99s/it]  19%|█▉        | 3933/20600 [22:54:03<99:57:33, 21.59s/it] 19%|█▉        | 3934/20600 [22:54:20<94:05:44, 20.33s/it] 19%|█▉        | 3935/20600 [22:54:37<88:55:36, 19.21s/it] 19%|█▉        | 3936/20600 [22:54:58<91:35:06, 19.79s/it] 19%|█▉        | 3937/20600 [22:55:22<97:34:08, 21.08s/it] 19%|█▉        | 3938/20600 [22:55:36<87:58:13, 19.01s/it] 19%|█▉        | 3939/20600 [22:55:56<88:24:08, 19.10s/it] 19%|█▉        | 3940/20600 [22:56:23<99:08:54, 21.42s/it]                                                          {'loss': 0.0, 'learning_rate': 4.597022435059498e-05, 'epoch': 37.98}
 19%|█▉        | 3940/20600 [22:56:23<99:08:54, 21.42s/it][INFO|trainer.py:3081] 2023-08-17 14:45:25,572 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:45:25,572 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:45:25,572 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.935, 'eval_samples_per_second': 0.783, 'eval_steps_per_second': 0.112, 'epoch': 37.98}
 19%|█▉        | 3940/20600 [22:56:32<99:08:54, 21.42s/it]
100%|██████████| 1/1 [00:08<00:00,  8.09s/it][A
                                             [A 19%|█▉        | 3941/20600 [22:56:48<104:24:38, 22.56s/it] 19%|█▉        | 3942/20600 [22:57:08<100:51:26, 21.80s/it] 19%|█▉        | 3943/20600 [22:57:26<95:39:04, 20.67s/it]  19%|█▉        | 3944/20600 [22:57:42<89:01:39, 19.24s/it] 19%|█▉        | 3945/20600 [22:57:58<85:16:00, 18.43s/it] 19%|█▉        | 3946/20600 [22:58:18<87:17:04, 18.87s/it] 19%|█▉        | 3947/20600 [22:58:41<92:11:31, 19.93s/it] 19%|█▉        | 3948/20600 [22:58:56<85:40:10, 18.52s/it] 19%|█▉        | 3949/20600 [22:59:20<93:08:53, 20.14s/it] 19%|█▉        | 3950/20600 [22:59:37<89:11:24, 19.28s/it]                                                          {'loss': 0.0, 'learning_rate': 4.594944312510134e-05, 'epoch': 38.07}
 19%|█▉        | 3950/20600 [22:59:37<89:11:24, 19.28s/it][INFO|trainer.py:3081] 2023-08-17 14:48:39,995 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:48:39,995 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:48:39,995 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5226, 'eval_samples_per_second': 1.987, 'eval_steps_per_second': 0.284, 'epoch': 38.07}
 19%|█▉        | 3950/20600 [22:59:41<89:11:24, 19.28s/it]
100%|██████████| 1/1 [00:02<00:00,  2.63s/it][A
                                             [A 19%|█▉        | 3951/20600 [22:59:56<88:23:14, 19.11s/it] 19%|█▉        | 3952/20600 [23:00:16<90:19:36, 19.53s/it] 19%|█▉        | 3953/20600 [23:00:37<91:28:10, 19.78s/it] 19%|█▉        | 3954/20600 [23:01:06<105:00:41, 22.71s/it] 19%|█▉        | 3955/20600 [23:01:24<97:37:33, 21.11s/it]  19%|█▉        | 3956/20600 [23:01:46<99:21:21, 21.49s/it] 19%|█▉        | 3957/20600 [23:02:03<93:16:40, 20.18s/it] 19%|█▉        | 3958/20600 [23:02:30<103:24:36, 22.37s/it] 19%|█▉        | 3959/20600 [23:02:50<99:27:57, 21.52s/it]  19%|█▉        | 3960/20600 [23:03:09<96:13:11, 20.82s/it]                                                          {'loss': 0.0, 'learning_rate': 4.592861317619457e-05, 'epoch': 38.17}
 19%|█▉        | 3960/20600 [23:03:09<96:13:11, 20.82s/it][INFO|trainer.py:3081] 2023-08-17 14:52:12,168 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:52:12,168 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:52:12,168 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.6455, 'eval_samples_per_second': 1.24, 'eval_steps_per_second': 0.177, 'epoch': 38.17}
 19%|█▉        | 3960/20600 [23:03:15<96:13:11, 20.82s/it]
100%|██████████| 1/1 [00:04<00:00,  4.74s/it][A
                                             [A 19%|█▉        | 3961/20600 [23:03:38<107:45:21, 23.31s/it] 19%|█▉        | 3962/20600 [23:04:10<119:58:49, 25.96s/it] 19%|█▉        | 3963/20600 [23:04:30<111:26:07, 24.11s/it] 19%|█▉        | 3964/20600 [23:04:49<103:25:17, 22.38s/it] 19%|█▉        | 3965/20600 [23:05:11<103:45:27, 22.45s/it] 19%|█▉        | 3966/20600 [23:05:28<96:12:46, 20.82s/it]  19%|█▉        | 3967/20600 [23:05:58<109:06:46, 23.62s/it] 19%|█▉        | 3968/20600 [23:06:17<101:48:39, 22.04s/it] 19%|█▉        | 3969/20600 [23:06:34<94:49:10, 20.52s/it]  19%|█▉        | 3970/20600 [23:07:03<106:18:40, 23.01s/it]                                                           {'loss': 0.0, 'learning_rate': 4.590773455232016e-05, 'epoch': 38.27}
 19%|█▉        | 3970/20600 [23:07:03<106:18:40, 23.01s/it][INFO|trainer.py:3081] 2023-08-17 14:56:05,557 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:56:05,557 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:56:05,557 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4822, 'eval_samples_per_second': 2.01, 'eval_steps_per_second': 0.287, 'epoch': 38.27}
 19%|█▉        | 3970/20600 [23:07:06<106:18:40, 23.01s/it]
100%|██████████| 1/1 [00:02<00:00,  2.62s/it][A
                                             [A 19%|█▉        | 3971/20600 [23:07:26<107:15:08, 23.22s/it] 19%|█▉        | 3972/20600 [23:07:55<114:20:04, 24.75s/it] 19%|█▉        | 3973/20600 [23:08:16<110:00:50, 23.82s/it] 19%|█▉        | 3974/20600 [23:08:38<106:32:56, 23.07s/it] 19%|█▉        | 3975/20600 [23:08:54<97:49:31, 21.18s/it]  19%|█▉        | 3976/20600 [23:09:18<101:01:22, 21.88s/it] 19%|█▉        | 3977/20600 [23:09:36<95:12:10, 20.62s/it]  19%|█▉        | 3978/20600 [23:09:57<96:17:17, 20.85s/it] 19%|█▉        | 3979/20600 [23:10:17<95:04:10, 20.59s/it] 19%|█▉        | 3980/20600 [23:10:33<89:29:59, 19.39s/it]                                                          {'loss': 0.0, 'learning_rate': 4.588680730203681e-05, 'epoch': 38.36}
 19%|█▉        | 3980/20600 [23:10:33<89:29:59, 19.39s/it][INFO|trainer.py:3081] 2023-08-17 14:59:36,465 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 14:59:36,465 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 14:59:36,465 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9714, 'eval_samples_per_second': 1.763, 'eval_steps_per_second': 0.252, 'epoch': 38.36}
 19%|█▉        | 3980/20600 [23:10:37<89:29:59, 19.39s/it]
100%|██████████| 1/1 [00:03<00:00,  3.05s/it][A
                                             [A 19%|█▉        | 3981/20600 [23:10:55<92:07:36, 19.96s/it] 19%|█▉        | 3982/20600 [23:11:21<101:17:50, 21.94s/it] 19%|█▉        | 3983/20600 [23:11:42<99:25:36, 21.54s/it]  19%|█▉        | 3984/20600 [23:12:01<95:34:42, 20.71s/it] 19%|█▉        | 3985/20600 [23:12:23<97:55:16, 21.22s/it] 19%|█▉        | 3986/20600 [23:12:39<91:10:16, 19.76s/it] 19%|█▉        | 3987/20600 [23:12:56<86:04:22, 18.65s/it] 19%|█▉        | 3988/20600 [23:13:17<90:14:35, 19.56s/it] 19%|█▉        | 3989/20600 [23:13:39<93:54:11, 20.35s/it] 19%|█▉        | 3990/20600 [23:13:57<89:45:20, 19.45s/it]                                                          {'loss': 0.0, 'learning_rate': 4.5865831474016316e-05, 'epoch': 38.46}
 19%|█▉        | 3990/20600 [23:13:57<89:45:20, 19.45s/it][INFO|trainer.py:3081] 2023-08-17 15:02:59,754 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:02:59,754 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:02:59,754 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7319, 'eval_samples_per_second': 1.876, 'eval_steps_per_second': 0.268, 'epoch': 38.46}
 19%|█▉        | 3990/20600 [23:14:01<89:45:20, 19.45s/it]
100%|██████████| 1/1 [00:02<00:00,  2.85s/it][A
                                             [A 19%|█▉        | 3991/20600 [23:14:20<95:32:55, 20.71s/it] 19%|█▉        | 3992/20600 [23:14:43<98:10:22, 21.28s/it] 19%|█▉        | 3993/20600 [23:15:02<94:32:22, 20.49s/it] 19%|█▉        | 3994/20600 [23:15:26<100:04:08, 21.69s/it] 19%|█▉        | 3995/20600 [23:15:48<100:39:02, 21.82s/it] 19%|█▉        | 3996/20600 [23:16:08<97:50:32, 21.21s/it]  19%|█▉        | 3997/20600 [23:16:25<92:20:32, 20.02s/it] 19%|█▉        | 3998/20600 [23:16:43<88:52:53, 19.27s/it] 19%|█▉        | 3999/20600 [23:17:03<89:43:35, 19.46s/it] 19%|█▉        | 4000/20600 [23:17:19<85:43:02, 18.59s/it]                                                          {'loss': 0.0, 'learning_rate': 4.584480711704348e-05, 'epoch': 38.55}
 19%|█▉        | 4000/20600 [23:17:19<85:43:02, 18.59s/it][INFO|trainer.py:3081] 2023-08-17 15:06:22,290 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:06:22,291 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:06:22,291 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8364, 'eval_samples_per_second': 1.825, 'eval_steps_per_second': 0.261, 'epoch': 38.55}
 19%|█▉        | 4000/20600 [23:17:23<85:43:02, 18.59s/it]
100%|██████████| 1/1 [00:02<00:00,  2.87s/it][A
                                             [A08/17/2023 15:06:26 - INFO - llmtuner.tuner.core.trainer - Saving model checkpoint to ../outputs/Ihin/Ihin-sft-llama2/checkpoint-4000
 19%|█▉        | 4001/20600 [23:17:43<92:06:21, 19.98s/it] 19%|█▉        | 4002/20600 [23:17:59<87:51:58, 19.06s/it] 19%|█▉        | 4003/20600 [23:18:19<88:08:28, 19.12s/it] 19%|█▉        | 4004/20600 [23:18:36<85:32:25, 18.56s/it] 19%|█▉        | 4005/20600 [23:18:54<85:19:08, 18.51s/it] 19%|█▉        | 4006/20600 [23:19:11<83:14:44, 18.06s/it] 19%|█▉        | 4007/20600 [23:19:32<87:12:28, 18.92s/it] 19%|█▉        | 4008/20600 [23:19:53<90:16:03, 19.59s/it] 19%|█▉        | 4009/20600 [23:20:08<82:55:56, 18.00s/it] 19%|█▉        | 4010/20600 [23:20:32<91:36:21, 19.88s/it]                                                          {'loss': 0.0, 'learning_rate': 4.582373428001591e-05, 'epoch': 38.65}
 19%|█▉        | 4010/20600 [23:20:32<91:36:21, 19.88s/it][INFO|trainer.py:3081] 2023-08-17 15:09:34,953 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:09:34,953 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:09:34,953 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.4507, 'eval_samples_per_second': 1.573, 'eval_steps_per_second': 0.225, 'epoch': 38.65}
 19%|█▉        | 4010/20600 [23:20:36<91:36:21, 19.88s/it]
100%|██████████| 1/1 [00:03<00:00,  3.57s/it][A
                                             [A 19%|█▉        | 4011/20600 [23:20:51<90:56:25, 19.74s/it] 19%|█▉        | 4012/20600 [23:21:10<89:53:36, 19.51s/it] 19%|█▉        | 4013/20600 [23:21:39<102:50:01, 22.32s/it] 19%|█▉        | 4014/20600 [23:21:56<94:50:12, 20.58s/it]  19%|█▉        | 4015/20600 [23:22:17<95:34:04, 20.74s/it] 19%|█▉        | 4016/20600 [23:22:40<98:11:59, 21.32s/it] 20%|█▉        | 4017/20600 [23:22:57<92:37:18, 20.11s/it] 20%|█▉        | 4018/20600 [23:23:17<93:14:26, 20.24s/it] 20%|█▉        | 4019/20600 [23:23:36<90:27:12, 19.64s/it] 20%|█▉        | 4020/20600 [23:24:05<104:15:30, 22.64s/it]                                                           {'loss': 0.0, 'learning_rate': 4.580261301194403e-05, 'epoch': 38.75}
 20%|█▉        | 4020/20600 [23:24:05<104:15:30, 22.64s/it][INFO|trainer.py:3081] 2023-08-17 15:13:08,245 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:13:08,245 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:13:08,245 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.4726, 'eval_samples_per_second': 1.081, 'eval_steps_per_second': 0.154, 'epoch': 38.75}
 20%|█▉        | 4020/20600 [23:24:12<104:15:30, 22.64s/it]
100%|██████████| 1/1 [00:05<00:00,  5.62s/it][A
                                             [A 20%|█▉        | 4021/20600 [23:24:32<109:43:07, 23.82s/it] 20%|█▉        | 4022/20600 [23:24:56<109:45:59, 23.84s/it] 20%|█▉        | 4023/20600 [23:25:14<102:10:36, 22.19s/it] 20%|█▉        | 4024/20600 [23:25:39<105:41:32, 22.95s/it] 20%|█▉        | 4025/20600 [23:25:56<97:54:00, 21.26s/it]  20%|█▉        | 4026/20600 [23:26:15<94:05:21, 20.44s/it] 20%|█▉        | 4027/20600 [23:26:37<97:05:38, 21.09s/it] 20%|█▉        | 4028/20600 [23:26:56<94:28:57, 20.52s/it] 20%|█▉        | 4029/20600 [23:27:19<97:52:57, 21.26s/it] 20%|█▉        | 4030/20600 [23:27:41<98:45:30, 21.46s/it]                                                          {'loss': 0.0, 'learning_rate': 4.578144336195087e-05, 'epoch': 38.84}
 20%|█▉        | 4030/20600 [23:27:41<98:45:30, 21.46s/it][INFO|trainer.py:3081] 2023-08-17 15:16:44,314 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:16:44,315 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:16:44,315 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.8358, 'eval_samples_per_second': 1.024, 'eval_steps_per_second': 0.146, 'epoch': 38.84}
 20%|█▉        | 4030/20600 [23:27:48<98:45:30, 21.46s/it]
100%|██████████| 1/1 [00:05<00:00,  5.97s/it][A
                                             [A 20%|█▉        | 4031/20600 [23:28:04<100:18:20, 21.79s/it] 20%|█▉        | 4032/20600 [23:28:20<91:47:22, 19.94s/it]  20%|█▉        | 4033/20600 [23:28:46<101:11:37, 21.99s/it] 20%|█▉        | 4034/20600 [23:29:08<101:17:25, 22.01s/it] 20%|█▉        | 4035/20600 [23:29:29<98:47:55, 21.47s/it]  20%|█▉        | 4036/20600 [23:29:46<92:55:55, 20.20s/it] 20%|█▉        | 4037/20600 [23:30:07<94:29:07, 20.54s/it] 20%|█▉        | 4038/20600 [23:30:30<98:16:56, 21.36s/it] 20%|█▉        | 4039/20600 [23:30:50<96:20:54, 20.94s/it] 20%|█▉        | 4040/20600 [23:31:10<95:07:45, 20.68s/it]                                                          {'loss': 0.0, 'learning_rate': 4.576022537927199e-05, 'epoch': 38.94}
 20%|█▉        | 4040/20600 [23:31:10<95:07:45, 20.68s/it][INFO|trainer.py:3081] 2023-08-17 15:20:13,417 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:20:13,417 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:20:13,417 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.9991, 'eval_samples_per_second': 0.875, 'eval_steps_per_second': 0.125, 'epoch': 38.94}
 20%|█▉        | 4040/20600 [23:31:18<95:07:45, 20.68s/it]
100%|██████████| 1/1 [00:07<00:00,  7.15s/it][A
                                             [A 20%|█▉        | 4041/20600 [23:31:36<101:46:53, 22.13s/it] 20%|█▉        | 4042/20600 [23:31:53<95:27:49, 20.76s/it]  20%|█▉        | 4043/20600 [23:32:12<91:42:38, 19.94s/it] 20%|█▉        | 4044/20600 [23:32:32<92:27:32, 20.10s/it] 20%|█▉        | 4045/20600 [23:32:56<97:22:16, 21.17s/it] 20%|█▉        | 4046/20600 [23:33:15<95:19:49, 20.73s/it] 20%|█▉        | 4047/20600 [23:33:40<101:11:56, 22.01s/it] 20%|█▉        | 4048/20600 [23:34:02<100:36:32, 21.88s/it] 20%|█▉        | 4049/20600 [23:34:20<95:30:03, 20.77s/it]  20%|█▉        | 4050/20600 [23:34:45<100:49:35, 21.93s/it]                                                           {'loss': 0.0, 'learning_rate': 4.5738959113255364e-05, 'epoch': 39.04}
 20%|█▉        | 4050/20600 [23:34:45<100:49:35, 21.93s/it][INFO|trainer.py:3081] 2023-08-17 15:23:47,795 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:23:47,795 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:23:47,796 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 6.2352, 'eval_samples_per_second': 1.123, 'eval_steps_per_second': 0.16, 'epoch': 39.04}
 20%|█▉        | 4050/20600 [23:34:51<100:49:35, 21.93s/it]
100%|██████████| 1/1 [00:05<00:00,  5.35s/it][A
                                             [A 20%|█▉        | 4051/20600 [23:35:09<104:06:31, 22.65s/it] 20%|█▉        | 4052/20600 [23:35:30<102:03:53, 22.20s/it] 20%|█▉        | 4053/20600 [23:35:50<98:29:04, 21.43s/it]  20%|█▉        | 4054/20600 [23:36:09<95:23:54, 20.76s/it] 20%|█▉        | 4055/20600 [23:36:31<96:22:20, 20.97s/it] 20%|█▉        | 4056/20600 [23:36:47<90:38:51, 19.73s/it] 20%|█▉        | 4057/20600 [23:37:11<95:28:56, 20.78s/it] 20%|█▉        | 4058/20600 [23:37:30<93:03:55, 20.25s/it] 20%|█▉        | 4059/20600 [23:37:48<90:16:21, 19.65s/it] 20%|█▉        | 4060/20600 [23:38:12<96:02:20, 20.90s/it]                                                          {'loss': 0.0, 'learning_rate': 4.571764461336127e-05, 'epoch': 39.13}
 20%|█▉        | 4060/20600 [23:38:12<96:02:20, 20.90s/it][INFO|trainer.py:3081] 2023-08-17 15:27:14,709 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:27:14,710 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:27:14,710 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.7454, 'eval_samples_per_second': 1.038, 'eval_steps_per_second': 0.148, 'epoch': 39.13}
 20%|█▉        | 4060/20600 [23:38:18<96:02:20, 20.90s/it]
100%|██████████| 1/1 [00:05<00:00,  5.87s/it][A
                                             [A 20%|█▉        | 4061/20600 [23:38:37<102:46:02, 22.37s/it] 20%|█▉        | 4062/20600 [23:39:05<109:48:44, 23.90s/it] 20%|█▉        | 4063/20600 [23:39:26<106:02:12, 23.08s/it] 20%|█▉        | 4064/20600 [23:39:43<98:07:26, 21.36s/it]  20%|█▉        | 4065/20600 [23:40:03<95:27:18, 20.78s/it] 20%|█▉        | 4066/20600 [23:40:27<100:29:47, 21.88s/it] 20%|█▉        | 4067/20600 [23:40:44<93:42:34, 20.40s/it]  20%|█▉        | 4068/20600 [23:41:06<95:58:06, 20.90s/it] 20%|█▉        | 4069/20600 [23:41:29<98:41:11, 21.49s/it] 20%|█▉        | 4070/20600 [23:41:47<94:10:57, 20.51s/it]                                                          {'loss': 0.0, 'learning_rate': 4.5696281929162136e-05, 'epoch': 39.23}
 20%|█▉        | 4070/20600 [23:41:48<94:10:57, 20.51s/it][INFO|trainer.py:3081] 2023-08-17 15:30:50,477 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:30:50,477 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:30:50,477 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.0963, 'eval_samples_per_second': 0.986, 'eval_steps_per_second': 0.141, 'epoch': 39.23}
 20%|█▉        | 4070/20600 [23:41:55<94:10:57, 20.51s/it]
100%|██████████| 1/1 [00:06<00:00,  6.22s/it][A
                                             [A 20%|█▉        | 4071/20600 [23:42:15<103:49:18, 22.61s/it] 20%|█▉        | 4072/20600 [23:42:37<103:20:25, 22.51s/it] 20%|█▉        | 4073/20600 [23:43:01<104:57:01, 22.86s/it] 20%|█▉        | 4074/20600 [23:43:20<100:01:17, 21.79s/it] 20%|█▉        | 4075/20600 [23:43:36<91:17:33, 19.89s/it]  20%|█▉        | 4076/20600 [23:44:04<102:29:38, 22.33s/it] 20%|█▉        | 4077/20600 [23:44:22<96:20:43, 20.99s/it]  20%|█▉        | 4078/20600 [23:44:46<101:40:07, 22.15s/it] 20%|█▉        | 4079/20600 [23:45:01<91:37:47, 19.97s/it]  20%|█▉        | 4080/20600 [23:45:26<98:46:53, 21.53s/it]                                                          {'loss': 0.0, 'learning_rate': 4.567487111034248e-05, 'epoch': 39.33}
 20%|█▉        | 4080/20600 [23:45:26<98:46:53, 21.53s/it][INFO|trainer.py:3081] 2023-08-17 15:34:29,464 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:34:29,464 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:34:29,465 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.5631, 'eval_samples_per_second': 1.965, 'eval_steps_per_second': 0.281, 'epoch': 39.33}
 20%|█▉        | 4080/20600 [23:45:30<98:46:53, 21.53s/it]
100%|██████████| 1/1 [00:02<00:00,  2.73s/it][A
                                             [A 20%|█▉        | 4081/20600 [23:45:53<105:03:11, 22.89s/it] 20%|█▉        | 4082/20600 [23:46:10<97:41:41, 21.29s/it]  20%|█▉        | 4083/20600 [23:46:28<93:06:54, 20.30s/it] 20%|█▉        | 4084/20600 [23:46:48<92:32:44, 20.17s/it] 20%|█▉        | 4085/20600 [23:47:05<88:07:24, 19.21s/it] 20%|█▉        | 4086/20600 [23:47:30<95:33:05, 20.83s/it] 20%|█▉        | 4087/20600 [23:47:45<88:12:17, 19.23s/it] 20%|█▉        | 4088/20600 [23:48:09<94:23:35, 20.58s/it] 20%|█▉        | 4089/20600 [23:48:29<94:22:33, 20.58s/it] 20%|█▉        | 4090/20600 [23:48:53<98:29:35, 21.48s/it]                                                          {'loss': 0.0, 'learning_rate': 4.565341220669878e-05, 'epoch': 39.42}
 20%|█▉        | 4090/20600 [23:48:53<98:29:35, 21.48s/it][INFO|trainer.py:3081] 2023-08-17 15:37:55,886 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:37:55,886 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:37:55,886 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8707, 'eval_samples_per_second': 1.808, 'eval_steps_per_second': 0.258, 'epoch': 39.42}
 20%|█▉        | 4090/20600 [23:48:57<98:29:35, 21.48s/it]
100%|██████████| 1/1 [00:03<00:00,  3.03s/it][A
                                             [A 20%|█▉        | 4091/20600 [23:49:16<100:59:01, 22.02s/it] 20%|█▉        | 4092/20600 [23:49:35<97:11:47, 21.20s/it]  20%|█▉        | 4093/20600 [23:49:58<99:05:55, 21.61s/it] 20%|█▉        | 4094/20600 [23:50:19<97:29:45, 21.26s/it] 20%|█▉        | 4095/20600 [23:50:40<98:04:00, 21.39s/it] 20%|█▉        | 4096/20600 [23:50:57<92:07:02, 20.09s/it] 20%|█▉        | 4097/20600 [23:51:21<97:10:15, 21.20s/it] 20%|█▉        | 4098/20600 [23:51:40<93:25:00, 20.38s/it] 20%|█▉        | 4099/20600 [23:51:59<91:47:08, 20.02s/it] 20%|█▉        | 4100/20600 [23:52:19<91:30:49, 19.97s/it]                                                          {'loss': 0.0, 'learning_rate': 4.563190526813932e-05, 'epoch': 39.52}
 20%|█▉        | 4100/20600 [23:52:19<91:30:49, 19.97s/it][INFO|trainer.py:3081] 2023-08-17 15:41:21,523 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:41:21,524 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:41:21,524 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7442, 'eval_samples_per_second': 1.87, 'eval_steps_per_second': 0.267, 'epoch': 39.52}
 20%|█▉        | 4100/20600 [23:52:22<91:30:49, 19.97s/it]
100%|██████████| 1/1 [00:02<00:00,  2.86s/it][A
                                             [A 20%|█▉        | 4101/20600 [23:52:39<92:46:31, 20.24s/it] 20%|█▉        | 4102/20600 [23:53:06<101:30:04, 22.15s/it] 20%|█▉        | 4103/20600 [23:53:33<108:00:13, 23.57s/it] 20%|█▉        | 4104/20600 [23:53:59<111:57:57, 24.43s/it] 20%|█▉        | 4105/20600 [23:54:17<103:10:35, 22.52s/it] 20%|█▉        | 4106/20600 [23:54:37<98:37:48, 21.53s/it]  20%|█▉        | 4107/20600 [23:55:07<110:16:45, 24.07s/it] 20%|█▉        | 4108/20600 [23:55:22<98:43:14, 21.55s/it]  20%|█▉        | 4109/20600 [23:55:44<98:43:52, 21.55s/it] 20%|█▉        | 4110/20600 [23:56:05<98:33:44, 21.52s/it]                                                          {'loss': 0.0, 'learning_rate': 4.5610350344684116e-05, 'epoch': 39.61}
 20%|█▉        | 4110/20600 [23:56:05<98:33:44, 21.52s/it][INFO|trainer.py:3081] 2023-08-17 15:45:08,279 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:45:08,279 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:45:08,279 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 8.7167, 'eval_samples_per_second': 0.803, 'eval_steps_per_second': 0.115, 'epoch': 39.61}
 20%|█▉        | 4110/20600 [23:56:14<98:33:44, 21.52s/it]
100%|██████████| 1/1 [00:07<00:00,  7.82s/it][A
                                             [A 20%|█▉        | 4111/20600 [23:56:38<114:06:13, 24.91s/it] 20%|█▉        | 4112/20600 [23:56:59<108:46:13, 23.75s/it] 20%|█▉        | 4113/20600 [23:57:16<98:46:23, 21.57s/it]  20%|█▉        | 4114/20600 [23:57:43<106:27:51, 23.25s/it] 20%|█▉        | 4115/20600 [23:58:03<102:23:01, 22.36s/it] 20%|█▉        | 4116/20600 [23:58:24<100:44:02, 22.00s/it] 20%|█▉        | 4117/20600 [23:58:44<97:18:22, 21.25s/it]  20%|█▉        | 4118/20600 [23:59:02<93:38:10, 20.45s/it] 20%|█▉        | 4119/20600 [23:59:30<103:35:15, 22.63s/it] 20%|██        | 4120/20600 [23:59:45<93:43:56, 20.48s/it]                                                           {'loss': 0.0, 'learning_rate': 4.558874748646479e-05, 'epoch': 39.71}
 20%|██        | 4120/20600 [23:59:45<93:43:56, 20.48s/it][INFO|trainer.py:3081] 2023-08-17 15:48:48,466 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:48:48,466 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:48:48,466 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.7242, 'eval_samples_per_second': 1.88, 'eval_steps_per_second': 0.269, 'epoch': 39.71}
 20%|██        | 4120/20600 [23:59:49<93:43:56, 20.48s/it]
100%|██████████| 1/1 [00:02<00:00,  2.81s/it][A
                                             [A 20%|██        | 4121/20600 [24:00:09<97:28:39, 21.29s/it] 20%|██        | 4122/20600 [24:00:30<97:34:32, 21.32s/it] 20%|██        | 4123/20600 [24:00:47<91:08:11, 19.91s/it] 20%|██        | 4124/20600 [24:01:04<87:17:01, 19.07s/it] 20%|██        | 4125/20600 [24:01:26<91:49:30, 20.06s/it] 20%|██        | 4126/20600 [24:01:45<90:19:04, 19.74s/it] 20%|██        | 4127/20600 [24:02:08<94:03:27, 20.56s/it] 20%|██        | 4128/20600 [24:02:22<85:43:26, 18.74s/it] 20%|██        | 4129/20600 [24:02:54<103:47:29, 22.69s/it] 20%|██        | 4130/20600 [24:03:11<95:23:16, 20.85s/it]                                                           {'loss': 0.0, 'learning_rate': 4.5567096743724433e-05, 'epoch': 39.81}
 20%|██        | 4130/20600 [24:03:11<95:23:16, 20.85s/it][INFO|trainer.py:3081] 2023-08-17 15:52:13,589 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:52:13,589 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:52:13,589 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2376, 'eval_samples_per_second': 0.967, 'eval_steps_per_second': 0.138, 'epoch': 39.81}
 20%|██        | 4130/20600 [24:03:18<95:23:16, 20.85s/it]
100%|██████████| 1/1 [00:06<00:00,  6.34s/it][A
                                             [A 20%|██        | 4131/20600 [24:03:37<103:38:14, 22.65s/it] 20%|██        | 4132/20600 [24:03:55<96:32:33, 21.10s/it]  20%|██        | 4133/20600 [24:04:22<104:51:27, 22.92s/it] 20%|██        | 4134/20600 [24:04:37<93:35:10, 20.46s/it]  20%|██        | 4135/20600 [24:04:56<91:23:42, 19.98s/it] 20%|██        | 4136/20600 [24:05:26<106:03:34, 23.19s/it] 20%|██        | 4137/20600 [24:05:49<105:45:53, 23.13s/it] 20%|██        | 4138/20600 [24:06:09<100:23:56, 21.96s/it] 20%|██        | 4139/20600 [24:06:28<97:19:51, 21.29s/it]  20%|██        | 4140/20600 [24:06:45<90:31:24, 19.80s/it]                                                          {'loss': 0.0, 'learning_rate': 4.554539816681752e-05, 'epoch': 39.9}
 20%|██        | 4140/20600 [24:06:45<90:31:24, 19.80s/it][INFO|trainer.py:3081] 2023-08-17 15:55:47,623 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:55:47,623 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:55:47,623 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.0041, 'eval_samples_per_second': 1.166, 'eval_steps_per_second': 0.167, 'epoch': 39.9}
 20%|██        | 4140/20600 [24:06:51<90:31:24, 19.80s/it]
100%|██████████| 1/1 [00:05<00:00,  5.04s/it][A
                                             [A 20%|██        | 4141/20600 [24:07:09<96:26:11, 21.09s/it] 20%|██        | 4142/20600 [24:07:32<98:45:56, 21.60s/it] 20%|██        | 4143/20600 [24:07:51<96:08:59, 21.03s/it] 20%|██        | 4144/20600 [24:08:12<95:06:28, 20.81s/it] 20%|██        | 4145/20600 [24:08:30<92:35:03, 20.26s/it] 20%|██        | 4146/20600 [24:08:47<87:53:22, 19.23s/it] 20%|██        | 4147/20600 [24:09:08<90:28:05, 19.79s/it] 20%|██        | 4148/20600 [24:09:25<86:32:16, 18.94s/it] 20%|██        | 4149/20600 [24:09:46<88:31:47, 19.37s/it] 20%|██        | 4150/20600 [24:10:01<83:07:04, 18.19s/it]                                                          {'loss': 0.0, 'learning_rate': 4.552365180620978e-05, 'epoch': 40.0}
 20%|██        | 4150/20600 [24:10:01<83:07:04, 18.19s/it][INFO|trainer.py:3081] 2023-08-17 15:59:04,179 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 15:59:04,179 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 15:59:04,179 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.6254, 'eval_samples_per_second': 1.513, 'eval_steps_per_second': 0.216, 'epoch': 40.0}
 20%|██        | 4150/20600 [24:10:06<83:07:04, 18.19s/it]
100%|██████████| 1/1 [00:03<00:00,  3.74s/it][A
                                             [A 20%|██        | 4151/20600 [24:10:26<92:15:23, 20.19s/it] 20%|██        | 4152/20600 [24:10:44<89:01:33, 19.49s/it] 20%|██        | 4153/20600 [24:11:09<97:25:15, 21.32s/it] 20%|██        | 4154/20600 [24:11:27<92:28:01, 20.24s/it] 20%|██        | 4155/20600 [24:11:45<89:43:18, 19.64s/it] 20%|██        | 4156/20600 [24:12:08<93:22:52, 20.44s/it] 20%|██        | 4157/20600 [24:12:33<99:46:45, 21.85s/it] 20%|██        | 4158/20600 [24:13:01<108:10:14, 23.68s/it] 20%|██        | 4159/20600 [24:13:21<102:51:01, 22.52s/it] 20%|██        | 4160/20600 [24:13:44<104:37:05, 22.91s/it]                                                           {'loss': 0.0, 'learning_rate': 4.5501857712478045e-05, 'epoch': 40.1}
 20%|██        | 4160/20600 [24:13:45<104:37:05, 22.91s/it][INFO|trainer.py:3081] 2023-08-17 16:02:47,484 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:02:47,484 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:02:47,484 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.9558, 'eval_samples_per_second': 1.77, 'eval_steps_per_second': 0.253, 'epoch': 40.1}
 20%|██        | 4160/20600 [24:13:48<104:37:05, 22.91s/it]
100%|██████████| 1/1 [00:03<00:00,  3.08s/it][A
                                             [A 20%|██        | 4161/20600 [24:14:12<110:54:26, 24.29s/it] 20%|██        | 4162/20600 [24:14:34<108:11:27, 23.69s/it] 20%|██        | 4163/20600 [24:15:00<111:15:13, 24.37s/it] 20%|██        | 4164/20600 [24:15:21<105:40:43, 23.15s/it] 20%|██        | 4165/20600 [24:15:39<98:43:25, 21.62s/it]  20%|██        | 4166/20600 [24:16:03<101:58:07, 22.34s/it] 20%|██        | 4167/20600 [24:16:22<97:44:43, 21.41s/it]  20%|██        | 4168/20600 [24:16:46<101:35:41, 22.26s/it] 20%|██        | 4169/20600 [24:17:09<102:53:26, 22.54s/it] 20%|██        | 4170/20600 [24:17:35<107:05:32, 23.47s/it]                                                           {'loss': 0.0, 'learning_rate': 4.5480015936310206e-05, 'epoch': 40.19}
 20%|██        | 4170/20600 [24:17:35<107:05:32, 23.47s/it][INFO|trainer.py:3081] 2023-08-17 16:06:37,918 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:06:37,918 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:06:37,918 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                           
                                     [A{'eval_loss': nan, 'eval_runtime': 3.4804, 'eval_samples_per_second': 2.011, 'eval_steps_per_second': 0.287, 'epoch': 40.19}
 20%|██        | 4170/20600 [24:17:38<107:05:32, 23.47s/it]
100%|██████████| 1/1 [00:02<00:00,  2.59s/it][A
                                             [A 20%|██        | 4171/20600 [24:18:01<110:09:17, 24.14s/it] 20%|██        | 4172/20600 [24:18:21<104:39:56, 22.94s/it] 20%|██        | 4173/20600 [24:18:38<96:29:57, 21.15s/it]  20%|██        | 4174/20600 [24:19:01<99:49:56, 21.88s/it] 20%|██        | 4175/20600 [24:19:20<95:30:06, 20.93s/it] 20%|██        | 4176/20600 [24:19:40<94:17:19, 20.67s/it] 20%|██        | 4177/20600 [24:19:58<90:31:46, 19.84s/it] 20%|██        | 4178/20600 [24:20:18<90:53:53, 19.93s/it] 20%|██        | 4179/20600 [24:20:39<92:46:36, 20.34s/it] 20%|██        | 4180/20600 [24:20:57<89:30:44, 19.63s/it]                                                          {'loss': 0.0, 'learning_rate': 4.545812652850502e-05, 'epoch': 40.29}
 20%|██        | 4180/20600 [24:20:57<89:30:44, 19.63s/it][INFO|trainer.py:3081] 2023-08-17 16:10:00,391 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:10:00,392 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:10:00,392 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 3.8972, 'eval_samples_per_second': 1.796, 'eval_steps_per_second': 0.257, 'epoch': 40.29}
 20%|██        | 4180/20600 [24:21:01<89:30:44, 19.63s/it]
100%|██████████| 1/1 [00:03<00:00,  3.02s/it][A
                                             [A 20%|██        | 4181/20600 [24:21:23<97:20:09, 21.34s/it] 20%|██        | 4182/20600 [24:21:41<93:10:21, 20.43s/it] 20%|██        | 4183/20600 [24:22:00<91:45:06, 20.12s/it] 20%|██        | 4184/20600 [24:22:20<91:30:38, 20.07s/it] 20%|██        | 4185/20600 [24:22:48<101:16:59, 22.21s/it] 20%|██        | 4186/20600 [24:23:04<93:53:06, 20.59s/it]  20%|██        | 4187/20600 [24:23:28<97:37:09, 21.41s/it] 20%|██        | 4188/20600 [24:23:47<94:54:35, 20.82s/it] 20%|██        | 4189/20600 [24:24:08<94:31:06, 20.73s/it] 20%|██        | 4190/20600 [24:24:25<89:48:46, 19.70s/it]                                                          {'loss': 0.0, 'learning_rate': 4.543618953997203e-05, 'epoch': 40.39}
 20%|██        | 4190/20600 [24:24:25<89:48:46, 19.70s/it][INFO|trainer.py:3081] 2023-08-17 16:13:28,002 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:13:28,116 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:13:28,117 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.2489, 'eval_samples_per_second': 1.334, 'eval_steps_per_second': 0.191, 'epoch': 40.39}
 20%|██        | 4190/20600 [24:24:30<89:48:46, 19.70s/it]
100%|██████████| 1/1 [00:04<00:00,  4.28s/it][A
                                             [A 20%|██        | 4191/20600 [24:24:47<93:25:42, 20.50s/it] 20%|██        | 4192/20600 [24:25:07<91:52:02, 20.16s/it] 20%|██        | 4193/20600 [24:25:32<98:22:04, 21.58s/it] 20%|██        | 4194/20600 [24:25:47<89:55:57, 19.73s/it] 20%|██        | 4195/20600 [24:26:07<90:23:17, 19.84s/it] 20%|██        | 4196/20600 [24:26:28<92:12:14, 20.23s/it] 20%|██        | 4197/20600 [24:26:46<88:47:10, 19.49s/it] 20%|██        | 4198/20600 [24:27:05<88:27:49, 19.42s/it] 20%|██        | 4199/20600 [24:27:25<89:23:28, 19.62s/it] 20%|██        | 4200/20600 [24:27:44<88:22:11, 19.40s/it]                                                          {'loss': 0.0, 'learning_rate': 4.541420502173145e-05, 'epoch': 40.48}
 20%|██        | 4200/20600 [24:27:44<88:22:11, 19.40s/it][INFO|trainer.py:3081] 2023-08-17 16:16:47,233 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:16:47,234 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:16:47,234 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 7.2494, 'eval_samples_per_second': 0.966, 'eval_steps_per_second': 0.138, 'epoch': 40.48}
 20%|██        | 4200/20600 [24:27:52<88:22:11, 19.40s/it]
100%|██████████| 1/1 [00:06<00:00,  6.38s/it][A
                                             [A 20%|██        | 4201/20600 [24:28:13<100:29:37, 22.06s/it] 20%|██        | 4202/20600 [24:28:31<95:03:43, 20.87s/it]  20%|██        | 4203/20600 [24:28:47<89:02:31, 19.55s/it] 20%|██        | 4204/20600 [24:29:06<88:28:33, 19.43s/it] 20%|██        | 4205/20600 [24:29:25<87:37:57, 19.24s/it] 20%|██        | 4206/20600 [24:29:46<90:15:02, 19.82s/it] 20%|██        | 4207/20600 [24:30:05<88:43:59, 19.49s/it] 20%|██        | 4208/20600 [24:30:23<86:39:12, 19.03s/it] 20%|██        | 4209/20600 [24:30:40<84:15:40, 18.51s/it] 20%|██        | 4210/20600 [24:30:58<82:56:46, 18.22s/it]                                                          {'loss': 0.0, 'learning_rate': 4.539217302491403e-05, 'epoch': 40.58}
 20%|██        | 4210/20600 [24:30:58<82:56:46, 18.22s/it][INFO|trainer.py:3081] 2023-08-17 16:20:00,717 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:20:00,717 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:20:00,717 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 4.1165, 'eval_samples_per_second': 1.7, 'eval_steps_per_second': 0.243, 'epoch': 40.58}
 20%|██        | 4210/20600 [24:31:02<82:56:46, 18.22s/it]
100%|██████████| 1/1 [00:03<00:00,  3.25s/it][A
                                             [A 20%|██        | 4211/20600 [24:31:21<89:31:16, 19.66s/it] 20%|██        | 4212/20600 [24:31:39<87:06:50, 19.14s/it] 20%|██        | 4213/20600 [24:31:57<85:24:26, 18.76s/it] 20%|██        | 4214/20600 [24:32:17<88:19:12, 19.40s/it] 20%|██        | 4215/20600 [24:32:39<90:34:17, 19.90s/it] 20%|██        | 4216/20600 [24:32:55<86:34:12, 19.02s/it] 20%|██        | 4217/20600 [24:33:20<94:01:41, 20.66s/it] 20%|██        | 4218/20600 [24:33:38<90:45:36, 19.94s/it] 20%|██        | 4219/20600 [24:34:00<92:46:13, 20.39s/it] 20%|██        | 4220/20600 [24:34:19<90:41:26, 19.93s/it]                                                          {'loss': 0.0, 'learning_rate': 4.5370093600760946e-05, 'epoch': 40.67}
 20%|██        | 4220/20600 [24:34:19<90:41:26, 19.93s/it][INFO|trainer.py:3081] 2023-08-17 16:23:21,524 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:23:21,524 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:23:21,524 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 6.1231, 'eval_samples_per_second': 1.143, 'eval_steps_per_second': 0.163, 'epoch': 40.67}
 20%|██        | 4220/20600 [24:34:25<90:41:26, 19.93s/it]
100%|██████████| 1/1 [00:05<00:00,  5.27s/it][A
                                             [A 20%|██        | 4221/20600 [24:34:44<98:06:47, 21.56s/it] 20%|██        | 4222/20600 [24:35:01<91:54:32, 20.20s/it] 20%|██        | 4223/20600 [24:35:19<89:21:09, 19.64s/it] 21%|██        | 4224/20600 [24:35:35<84:07:51, 18.49s/it] 21%|██        | 4225/20600 [24:35:53<83:07:50, 18.28s/it] 21%|██        | 4226/20600 [24:36:10<81:39:34, 17.95s/it] 21%|██        | 4227/20600 [24:36:36<92:38:26, 20.37s/it] 21%|██        | 4228/20600 [24:36:58<94:42:30, 20.83s/it] 21%|██        | 4229/20600 [24:37:13<87:25:30, 19.22s/it] 21%|██        | 4230/20600 [24:37:37<93:56:09, 20.66s/it]                                                          {'loss': 0.0, 'learning_rate': 4.5347966800623674e-05, 'epoch': 40.77}
 21%|██        | 4230/20600 [24:37:37<93:56:09, 20.66s/it][INFO|trainer.py:3081] 2023-08-17 16:26:40,426 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:26:40,426 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:26:40,426 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 5.2663, 'eval_samples_per_second': 1.329, 'eval_steps_per_second': 0.19, 'epoch': 40.77}
 21%|██        | 4230/20600 [24:37:43<93:56:09, 20.66s/it]
100%|██████████| 1/1 [00:04<00:00,  4.42s/it][A
                                             [A 21%|██        | 4231/20600 [24:37:57<92:37:42, 20.37s/it] 21%|██        | 4232/20600 [24:38:20<95:48:40, 21.07s/it] 21%|██        | 4233/20600 [24:38:39<93:23:23, 20.54s/it] 21%|██        | 4234/20600 [24:38:59<92:41:59, 20.39s/it] 21%|██        | 4235/20600 [24:39:17<89:07:17, 19.61s/it] 21%|██        | 4236/20600 [24:39:44<99:01:34, 21.79s/it] 21%|██        | 4237/20600 [24:40:00<91:26:47, 20.12s/it] 21%|██        | 4238/20600 [24:40:25<97:33:55, 21.47s/it] 21%|██        | 4239/20600 [24:40:48<100:31:10, 22.12s/it] 21%|██        | 4240/20600 [24:41:02<89:29:24, 19.69s/it]                                                           {'loss': 0.0, 'learning_rate': 4.532579267596389e-05, 'epoch': 40.87}
 21%|██        | 4240/20600 [24:41:02<89:29:24, 19.69s/it][INFO|trainer.py:3081] 2023-08-17 16:30:05,342 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-08-17 16:30:05,342 >>   Num examples = 7
[INFO|trainer.py:3086] 2023-08-17 16:30:05,342 >>   Batch size = 8

  0%|          | 0/1 [00:00<?, ?it/s][A                                                          
                                     [A{'eval_loss': nan, 'eval_runtime': 9.0311, 'eval_samples_per_second': 0.775, 'eval_steps_per_second': 0.111, 'epoch': 40.87}
 21%|██        | 4240/20600 [24:41:11<89:29:24, 19.69s/it]
100%|██████████| 1/1 [00:08<00:00,  8.13s/it][A
                                             [A 21%|██        | 4241/20600 [24:41:36<108:10:35, 23.81s/it] 21%|██        | 4242/20600 [24:41:56<102:41:20, 22.60s/it] 21%|██        | 4243/20600 [24:42:19<104:19:13, 22.96s/it]WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3636 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3637 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3638 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -15) local_rank: 0 (pid: 3635) of binary: /home/jyhu/miniconda3/envs/llama_etuning/bin/python
Traceback (most recent call last):
  File "/home/jyhu/miniconda3/envs/llama_etuning/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/accelerate/commands/launch.py", line 970, in launch_command
    multi_gpu_launcher(args)
  File "/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/accelerate/commands/launch.py", line 646, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jyhu/miniconda3/envs/llama_etuning/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
../src/train_bash.py FAILED
------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-17_16:31:37
  host      : blade3
  rank      : 0 (local_rank: 0)
  exitcode  : -15 (pid: 3635)
  error_file: <N/A>
  traceback : Signal 15 (SIGTERM) received by PID 3635
======================================================
